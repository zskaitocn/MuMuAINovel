"""MCPå·¥å…·æœåŠ¡ - ç»Ÿä¸€ç®¡ç†MCPå·¥å…·çš„æ³¨å…¥å’Œæ‰§è¡Œ"""

from typing import List, Dict, Any, Optional
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
import asyncio
import json
import time
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from collections import defaultdict

from app.models.mcp_plugin import MCPPlugin
from app.mcp.registry import mcp_registry
from app.mcp.config import mcp_config
from app.logger import get_logger

logger = get_logger(__name__)


@dataclass
class ToolMetrics:
    """å·¥å…·è°ƒç”¨æŒ‡æ ‡"""
    total_calls: int = 0
    success_calls: int = 0
    failed_calls: int = 0
    total_duration_ms: float = 0.0
    avg_duration_ms: float = 0.0
    last_call_time: Optional[datetime] = None
    
    def update_success(self, duration_ms: float):
        """æ›´æ–°æˆåŠŸè°ƒç”¨æŒ‡æ ‡"""
        self.total_calls += 1
        self.success_calls += 1
        self.total_duration_ms += duration_ms
        self.avg_duration_ms = self.total_duration_ms / self.total_calls
        self.last_call_time = datetime.now()
    
    def update_failure(self, duration_ms: float):
        """æ›´æ–°å¤±è´¥è°ƒç”¨æŒ‡æ ‡"""
        self.total_calls += 1
        self.failed_calls += 1
        self.total_duration_ms += duration_ms
        self.avg_duration_ms = self.total_duration_ms / self.total_calls
        self.last_call_time = datetime.now()
    
    @property
    def success_rate(self) -> float:
        """æˆåŠŸç‡"""
        if self.total_calls == 0:
            return 0.0
        return self.success_calls / self.total_calls


@dataclass
class ToolCacheEntry:
    """å·¥å…·ç¼“å­˜æ¡ç›®"""
    tools: List[Dict[str, Any]]
    expire_time: datetime
    hit_count: int = 0


class MCPToolServiceError(Exception):
    """MCPå·¥å…·æœåŠ¡å¼‚å¸¸"""
    pass


class MCPToolService:
    """MCPå·¥å…·æœåŠ¡ - ç»Ÿä¸€ç®¡ç†MCPå·¥å…·çš„æ³¨å…¥å’Œæ‰§è¡Œï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
    
    def __init__(
        self,
        cache_ttl_minutes: Optional[int] = None,
        max_retries: Optional[int] = None
    ):
        """
        åˆå§‹åŒ–MCPå·¥å…·æœåŠ¡
        
        Args:
            cache_ttl_minutes: å·¥å…·ç¼“å­˜TTLï¼ˆåˆ†é’Ÿï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ï¼‰
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤ä½¿ç”¨é…ç½®ï¼‰
        """
        # å·¥å…·å®šä¹‰ç¼“å­˜: {cache_key: ToolCacheEntry}
        self._tool_cache: Dict[str, ToolCacheEntry] = {}
        self._cache_ttl = timedelta(
            minutes=cache_ttl_minutes or mcp_config.TOOL_CACHE_TTL_MINUTES
        )
        
        # è°ƒç”¨æŒ‡æ ‡: {tool_key: ToolMetrics}
        self._metrics: Dict[str, ToolMetrics] = defaultdict(ToolMetrics)
        
        # é‡è¯•é…ç½®ï¼ˆä½¿ç”¨é…ç½®å¸¸é‡ï¼‰
        self._max_retries = max_retries or mcp_config.MAX_RETRIES
        self._base_retry_delay = mcp_config.BASE_RETRY_DELAY_SECONDS
        self._max_retry_delay = mcp_config.MAX_RETRY_DELAY_SECONDS
        
        logger.info(
            f"âœ… MCPToolServiceåˆå§‹åŒ–å®Œæˆ "
            f"(ç¼“å­˜TTL={self._cache_ttl.total_seconds()/60:.1f}åˆ†é’Ÿ, "
            f"æœ€å¤§é‡è¯•={self._max_retries}æ¬¡)"
        )
    
    async def get_user_enabled_tools(
        self,
        user_id: str,
        db_session: AsyncSession,
        category: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        è·å–ç”¨æˆ·å¯ç”¨çš„MCPå·¥å…·åˆ—è¡¨
        
        Args:
            user_id: ç”¨æˆ·ID
            db_session: æ•°æ®åº“ä¼šè¯
            category: å·¥å…·ç±»åˆ«ç­›é€‰ï¼ˆsearch/analysis/filesystemç­‰ï¼‰
        
        Returns:
            å·¥å…·å®šä¹‰åˆ—è¡¨ï¼Œæ ¼å¼ç¬¦åˆOpenAI Function Callingè§„èŒƒ
        """
        try:
            # 1. æŸ¥è¯¢ç”¨æˆ·å¯ç”¨çš„æ’ä»¶ï¼ˆenabled=Trueå³å¯ï¼Œä¸å¼ºåˆ¶è¦æ±‚status=activeï¼‰
            # å› ä¸ºæ–°å¯ç”¨çš„æ’ä»¶statuså¯èƒ½è¿˜æ˜¯inactiveï¼Œéœ€è¦ç»™å®ƒæœºä¼šè¢«è°ƒç”¨
            query = select(MCPPlugin).where(
                MCPPlugin.user_id == user_id,
                MCPPlugin.enabled == True
            )
            
            if category:
                query = query.where(MCPPlugin.category == category)
            
            result = await db_session.execute(query)
            plugins = result.scalars().all()
            
            if not plugins:
                logger.info(f"ç”¨æˆ· {user_id} æ²¡æœ‰å¯ç”¨çš„MCPæ’ä»¶")
                return []
            
            # 2. è·å–æ‰€æœ‰å·¥å…·å®šä¹‰ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
            all_tools = []
            for plugin in plugins:
                try:
                    # ç¡®ä¿æ’ä»¶å·²åŠ è½½åˆ°æ³¨å†Œè¡¨
                    if not mcp_registry.get_client(user_id, plugin.plugin_name):
                        logger.info(f"æ’ä»¶ {plugin.plugin_name} æœªåŠ è½½ï¼Œå°è¯•åŠ è½½...")
                        success = await mcp_registry.load_plugin(plugin)
                        if not success:
                            logger.warning(f"æ’ä»¶ {plugin.plugin_name} åŠ è½½å¤±è´¥ï¼Œè·³è¿‡")
                            continue
                    
                    # âœ… ä½¿ç”¨ç¼“å­˜è·å–å·¥å…·åˆ—è¡¨
                    plugin_tools = await self._get_plugin_tools_cached(
                        user_id=user_id,
                        plugin_name=plugin.plugin_name
                    )
                    
                    # æ ¼å¼åŒ–ä¸ºFunction Callingæ ¼å¼
                    formatted_tools = self._format_tools_for_ai(
                        plugin_tools,
                        plugin.plugin_name
                    )
                    all_tools.extend(formatted_tools)
                    
                    logger.info(
                        f"ä»æ’ä»¶ {plugin.plugin_name} åŠ è½½äº† "
                        f"{len(formatted_tools)} ä¸ªå·¥å…·"
                    )
                    
                except Exception as e:
                    logger.error(
                        f"è·å–æ’ä»¶ {plugin.plugin_name} çš„å·¥å…·å¤±è´¥: {e}",
                        exc_info=True
                    )
                    continue
            
            logger.info(f"ç”¨æˆ· {user_id} å…±åŠ è½½ {len(all_tools)} ä¸ªMCPå·¥å…·")
            return all_tools
            
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·MCPå·¥å…·å¤±è´¥: {e}", exc_info=True)
            raise MCPToolServiceError(f"è·å–MCPå·¥å…·å¤±è´¥: {str(e)}")
    
    def _format_tools_for_ai(
        self,
        plugin_tools: List[Dict[str, Any]],
        plugin_name: str
    ) -> List[Dict[str, Any]]:
        """
        å°†MCPå·¥å…·å®šä¹‰æ ¼å¼åŒ–ä¸ºAI Function Callingæ ¼å¼
        
        Args:
            plugin_tools: MCPæ’ä»¶çš„å·¥å…·åˆ—è¡¨
            plugin_name: æ’ä»¶åç§°
        
        Returns:
            æ ¼å¼åŒ–åçš„å·¥å…·åˆ—è¡¨
        """
        formatted_tools = []
        
        for tool in plugin_tools:
            formatted_tool = {
                "type": "function",
                "function": {
                    "name": f"{plugin_name}_{tool['name']}",  # åŠ æ’ä»¶å‰ç¼€é¿å…å†²çª
                    "description": tool.get("description", ""),
                    "parameters": tool.get("inputSchema", {
                        "type": "object",
                        "properties": {},
                        "required": []
                    })
                }
            }
            formatted_tools.append(formatted_tool)
        
        return formatted_tools
    
    async def _get_plugin_tools_cached(
        self,
        user_id: str,
        plugin_name: str
    ) -> List[Dict[str, Any]]:
        """
        å¸¦ç¼“å­˜çš„å·¥å…·åˆ—è¡¨è·å–
        
        Args:
            user_id: ç”¨æˆ·ID
            plugin_name: æ’ä»¶åç§°
            
        Returns:
            å·¥å…·åˆ—è¡¨
        """
        cache_key = f"{user_id}:{plugin_name}"
        now = datetime.now()
        
        # æ£€æŸ¥ç¼“å­˜
        if cache_key in self._tool_cache:
            entry = self._tool_cache[cache_key]
            if now < entry.expire_time:
                entry.hit_count += 1
                logger.debug(
                    f"ğŸ¯ å·¥å…·ç¼“å­˜å‘½ä¸­: {cache_key} "
                    f"(å‘½ä¸­æ¬¡æ•°: {entry.hit_count})"
                )
                return entry.tools
            else:
                logger.debug(f"â° å·¥å…·ç¼“å­˜è¿‡æœŸ: {cache_key}")
                del self._tool_cache[cache_key]
        
        # ç¼“å­˜æœªå‘½ä¸­ï¼Œä»MCPè·å–
        logger.debug(f"ğŸ” å·¥å…·ç¼“å­˜æœªå‘½ä¸­ï¼Œä»MCPè·å–: {cache_key}")
        tools = await mcp_registry.get_plugin_tools(user_id, plugin_name)
        
        # æ›´æ–°ç¼“å­˜
        self._tool_cache[cache_key] = ToolCacheEntry(
            tools=tools,
            expire_time=now + self._cache_ttl,
            hit_count=0
        )
        
        return tools
    
    def clear_cache(self, user_id: Optional[str] = None, plugin_name: Optional[str] = None):
        """
        æ¸…ç†ç¼“å­˜
        
        Args:
            user_id: ç”¨æˆ·IDï¼ˆå¯é€‰ï¼Œæ¸…ç†ç‰¹å®šç”¨æˆ·çš„ç¼“å­˜ï¼‰
            plugin_name: æ’ä»¶åç§°ï¼ˆå¯é€‰ï¼Œæ¸…ç†ç‰¹å®šæ’ä»¶çš„ç¼“å­˜ï¼‰
        """
        if user_id is None and plugin_name is None:
            # æ¸…ç†æ‰€æœ‰ç¼“å­˜
            self._tool_cache.clear()
            logger.info("ğŸ§¹ å·²æ¸…ç†æ‰€æœ‰å·¥å…·ç¼“å­˜")
        elif user_id and plugin_name:
            # æ¸…ç†ç‰¹å®šæ’ä»¶ç¼“å­˜
            cache_key = f"{user_id}:{plugin_name}"
            if cache_key in self._tool_cache:
                del self._tool_cache[cache_key]
                logger.info(f"ğŸ§¹ å·²æ¸…ç†ç¼“å­˜: {cache_key}")
        elif user_id:
            # æ¸…ç†ç”¨æˆ·æ‰€æœ‰ç¼“å­˜
            keys_to_delete = [
                key for key in self._tool_cache.keys()
                if key.startswith(f"{user_id}:")
            ]
            for key in keys_to_delete:
                del self._tool_cache[key]
            logger.info(f"ğŸ§¹ å·²æ¸…ç†ç”¨æˆ·ç¼“å­˜: {user_id} ({len(keys_to_delete)}ä¸ª)")
    
    async def execute_tool_calls(
        self,
        user_id: str,
        tool_calls: List[Dict[str, Any]],
        db_session: AsyncSession,
        timeout: Optional[float] = None,
        max_concurrent: int = 2 
    ) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡æ‰§è¡ŒAIè¯·æ±‚çš„å·¥å…·è°ƒç”¨ï¼ˆé™åˆ¶å¹¶å‘æ•°ï¼Œé¿å…è¶…æ—¶ï¼‰
        
        Args:
            user_id: ç”¨æˆ·ID
            tool_calls: AIè¿”å›çš„å·¥å…·è°ƒç”¨åˆ—è¡¨
            db_session: æ•°æ®åº“ä¼šè¯
            timeout: å•ä¸ªå·¥å…·è°ƒç”¨çš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ï¼‰
            max_concurrent: æœ€å¤§å¹¶å‘å·¥å…·è°ƒç”¨æ•°ï¼ˆé»˜è®¤2ï¼‰
        
        Returns:
            å·¥å…·è°ƒç”¨ç»“æœåˆ—è¡¨
        """
        if not tool_calls:
            return []
        
        # ä½¿ç”¨é…ç½®çš„é»˜è®¤è¶…æ—¶
        actual_timeout = timeout or mcp_config.TOOL_CALL_TIMEOUT_SECONDS
        
        logger.info(f"å¼€å§‹æ‰§è¡Œ {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨ (è¶…æ—¶={actual_timeout}s, æœ€å¤§å¹¶å‘={max_concurrent})")
        
        # âœ… åˆ†æ‰¹æ‰§è¡Œï¼Œæ¯æ‰¹æœ€å¤šmax_concurrentä¸ª
        all_results = []
        for i in range(0, len(tool_calls), max_concurrent):
            batch = tool_calls[i:i+max_concurrent]
            batch_num = i // max_concurrent + 1
            total_batches = (len(tool_calls) + max_concurrent - 1) // max_concurrent
            
            logger.info(f"æ‰§è¡Œå·¥å…·æ‰¹æ¬¡ {batch_num}/{total_batches}, æ•°é‡: {len(batch)}")
            
            # åˆ›å»ºå½“å‰æ‰¹æ¬¡çš„å¼‚æ­¥ä»»åŠ¡
            tasks = [
                self._execute_single_tool(
                    user_id=user_id,
                    tool_call=tool_call,
                    db_session=db_session,
                    timeout=actual_timeout
                )
                for tool_call in batch
            ]
            
            # å¹¶è¡Œæ‰§è¡Œå½“å‰æ‰¹æ¬¡
            batch_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # å¤„ç†æ‰¹æ¬¡ç»“æœ
            for j, result in enumerate(batch_results):
                tool_call = batch[j]
                
                if isinstance(result, Exception):
                    # å·¥å…·è°ƒç”¨å¼‚å¸¸
                    all_results.append({
                        "tool_call_id": tool_call.get("id", f"call_{i+j}"),
                        "role": "tool",
                        "name": tool_call["function"]["name"],
                        "content": f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(result)}",
                        "success": False,
                        "error": str(result)
                    })
                else:
                    all_results.append(result)
            
            # æ‰¹æ¬¡é—´å¢åŠ çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…APIé™æµ
            if i + max_concurrent < len(tool_calls):
                await asyncio.sleep(0.5)
                logger.debug(f"æ‰¹æ¬¡é—´å»¶è¿Ÿ 0.5 ç§’...")
        
        return all_results
    
    async def _execute_single_tool(
        self,
        user_id: str,
        tool_call: Dict[str, Any],
        db_session: AsyncSession,
        timeout: float
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå•ä¸ªå·¥å…·è°ƒç”¨
        
        Args:
            user_id: ç”¨æˆ·ID
            tool_call: å·¥å…·è°ƒç”¨ä¿¡æ¯
            db_session: æ•°æ®åº“ä¼šè¯
            timeout: è¶…æ—¶æ—¶é—´
        
        Returns:
            å·¥å…·è°ƒç”¨ç»“æœ
        """
        tool_call_id = tool_call.get("id", "unknown")
        function_name = tool_call["function"]["name"]
        
        try:
            # è§£ææ’ä»¶åå’Œå·¥å…·å
            logger.debug(f"ğŸ” è§£æå·¥å…·åç§°: {function_name}")
            if "_" in function_name:
                plugin_name, tool_name = function_name.split("_", 1)
                logger.debug(f"  æ’ä»¶: {plugin_name}, å·¥å…·: {tool_name}")
            else:
                raise ValueError(f"æ— æ•ˆçš„å·¥å…·åç§°æ ¼å¼: {function_name}")
            
            # è§£æå‚æ•°
            arguments_str = tool_call["function"]["arguments"]
            logger.debug(f"ğŸ” è§£æå‚æ•°:")
            logger.debug(f"  åŸå§‹ç±»å‹: {type(arguments_str)}")
            logger.debug(f"  åŸå§‹å†…å®¹: {arguments_str}")
            
            if isinstance(arguments_str, str):
                try:
                    arguments = json.loads(arguments_str)
                    logger.debug(f"  âœ… JSONè§£ææˆåŠŸ: {arguments}")
                except json.JSONDecodeError as je:
                    logger.error(f"  âŒ JSONè§£æå¤±è´¥: {je}")
                    logger.error(f"  åŸå§‹å­—ç¬¦ä¸²: '{arguments_str}'")
                    raise ValueError(f"å‚æ•°JSONè§£æå¤±è´¥: {je}")
            else:
                arguments = arguments_str
                logger.debug(f"  ç›´æ¥ä½¿ç”¨dictç±»å‹å‚æ•°")
            
            logger.info(
                f"æ‰§è¡Œå·¥å…·: {plugin_name}.{tool_name}, "
                f"å‚æ•°: {arguments}"
            )
            
            # âœ… ä½¿ç”¨å¸¦é‡è¯•çš„è°ƒç”¨
            tool_key = f"{plugin_name}.{tool_name}"
            start_time = time.time()
            
            try:
                result = await self._call_tool_with_retry(
                    user_id=user_id,
                    plugin_name=plugin_name,
                    tool_name=tool_name,
                    arguments=arguments,
                    timeout=timeout
                )
                
                # è®°å½•æˆåŠŸæŒ‡æ ‡
                duration_ms = (time.time() - start_time) * 1000
                self._metrics[tool_key].update_success(duration_ms)
                
                logger.info(
                    f"âœ… å·¥å…·è°ƒç”¨æˆåŠŸ: {tool_key} "
                    f"(è€—æ—¶: {duration_ms:.2f}ms)"
                )
                
                # æˆåŠŸè¿”å›
                return {
                    "tool_call_id": tool_call_id,
                    "role": "tool",
                    "name": function_name,
                    "content": json.dumps(result, ensure_ascii=False),
                    "success": True,
                    "error": None
                }
                
            except asyncio.TimeoutError:
                # è®°å½•å¤±è´¥æŒ‡æ ‡
                duration_ms = (time.time() - start_time) * 1000
                self._metrics[tool_key].update_failure(duration_ms)
                raise MCPToolServiceError(
                    f"å·¥å…·è°ƒç”¨è¶…æ—¶ï¼ˆ>{timeout}ç§’ï¼‰"
                )
        
        except Exception as e:
            # è®°å½•å¤±è´¥æŒ‡æ ‡
            tool_key = f"{plugin_name}.{tool_name}" if 'plugin_name' in locals() else function_name
            duration_ms = (time.time() - start_time) * 1000
            self._metrics[tool_key].update_failure(duration_ms)
            
            logger.error(
                f"âŒ å·¥å…· {function_name} è°ƒç”¨å¤±è´¥: {e}",
                exc_info=True
            )
            return {
                "tool_call_id": tool_call_id,
                "role": "tool",
                "name": function_name,
                "content": f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}",
                "success": False,
                "error": str(e)
            }
    
    async def _call_tool_with_retry(
        self,
        user_id: str,
        plugin_name: str,
        tool_name: str,
        arguments: Dict[str, Any],
        timeout: float
    ) -> Any:
        """
        å¸¦æŒ‡æ•°é€€é¿é‡è¯•çš„å·¥å…·è°ƒç”¨
        
        Args:
            user_id: ç”¨æˆ·ID
            plugin_name: æ’ä»¶åç§°
            tool_name: å·¥å…·åç§°
            arguments: å·¥å…·å‚æ•°
            timeout: è¶…æ—¶æ—¶é—´
            
        Returns:
            å·¥å…·æ‰§è¡Œç»“æœ
            
        Raises:
            MCPToolServiceError: å·¥å…·è°ƒç”¨å¤±è´¥
            asyncio.TimeoutError: è°ƒç”¨è¶…æ—¶
        """
        last_exception = None
        
        for attempt in range(self._max_retries):
            try:
                # å°è¯•è°ƒç”¨å·¥å…·
                result = await asyncio.wait_for(
                    mcp_registry.call_tool(
                        user_id=user_id,
                        plugin_name=plugin_name,
                        tool_name=tool_name,
                        arguments=arguments
                    ),
                    timeout=timeout
                )
                
                # æˆåŠŸåˆ™è¿”å›
                if attempt > 0:
                    logger.info(
                        f"âœ… é‡è¯•æˆåŠŸ: {plugin_name}.{tool_name} "
                        f"(ç¬¬{attempt + 1}æ¬¡å°è¯•)"
                    )
                return result
                
            except asyncio.TimeoutError:
                # è¶…æ—¶ä¸é‡è¯•ï¼Œç›´æ¥æŠ›å‡º
                raise
                
            except Exception as e:
                last_exception = e
                
                # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
                if attempt == self._max_retries - 1:
                    logger.error(
                        f"âŒ é‡è¯•å¤±è´¥: {plugin_name}.{tool_name} "
                        f"(å·²å°è¯•{self._max_retries}æ¬¡): {e}"
                    )
                    raise MCPToolServiceError(
                        f"å·¥å…·è°ƒç”¨å¤±è´¥ï¼ˆå·²é‡è¯•{self._max_retries}æ¬¡ï¼‰: {str(e)}"
                    )
                
                # è®¡ç®—æŒ‡æ•°é€€é¿å»¶è¿Ÿ
                delay = min(
                    self._base_retry_delay * (2 ** attempt),
                    self._max_retry_delay
                )
                
                logger.warning(
                    f"âš ï¸ å·¥å…·è°ƒç”¨å¤±è´¥ï¼Œ{delay:.1f}ç§’åé‡è¯• "
                    f"(ç¬¬{attempt + 1}/{self._max_retries}æ¬¡): "
                    f"{plugin_name}.{tool_name} - {e}"
                )
                
                await asyncio.sleep(delay)
        
        # ç†è®ºä¸Šä¸ä¼šåˆ°è¿™é‡Œï¼Œä½†ä¸ºäº†ç±»å‹å®‰å…¨
        raise MCPToolServiceError(f"å·¥å…·è°ƒç”¨å¤±è´¥: {last_exception}")
    
    def get_metrics(self, tool_name: Optional[str] = None) -> Dict[str, Dict[str, Any]]:
        """
        è·å–å·¥å…·è°ƒç”¨æŒ‡æ ‡
        
        Args:
            tool_name: å·¥å…·åç§°ï¼ˆå¯é€‰ï¼Œè·å–ç‰¹å®šå·¥å…·çš„æŒ‡æ ‡ï¼‰
            
        Returns:
            æŒ‡æ ‡å­—å…¸
        """
        if tool_name:
            if tool_name in self._metrics:
                metric = self._metrics[tool_name]
                return {
                    tool_name: {
                        "total_calls": metric.total_calls,
                        "success_calls": metric.success_calls,
                        "failed_calls": metric.failed_calls,
                        "success_rate": metric.success_rate,
                        "avg_duration_ms": round(metric.avg_duration_ms, 2),
                        "last_call_time": metric.last_call_time.isoformat() if metric.last_call_time else None
                    }
                }
            return {}
        
        # è¿”å›æ‰€æœ‰å·¥å…·çš„æŒ‡æ ‡
        result = {}
        for tool_key, metric in self._metrics.items():
            result[tool_key] = {
                "total_calls": metric.total_calls,
                "success_calls": metric.success_calls,
                "failed_calls": metric.failed_calls,
                "success_rate": round(metric.success_rate, 3),
                "avg_duration_ms": round(metric.avg_duration_ms, 2),
                "last_call_time": metric.last_call_time.isoformat() if metric.last_call_time else None
            }
        return result
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        total_entries = len(self._tool_cache)
        total_hits = sum(entry.hit_count for entry in self._tool_cache.values())
        
        return {
            "total_entries": total_entries,
            "total_hits": total_hits,
            "cache_ttl_minutes": self._cache_ttl.total_seconds() / 60,
            "entries": [
                {
                    "key": key,
                    "tools_count": len(entry.tools),
                    "hit_count": entry.hit_count,
                    "expire_time": entry.expire_time.isoformat()
                }
                for key, entry in self._tool_cache.items()
            ]
        }
    
    async def build_tool_context(
        self,
        tool_results: List[Dict[str, Any]],
        format: str = "markdown"
    ) -> str:
        """
        å°†å·¥å…·è°ƒç”¨ç»“æœæ ¼å¼åŒ–ä¸ºä¸Šä¸‹æ–‡æ–‡æœ¬
        
        Args:
            tool_results: å·¥å…·è°ƒç”¨ç»“æœåˆ—è¡¨
            format: è¾“å‡ºæ ¼å¼ï¼ˆmarkdown/json/plainï¼‰
        
        Returns:
            æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        if not tool_results:
            return ""
        
        if format == "markdown":
            return self._build_markdown_context(tool_results)
        elif format == "json":
            return json.dumps(tool_results, ensure_ascii=False, indent=2)
        else:  # plain
            return self._build_plain_context(tool_results)
    
    def _build_markdown_context(
        self,
        tool_results: List[Dict[str, Any]]
    ) -> str:
        """æ„å»ºMarkdownæ ¼å¼çš„å·¥å…·ä¸Šä¸‹æ–‡"""
        lines = ["## ğŸ”§ å·¥å…·è°ƒç”¨ç»“æœ\n"]
        
        for i, result in enumerate(tool_results, 1):
            tool_name = result.get("name", "unknown")
            success = result.get("success", False)
            content = result.get("content", "")
            
            status_emoji = "âœ…" if success else "âŒ"
            lines.append(f"### {status_emoji} {i}. {tool_name}\n")
            
            if success:
                # å°è¯•ç¾åŒ–JSONå†…å®¹
                try:
                    content_obj = json.loads(content)
                    content = json.dumps(content_obj, ensure_ascii=False, indent=2)
                except:
                    pass
                lines.append(f"```json\n{content}\n```\n")
            else:
                lines.append(f"**é”™è¯¯**: {content}\n")
        
        return "\n".join(lines)
    
    def _build_plain_context(
        self,
        tool_results: List[Dict[str, Any]]
    ) -> str:
        """æ„å»ºçº¯æ–‡æœ¬æ ¼å¼çš„å·¥å…·ä¸Šä¸‹æ–‡"""
        lines = ["=== å·¥å…·è°ƒç”¨ç»“æœ ===\n"]
        
        for i, result in enumerate(tool_results, 1):
            tool_name = result.get("name", "unknown")
            success = result.get("success", False)
            content = result.get("content", "")
            
            status = "æˆåŠŸ" if success else "å¤±è´¥"
            lines.append(f"{i}. {tool_name} - {status}")
            lines.append(f"   ç»“æœ: {content}\n")
        
        return "\n".join(lines)


# å…¨å±€å•ä¾‹
mcp_tool_service = MCPToolService()