"""AIæœåŠ¡å°è£… - ç»Ÿä¸€çš„AIæ¥å£"""
from typing import Optional, AsyncGenerator, List, Dict, Any, Union

from app.config import settings as app_settings
from app.logger import get_logger
from app.services.ai_config import AIClientConfig, default_config
from app.services.ai_clients.openai_client import OpenAIClient
from app.services.ai_clients.anthropic_client import AnthropicClient
from app.services.ai_clients.gemini_client import GeminiClient
from app.services.ai_clients.base_client import cleanup_all_clients
from app.services.ai_providers.openai_provider import OpenAIProvider
from app.services.ai_providers.anthropic_provider import AnthropicProvider
from app.services.ai_providers.gemini_provider import GeminiProvider
from app.services.ai_providers.base_provider import BaseAIProvider
from app.services.json_helper import clean_json_response, parse_json
from app.mcp.adapters.universal import universal_mcp_adapter

# å¯¼å‡ºæ¸…ç†å‡½æ•°
cleanup_http_clients = cleanup_all_clients

logger = get_logger(__name__)


class AIService:
    """AIæœåŠ¡ç»Ÿä¸€æ¥å£"""

    def __init__(
        self,
        api_provider: Optional[str] = None,
        api_key: Optional[str] = None,
        api_base_url: Optional[str] = None,
        default_model: Optional[str] = None,
        default_temperature: Optional[float] = None,
        default_max_tokens: Optional[int] = None,
        default_system_prompt: Optional[str] = None,
        enable_mcp_adapter: bool = True,
        config: Optional[AIClientConfig] = None,
    ):
        self.api_provider = api_provider or app_settings.default_ai_provider
        self.default_model = default_model or app_settings.default_model
        self.default_temperature = default_temperature or app_settings.default_temperature
        self.default_max_tokens = default_max_tokens or app_settings.default_max_tokens
        self.default_system_prompt = default_system_prompt
        self.config = config or default_config
        
        self.mcp_adapter = universal_mcp_adapter if enable_mcp_adapter else None
        
        self._openai_provider: Optional[OpenAIProvider] = None
        self._anthropic_provider: Optional[AnthropicProvider] = None
        self._gemini_provider: Optional[GeminiProvider] = None
        
        # åˆå§‹åŒ– OpenAI
        openai_key = api_key if api_provider == "openai" else app_settings.openai_api_key
        if openai_key:
            base_url = api_base_url if api_provider == "openai" else app_settings.openai_base_url
            client = OpenAIClient(openai_key, base_url or "https://api.openai.com/v1", self.config)
            self._openai_provider = OpenAIProvider(client)
        
        # åˆå§‹åŒ– Anthropic
        anthropic_key = api_key if api_provider == "anthropic" else app_settings.anthropic_api_key
        if anthropic_key:
            base_url = api_base_url if api_provider == "anthropic" else app_settings.anthropic_base_url
            client = AnthropicClient(anthropic_key, base_url, self.config)
            self._anthropic_provider = AnthropicProvider(client)
        
        # åˆå§‹åŒ– Gemini
        if api_provider == "gemini" and api_key:
            client = GeminiClient(api_key, api_base_url, self.config)
            self._gemini_provider = GeminiProvider(client)

    def _get_provider(self, provider: Optional[str] = None) -> BaseAIProvider:
        """è·å–å¯¹åº”çš„ Provider"""
        p = provider or self.api_provider
        if p == "openai" and self._openai_provider:
            return self._openai_provider
        if p == "anthropic" and self._anthropic_provider:
            return self._anthropic_provider
        if p == "gemini" and self._gemini_provider:
            return self._gemini_provider
        raise ValueError(f"Provider {p} æœªåˆå§‹åŒ–")

    async def generate_text(
        self,
        prompt: str,
        provider: Optional[str] = None,
        model: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        system_prompt: Optional[str] = None,
        tools: Optional[List[Dict]] = None,
        tool_choice: Optional[str] = None,
    ) -> Dict[str, Any]:
        """ç”Ÿæˆæ–‡æœ¬"""
        prov = self._get_provider(provider)
        return await prov.generate(
            prompt=prompt,
            model=model or self.default_model,
            temperature=temperature or self.default_temperature,
            max_tokens=max_tokens or self.default_max_tokens,
            system_prompt=system_prompt or self.default_system_prompt,
            tools=tools,
            tool_choice=tool_choice,
        )

    async def generate_text_stream(
        self,
        prompt: str,
        provider: Optional[str] = None,
        model: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        system_prompt: Optional[str] = None,
    ) -> AsyncGenerator[str, None]:
        """æµå¼ç”Ÿæˆ"""
        prov = self._get_provider(provider)
        async for chunk in prov.generate_stream(
            prompt=prompt,
            model=model or self.default_model,
            temperature=temperature or self.default_temperature,
            max_tokens=max_tokens or self.default_max_tokens,
            system_prompt=system_prompt or self.default_system_prompt,
        ):
            yield chunk

    async def call_with_json_retry(
        self,
        prompt: str,
        system_prompt: Optional[str] = None,
        max_retries: int = 3,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        provider: Optional[str] = None,
        model: Optional[str] = None,
        expected_type: Optional[str] = None,
    ) -> Union[Dict, List]:
        """å¸¦é‡è¯•çš„ JSON è°ƒç”¨"""
        last_response = ""
        
        for attempt in range(1, max_retries + 1):
            current_prompt = prompt if attempt == 1 else self._add_json_hint(prompt, last_response, attempt)
            
            result = await self.generate_text(
                prompt=current_prompt,
                provider=provider,
                model=model,
                temperature=temperature,
                max_tokens=max_tokens,
                system_prompt=system_prompt,
            )
            
            last_response = result.get("content", "")
            
            try:
                data = parse_json(last_response)
                if expected_type == "object" and not isinstance(data, dict):
                    raise ValueError("æœŸæœ›å¯¹è±¡")
                if expected_type == "array" and not isinstance(data, list):
                    raise ValueError("æœŸæœ›æ•°ç»„")
                return data
            except Exception as e:
                if attempt == max_retries:
                    raise ValueError(f"JSON è§£æå¤±è´¥: {e}")
        
        raise ValueError("JSON è°ƒç”¨å¤±è´¥")

    @staticmethod
    def _add_json_hint(prompt: str, failed: str, attempt: int) -> str:
        return f"{prompt}\n\nâš ï¸ ç¬¬{attempt}æ¬¡é‡è¯•ï¼Œè¯·è¿”å›çº¯JSONï¼Œä¸è¦markdownåŒ…è£¹ã€‚ä¸Šæ¬¡é”™è¯¯: {failed[:200]}..."

    @staticmethod
    def _clean_json_response(text: str) -> str:
        """æ¸…æ´— JSON å“åº”"""
        return clean_json_response(text)

    async def generate_text_with_mcp(
        self,
        prompt: str,
        user_id: str,
        db_session,
        enable_mcp: bool = True,
        max_tool_rounds: int = 3,
        tool_choice: str = "auto",
        **kwargs
    ) -> Dict[str, Any]:
        """æ”¯æŒMCPå·¥å…·çš„AIæ–‡æœ¬ç”Ÿæˆ"""
        from app.services.mcp_tool_service import mcp_tool_service, MCPToolServiceError
        
        result = {"content": "", "tool_calls_made": 0, "tools_used": [], "finish_reason": "", "mcp_enhanced": False}
        tools = None
        
        if enable_mcp:
            try:
                tools = await mcp_tool_service.get_user_enabled_tools(user_id=user_id, db_session=db_session)
                if tools:
                    result["mcp_enhanced"] = True
            except MCPToolServiceError:
                tools = None
        
        original_prompt = prompt  # ä¿å­˜åŸå§‹æç¤ºè¯
        
        for round_num in range(max_tool_rounds):
            logger.debug(f"ğŸ”„ MCPå·¥å…·è°ƒç”¨ - ç¬¬{round_num+1}/{max_tool_rounds}è½®")
            logger.debug(f"   prompté•¿åº¦: {len(prompt)}, toolsæ•°é‡: {len(tools) if tools else 0}, tool_choice: {tool_choice}")
            
            ai_response = await self.generate_text(prompt=prompt, tools=tools, tool_choice=tool_choice, **kwargs)
            logger.debug(f"   AIå“åº”: finish_reason={ai_response.get('finish_reason')}, contenté•¿åº¦={len(ai_response.get('content', ''))}")
            
            tool_calls = ai_response.get("tool_calls", [])
            
            if not tool_calls:
                content = ai_response.get("content", "")
                result["content"] = content
                result["finish_reason"] = ai_response.get("finish_reason", "stop")
                logger.debug(f"   âœ… æ— å·¥å…·è°ƒç”¨ï¼Œè¿”å›å†…å®¹é•¿åº¦: {len(content)}")
                
                # ğŸ”§ ä¿®å¤ï¼šå¦‚æœå†…å®¹ä¸ºç©ºä¸”å·²ç»è°ƒç”¨è¿‡å·¥å…·ï¼Œå¼ºåˆ¶è¦æ±‚AIç»™å‡ºç­”æ¡ˆ
                if not content.strip() and result["tool_calls_made"] > 0:
                    logger.warning(f"âš ï¸ AIåœ¨å·¥å…·è°ƒç”¨åè¿”å›ç©ºå†…å®¹ï¼Œå°è¯•å¼ºåˆ¶è¦æ±‚å›ç­”ï¼ˆç¬¬{round_num+1}è½®ï¼‰")
                    prompt = f"{prompt}\n\nâš ï¸ è¯·æ³¨æ„ï¼šä½ å¿…é¡»åŸºäºä»¥ä¸Šå·¥å…·æŸ¥è¯¢ç»“æœï¼Œç»™å‡ºå®Œæ•´çš„å›ç­”ã€‚ä¸è¦è¿”å›ç©ºå†…å®¹ã€‚"
                    tools = None
                    tool_choice = "none"  # å¼ºåˆ¶ä¸ä½¿ç”¨å·¥å…·
                    continue
                
                break
            
            logger.info(f"ğŸ”§ æ£€æµ‹åˆ° {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")
            for idx, tc in enumerate(tool_calls):
                logger.debug(f"   å·¥å…·{idx+1}: {tc.get('function', {}).get('name')} - å‚æ•°: {tc.get('function', {}).get('arguments')}")
            
            try:
                logger.debug(f"   å¼€å§‹æ‰§è¡Œå·¥å…·è°ƒç”¨...")
                tool_results = await mcp_tool_service.execute_tool_calls(user_id=user_id, tool_calls=tool_calls, db_session=db_session)
                logger.debug(f"   å·¥å…·æ‰§è¡Œå®Œæˆï¼Œç»“æœæ•°é‡: {len(tool_results)}")
                
                # ğŸ” æ£€æŸ¥å·¥å…·ç»“æœ
                for idx, tr in enumerate(tool_results):
                    success = tr.get("success", False)
                    content_preview = tr.get("content", "")[:200] if tr.get("content") else "None"
                    logger.debug(f"   å·¥å…·ç»“æœ[{idx}]: success={success}, contenté¢„è§ˆ={content_preview}")
                
                for tc in tool_calls:
                    name = tc["function"]["name"]
                    if name not in result["tools_used"]:
                        result["tools_used"].append(name)
                result["tool_calls_made"] += len(tool_calls)
                
                tool_context = await mcp_tool_service.build_tool_context(tool_results, format="markdown")
                logger.debug(f"   å·¥å…·ä¸Šä¸‹æ–‡é•¿åº¦: {len(tool_context)}")
                logger.debug(f"   å·¥å…·ä¸Šä¸‹æ–‡é¢„è§ˆ: {tool_context[:300] if len(tool_context) > 300 else tool_context}")
                
                # ğŸ”§ æ”¹è¿›ï¼šåœ¨æœ€åä¸€è½®æ—¶ï¼Œæ˜ç¡®è¦æ±‚AIç»™å‡ºå®Œæ•´ç­”æ¡ˆ
                if round_num == max_tool_rounds - 1:
                    logger.info(f"âš ï¸ æœ€åä¸€è½®ï¼Œå¼ºåˆ¶è¦æ±‚AIç»™å‡ºæœ€ç»ˆç­”æ¡ˆ")
                    prompt = f"{original_prompt}\n\n{tool_context}\n\nâš ï¸ é‡è¦ï¼šè¿™æ˜¯æœ€åä¸€è½®ï¼Œè¯·åŸºäºä»¥ä¸Šå·¥å…·æŸ¥è¯¢çš„å‚è€ƒèµ„æ–™ï¼Œç»™å‡ºå®Œæ•´è¯¦ç»†çš„æœ€ç»ˆç­”æ¡ˆã€‚ä¸è¦å†è°ƒç”¨å·¥å…·ã€‚"
                    tool_choice = "none"
                else:
                    prompt = f"{original_prompt}\n\n{tool_context}\n\nè¯·åŸºäºä»¥ä¸Šå·¥å…·æŸ¥è¯¢ç»“æœï¼Œç»§ç»­å®Œæˆä»»åŠ¡ã€‚"
                    logger.debug(f"   æ–°prompté•¿åº¦: {len(prompt)}")
                
                tools = None  # å·¥å…·è°ƒç”¨åç¦ç”¨å·¥å…·åˆ—è¡¨ï¼Œé¿å…é‡å¤è°ƒç”¨
                logger.debug(f"   âœ… å·¥å…·è°ƒç”¨æˆåŠŸï¼Œå‡†å¤‡ä¸‹ä¸€è½®")
                
            except Exception as tool_error:
                logger.error(f"âŒ å·¥å…·è°ƒç”¨æ‰§è¡Œå¤±è´¥: {tool_error}", exc_info=True)
                logger.error(f"   é”™è¯¯ç±»å‹: {type(tool_error).__name__}")
                logger.error(f"   AIå“åº”å†…å®¹: {ai_response.get('content', '')[:200]}")
                result["content"] = ai_response.get("content", "")
                result["finish_reason"] = "tool_error"
                break
        
        return result


# å…¨å±€å®ä¾‹
ai_service = AIService()


def create_user_ai_service(
    api_provider: str,
    api_key: str,
    api_base_url: str,
    model_name: str,
    temperature: float,
    max_tokens: int,
    system_prompt: Optional[str] = None,
) -> AIService:
    """åˆ›å»ºç”¨æˆ· AI æœåŠ¡"""
    return AIService(
        api_provider=api_provider,
        api_key=api_key,
        api_base_url=api_base_url,
        default_model=model_name,
        default_temperature=temperature,
        default_max_tokens=max_tokens,
        default_system_prompt=system_prompt,
    )