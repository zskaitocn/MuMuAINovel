"""OpenAI å®¢æˆ·ç«¯"""
import json
from typing import Any, AsyncGenerator, Dict, Optional

from app.logger import get_logger
from .base_client import BaseAIClient

logger = get_logger(__name__)


class OpenAIClient(BaseAIClient):
    """OpenAI API å®¢æˆ·ç«¯"""

    def _build_headers(self) -> Dict[str, str]:
        return {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }

    def _build_payload(
        self,
        messages: list,
        model: str,
        temperature: float,
        max_tokens: int,
        tools: Optional[list] = None,
        tool_choice: Optional[str] = None,
        stream: bool = False,
    ) -> Dict[str, Any]:
        payload = {
            "model": model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
        }
        if stream:
            payload["stream"] = True
        if tools:
            # æ¸…ç† $schema å­—æ®µ
            cleaned = []
            for t in tools:
                tc = t.copy()
                if "function" in tc and "parameters" in tc["function"]:
                    tc["function"]["parameters"] = {
                        k: v for k, v in tc["function"]["parameters"].items() if k != "$schema"
                    }
                cleaned.append(tc)
            payload["tools"] = cleaned
            if tool_choice:
                payload["tool_choice"] = tool_choice
        return payload

    async def chat_completion(
        self,
        messages: list,
        model: str,
        temperature: float,
        max_tokens: int,
        tools: Optional[list] = None,
        tool_choice: Optional[str] = None,
    ) -> Dict[str, Any]:
        payload = self._build_payload(messages, model, temperature, max_tokens, tools, tool_choice)
        
        logger.debug(f"ğŸ“¤ OpenAI è¯·æ±‚ payload: {json.dumps(payload, ensure_ascii=False, indent=2)}")
        
        data = await self._request_with_retry("POST", "/chat/completions", payload)
        
        # è°ƒè¯•æ—¥å¿—ï¼šè¾“å‡ºåŸå§‹å“åº”
        logger.debug(f"ğŸ“¥ OpenAI åŸå§‹å“åº”: {json.dumps(data, ensure_ascii=False, indent=2)}")

        choices = data.get("choices", [])
        if not choices or len(choices) == 0:
            raise ValueError("API è¿”å›ç©º choices æˆ– choices ä¸ºç©ºåˆ—è¡¨")

        choice = choices[0]
        message = choice.get("message", {})
        return {
            "content": message.get("content", ""),
            "tool_calls": message.get("tool_calls"),
            "finish_reason": choice.get("finish_reason"),
        }

    async def chat_completion_stream(
        self,
        messages: list,
        model: str,
        temperature: float,
        max_tokens: int,
    ) -> AsyncGenerator[str, None]:
        payload = self._build_payload(messages, model, temperature, max_tokens, stream=True)
        
        try:
            async with await self._request_with_retry("POST", "/chat/completions", payload, stream=True) as response:
                response.raise_for_status()
                try:
                    async for line in response.aiter_lines():
                        if line.startswith("data: "):
                            data_str = line[6:]
                            if data_str.strip() == "[DONE]":
                                break
                            try:
                                data = json.loads(data_str)
                                choices = data.get("choices", [])
                                if choices and len(choices) > 0:
                                    content = choices[0].get("delta", {}).get("content", "")
                                    if content:
                                        yield content
                            except json.JSONDecodeError:
                                continue
                except GeneratorExit:
                    # ç”Ÿæˆå™¨è¢«å…³é—­ï¼Œè¿™æ˜¯æ­£å¸¸çš„æ¸…ç†è¿‡ç¨‹
                    logger.debug("æµå¼å“åº”ç”Ÿæˆå™¨è¢«å…³é—­(GeneratorExit)")
                    raise
                except Exception as iter_error:
                    logger.error(f"æµå¼å“åº”è¿­ä»£å‡ºé”™: {str(iter_error)}")
                    raise
        except GeneratorExit:
            # é‡æ–°æŠ›å‡ºGeneratorExitï¼Œè®©è°ƒç”¨æ–¹å¤„ç†
            raise
        except Exception as e:
            logger.error(f"æµå¼è¯·æ±‚å‡ºé”™: {str(e)}")
            raise