"""é¡¹ç›®åˆ›å»ºå‘å¯¼æµå¼API - ä½¿ç”¨SSEé¿å…è¶…æ—¶"""
from fastapi import APIRouter, Depends, HTTPException, Request
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from typing import Dict, Any, AsyncGenerator
import json
import re

from app.database import get_db
from app.models.project import Project
from app.models.character import Character
from app.models.outline import Outline
from app.models.chapter import Chapter
from app.models.career import Career, CharacterCareer
from app.models.relationship import CharacterRelationship, Organization, OrganizationMember, RelationshipType
from app.models.writing_style import WritingStyle
from app.models.project_default_style import ProjectDefaultStyle
from app.services.ai_service import AIService
from app.services.prompt_service import prompt_service, PromptService
from app.services.plot_expansion_service import PlotExpansionService
from app.logger import get_logger
from app.utils.sse_response import SSEResponse, create_sse_response, WizardProgressTracker
from app.api.settings import get_user_ai_service

router = APIRouter(prefix="/wizard-stream", tags=["é¡¹ç›®åˆ›å»ºå‘å¯¼(æµå¼)"])
logger = get_logger(__name__)


async def world_building_generator(
    data: Dict[str, Any],
    db: AsyncSession,
    user_ai_service: AIService
) -> AsyncGenerator[str, None]:
    """ä¸–ç•Œæ„å»ºæµå¼ç”Ÿæˆå™¨ - æ”¯æŒMCPå·¥å…·å¢å¼º"""
    # æ ‡è®°æ•°æ®åº“ä¼šè¯æ˜¯å¦å·²æäº¤
    db_committed = False
    # åˆå§‹åŒ–æ ‡å‡†è¿›åº¦è¿½è¸ªå™¨
    tracker = WizardProgressTracker("ä¸–ç•Œè§‚")
    
    try:
        # å‘é€å¼€å§‹æ¶ˆæ¯
        yield await tracker.start()
        
        # æå–å‚æ•°
        title = data.get("title")
        description = data.get("description")
        theme = data.get("theme")
        genre = data.get("genre")
        narrative_perspective = data.get("narrative_perspective")
        target_words = data.get("target_words")
        chapter_count = data.get("chapter_count")
        character_count = data.get("character_count")
        outline_mode = data.get("outline_mode", "one-to-many")  # å¤§çº²æ¨¡å¼ï¼Œé»˜è®¤ä¸€å¯¹å¤š
        provider = data.get("provider")
        model = data.get("model")
        enable_mcp = data.get("enable_mcp", True)  # é»˜è®¤å¯ç”¨MCP
        user_id = data.get("user_id")  # ä»ä¸­é—´ä»¶æ³¨å…¥
        
        if not title or not description or not theme or not genre:
            yield await tracker.error("titleã€descriptionã€theme å’Œ genre æ˜¯å¿…éœ€çš„å‚æ•°", 400)
            return
        
        # è·å–åŸºç¡€æç¤ºè¯ï¼ˆæ”¯æŒè‡ªå®šä¹‰ï¼‰
        yield await tracker.preparing("å‡†å¤‡AIæç¤ºè¯...")
        template = await PromptService.get_template("WORLD_BUILDING", user_id, db)
        base_prompt = PromptService.format_prompt(
            template,
            title=title,
            theme=theme,
            genre=genre or "é€šç”¨ç±»å‹",
            description=description or "æš‚æ— ç®€ä»‹"
        )
        
        # è®¾ç½®ç”¨æˆ·ä¿¡æ¯ä»¥å¯ç”¨MCP
        if user_id:
            user_ai_service.user_id = user_id
            user_ai_service.db_session = db
        
        # ===== æµå¼ç”Ÿæˆä¸–ç•Œè§‚ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰ =====
        MAX_WORLD_RETRIES = 3  # æœ€å¤šé‡è¯•3æ¬¡
        world_retry_count = 0
        world_generation_success = False
        world_data = {}
        estimated_total = 1000
        
        while world_retry_count < MAX_WORLD_RETRIES and not world_generation_success:
            try:
                # é‡è¯•æ—¶é‡ç½®ç”Ÿæˆè¿›åº¦
                if world_retry_count > 0:
                    tracker.reset_generating_progress()
                
                yield await tracker.generating(
                    current_chars=0,
                    estimated_total=estimated_total,
                    retry_count=world_retry_count,
                    max_retries=MAX_WORLD_RETRIES
                )
                
                # æµå¼ç”Ÿæˆä¸–ç•Œè§‚
                accumulated_text = ""
                chunk_count = 0
                
                async for chunk in user_ai_service.generate_text_stream(
                    prompt=base_prompt,
                    provider=provider,
                    model=model,
                    tool_choice="required",
                ):
                    chunk_count += 1
                    accumulated_text += chunk
                    
                    # å‘é€å†…å®¹å—
                    yield await tracker.generating_chunk(chunk)
                    
                    # å®šæœŸæ›´æ–°è¿›åº¦
                    current_len = len(accumulated_text)
                    if chunk_count % 10 == 0:
                        yield await tracker.generating(
                            current_chars=current_len,
                            estimated_total=estimated_total,
                            retry_count=world_retry_count,
                            max_retries=MAX_WORLD_RETRIES
                        )
                    
                    # æ¯20ä¸ªå—å‘é€å¿ƒè·³
                    if chunk_count % 20 == 0:
                        yield await tracker.heartbeat()
                
                # æ£€æŸ¥æ˜¯å¦è¿”å›ç©ºå“åº”
                if not accumulated_text or not accumulated_text.strip():
                    logger.warning(f"âš ï¸ AIè¿”å›ç©ºä¸–ç•Œè§‚ï¼ˆå°è¯•{world_retry_count+1}/{MAX_WORLD_RETRIES}ï¼‰")
                    world_retry_count += 1
                    if world_retry_count < MAX_WORLD_RETRIES:
                        yield await tracker.retry(world_retry_count, MAX_WORLD_RETRIES, "AIè¿”å›ä¸ºç©º")
                        continue
                    else:
                        # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼
                        logger.error("âŒ ä¸–ç•Œè§‚ç”Ÿæˆå¤šæ¬¡è¿”å›ç©ºå“åº”")
                        world_data = {
                            "time_period": "AIå¤šæ¬¡è¿”å›ä¸ºç©ºï¼Œè¯·ç¨åé‡è¯•",
                            "location": "AIå¤šæ¬¡è¿”å›ä¸ºç©ºï¼Œè¯·ç¨åé‡è¯•",
                            "atmosphere": "AIå¤šæ¬¡è¿”å›ä¸ºç©ºï¼Œè¯·ç¨åé‡è¯•",
                            "rules": "AIå¤šæ¬¡è¿”å›ä¸ºç©ºï¼Œè¯·ç¨åé‡è¯•"
                        }
                        world_generation_success = True  # æ ‡è®°ä¸ºæˆåŠŸä»¥ç»§ç»­æµç¨‹
                        break
                
                # è§£æç»“æœ - ä½¿ç”¨ç»Ÿä¸€çš„JSONæ¸…æ´—æ–¹æ³•
                yield await tracker.parsing("è§£æä¸–ç•Œè§‚æ•°æ®...")
                
                try:
                    logger.info(f"ğŸ” å¼€å§‹æ¸…æ´—JSONï¼ŒåŸå§‹é•¿åº¦: {len(accumulated_text)}")
                    logger.info(f"   åŸå§‹å†…å®¹é¢„è§ˆ: {accumulated_text[:300]}...")
                    
                    # âœ… ä½¿ç”¨ AIService çš„ç»Ÿä¸€æ¸…æ´—æ–¹æ³•
                    cleaned_text = user_ai_service._clean_json_response(accumulated_text)
                    logger.info(f"âœ… JSONæ¸…æ´—å®Œæˆï¼Œæ¸…æ´—åé•¿åº¦: {len(cleaned_text)}")
                    logger.info(f"   æ¸…æ´—åé¢„è§ˆ: {cleaned_text[:300]}...")
                    
                    world_data = json.loads(cleaned_text)
                    logger.info(f"âœ… ä¸–ç•Œè§‚JSONè§£ææˆåŠŸï¼ˆå°è¯•{world_retry_count+1}/{MAX_WORLD_RETRIES}ï¼‰")
                    world_generation_success = True  # è§£ææˆåŠŸï¼Œæ ‡è®°å®Œæˆ
                            
                except json.JSONDecodeError as e:
                    logger.error(f"âŒ ä¸–ç•Œæ„å»ºJSONè§£æå¤±è´¥ï¼ˆå°è¯•{world_retry_count+1}/{MAX_WORLD_RETRIES}ï¼‰: {e}")
                    logger.error(f"   åŸå§‹å†…å®¹é•¿åº¦: {len(accumulated_text)}")
                    logger.error(f"   åŸå§‹å†…å®¹é¢„è§ˆ: {accumulated_text[:200]}")
                    world_retry_count += 1
                    if world_retry_count < MAX_WORLD_RETRIES:
                        yield await tracker.retry(world_retry_count, MAX_WORLD_RETRIES, "JSONè§£æå¤±è´¥")
                        continue
                    else:
                        # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼
                        world_data = {
                            "time_period": "AIè¿”å›æ ¼å¼é”™è¯¯ï¼Œè¯·é‡è¯•",
                            "location": "AIè¿”å›æ ¼å¼é”™è¯¯ï¼Œè¯·é‡è¯•",
                            "atmosphere": "AIè¿”å›æ ¼å¼é”™è¯¯ï¼Œè¯·é‡è¯•",
                            "rules": "AIè¿”å›æ ¼å¼é”™è¯¯ï¼Œè¯·é‡è¯•"
                        }
                        world_generation_success = True  # æ ‡è®°ä¸ºæˆåŠŸä»¥ç»§ç»­æµç¨‹
                        
            except Exception as e:
                logger.error(f"âŒ ä¸–ç•Œæ„å»ºç”Ÿæˆå¼‚å¸¸ï¼ˆå°è¯•{world_retry_count+1}/{MAX_WORLD_RETRIES}ï¼‰: {type(e).__name__}: {e}")
                world_retry_count += 1
                if world_retry_count < MAX_WORLD_RETRIES:
                    yield await tracker.retry(world_retry_count, MAX_WORLD_RETRIES, "ç”Ÿæˆå¼‚å¸¸")
                    continue
                else:
                    # æœ€åä¸€æ¬¡é‡è¯•ä»å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
                    logger.error(f"   accumulated_text é•¿åº¦: {len(accumulated_text) if 'accumulated_text' in locals() else 'N/A'}")
                    raise
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        yield await tracker.saving("ä¿å­˜ä¸–ç•Œè§‚åˆ°æ•°æ®åº“...")
        
        # ç¡®ä¿user_idå­˜åœ¨
        if not user_id:
            yield await SSEResponse.send_error("ç”¨æˆ·IDç¼ºå¤±ï¼Œæ— æ³•åˆ›å»ºé¡¹ç›®", 401)
            return
        
        project = Project(
            user_id=user_id,  # æ·»åŠ user_idå­—æ®µ
            title=title,
            description=description,
            theme=theme,
            genre=genre,
            world_time_period=world_data.get("time_period"),
            world_location=world_data.get("location"),
            world_atmosphere=world_data.get("atmosphere"),
            world_rules=world_data.get("rules"),
            narrative_perspective=narrative_perspective,
            target_words=target_words,
            chapter_count=chapter_count,
            character_count=character_count,
            outline_mode=outline_mode,  # è®¾ç½®å¤§çº²æ¨¡å¼
            wizard_status="incomplete",
            wizard_step=1,
            status="planning"
        )
        db.add(project)
        await db.commit()
        await db.refresh(project)
        
        # è‡ªåŠ¨è®¾ç½®é»˜è®¤å†™ä½œé£æ ¼ä¸ºç¬¬ä¸€ä¸ªå…¨å±€é¢„è®¾é£æ ¼
        try:
            result = await db.execute(
                select(WritingStyle).where(
                    WritingStyle.user_id.is_(None),
                    WritingStyle.order_index == 1
                ).limit(1)
            )
            first_style = result.scalar_one_or_none()
            
            if first_style:
                default_style = ProjectDefaultStyle(
                    project_id=project.id,
                    style_id=first_style.id
                )
                db.add(default_style)
                await db.commit()
                logger.info(f"ä¸ºé¡¹ç›® {project.id} è‡ªåŠ¨è®¾ç½®é»˜è®¤é£æ ¼: {first_style.name}")
            else:
                logger.warning(f"æœªæ‰¾åˆ°order_index=1çš„å…¨å±€é¢„è®¾é£æ ¼ï¼Œé¡¹ç›® {project.id} æœªè®¾ç½®é»˜è®¤é£æ ¼")
        except Exception as e:
            logger.warning(f"è®¾ç½®é»˜è®¤å†™ä½œé£æ ¼å¤±è´¥: {e}ï¼Œä¸å½±å“é¡¹ç›®åˆ›å»º")
        
        # æ›´æ–°å‘å¯¼æ­¥éª¤çŠ¶æ€ä¸º1ï¼ˆä¸–ç•Œè§‚å·²å®Œæˆï¼‰
        # wizard_step: 0=æœªå¼€å§‹, 1=ä¸–ç•Œè§‚å·²å®Œæˆ, 2=èŒä¸šä½“ç³»å·²å®Œæˆ, 3=è§’è‰²å·²å®Œæˆ, 4=å¤§çº²å·²å®Œæˆ
        project.wizard_step = 1
        await db.commit()
        
        # ===== ä¸–ç•Œè§‚ç”Ÿæˆå®Œæˆ =====
        db_committed = True
        
        yield await tracker.complete()
        
        # å‘é€ä¸–ç•Œè§‚ç»“æœ
        yield await tracker.result({
            "project_id": project.id,
            "time_period": world_data.get("time_period"),
            "location": world_data.get("location"),
            "atmosphere": world_data.get("atmosphere"),
            "rules": world_data.get("rules")
        })
        
        # å‘é€ä¸–ç•Œè§‚å®Œæˆä¿¡å·
        yield await tracker.done()
        
        logger.info(f"âœ… ä¸–ç•Œè§‚ç”Ÿæˆå®Œæˆï¼Œé¡¹ç›®ID: {project.id}")
        
    except GeneratorExit:
        # SSEè¿æ¥æ–­å¼€ï¼Œå›æ»šæœªæäº¤çš„äº‹åŠ¡
        logger.warning("ä¸–ç•Œæ„å»ºç”Ÿæˆå™¨è¢«æå‰å…³é—­")
        if not db_committed and db.in_transaction():
            await db.rollback()
            logger.info("ä¸–ç•Œæ„å»ºäº‹åŠ¡å·²å›æ»šï¼ˆGeneratorExitï¼‰")
    except Exception as e:
        logger.error(f"ä¸–ç•Œæ„å»ºæµå¼ç”Ÿæˆå¤±è´¥: {str(e)}")
        # å¼‚å¸¸æ—¶å›æ»šäº‹åŠ¡
        if not db_committed and db.in_transaction():
            await db.rollback()
            logger.info("ä¸–ç•Œæ„å»ºäº‹åŠ¡å·²å›æ»šï¼ˆå¼‚å¸¸ï¼‰")
        yield await tracker.error(f"ç”Ÿæˆå¤±è´¥: {str(e)}")


@router.post("/world-building", summary="æµå¼ç”Ÿæˆä¸–ç•Œæ„å»º")
async def generate_world_building_stream(
    request: Request,
    data: Dict[str, Any],
    db: AsyncSession = Depends(get_db),
    user_ai_service: AIService = Depends(get_user_ai_service)
):
    """
    ä½¿ç”¨SSEæµå¼ç”Ÿæˆä¸–ç•Œæ„å»ºï¼Œé¿å…è¶…æ—¶
    å‰ç«¯ä½¿ç”¨EventSourceæ¥æ”¶å®æ—¶è¿›åº¦å’Œç»“æœ
    """
    # ä»ä¸­é—´ä»¶æ³¨å…¥user_idåˆ°dataä¸­
    if hasattr(request.state, 'user_id'):
        data['user_id'] = request.state.user_id
    
    return create_sse_response(world_building_generator(data, db, user_ai_service))


async def career_system_generator(
    data: Dict[str, Any],
    db: AsyncSession,
    user_ai_service: AIService
) -> AsyncGenerator[str, None]:
    """èŒä¸šä½“ç³»ç”Ÿæˆæµå¼ç”Ÿæˆå™¨ - ç‹¬ç«‹æ¥å£"""
    db_committed = False
    # åˆå§‹åŒ–æ ‡å‡†è¿›åº¦è¿½è¸ªå™¨
    tracker = WizardProgressTracker("èŒä¸šä½“ç³»")
    
    try:
        yield await tracker.start()
        
        # æå–å‚æ•°
        project_id = data.get("project_id")
        provider = data.get("provider")
        model = data.get("model")
        user_id = data.get("user_id")
        
        if not project_id:
            yield await tracker.error("project_id æ˜¯å¿…éœ€çš„å‚æ•°", 400)
            return
        
        # è·å–é¡¹ç›®ä¿¡æ¯
        yield await tracker.loading("åŠ è½½é¡¹ç›®ä¿¡æ¯...")
        result = await db.execute(
            select(Project).where(Project.id == project_id)
        )
        project = result.scalar_one_or_none()
        if not project:
            yield await tracker.error("é¡¹ç›®ä¸å­˜åœ¨", 404)
            return
        
        # è®¾ç½®ç”¨æˆ·ä¿¡æ¯ä»¥å¯ç”¨MCP
        if user_id:
            user_ai_service.user_id = user_id
            user_ai_service.db_session = db
        
        # è·å–ä¸–ç•Œè§‚æ•°æ®
        world_data = {
            "time_period": project.world_time_period or "æœªè®¾å®š",
            "location": project.world_location or "æœªè®¾å®š",
            "atmosphere": project.world_atmosphere or "æœªè®¾å®š",
            "rules": project.world_rules or "æœªè®¾å®š"
        }
        
        # è·å–èŒä¸šç”Ÿæˆæç¤ºè¯æ¨¡æ¿ï¼ˆæ”¯æŒç”¨æˆ·è‡ªå®šä¹‰ï¼‰
        yield await tracker.preparing("å‡†å¤‡AIæç¤ºè¯...")
        template = await PromptService.get_template("CAREER_SYSTEM_GENERATION", user_id, db)
        career_prompt = PromptService.format_prompt(
            template,
            title=project.title,
            genre=project.genre or 'æœªè®¾å®š',
            theme=project.theme or 'æœªè®¾å®š',
            time_period=world_data.get('time_period', 'æœªè®¾å®š'),
            location=world_data.get('location', 'æœªè®¾å®š'),
            atmosphere=world_data.get('atmosphere', 'æœªè®¾å®š'),
            rules=world_data.get('rules', 'æœªè®¾å®š')
        )
        
        estimated_total = 5000
        MAX_CAREER_RETRIES = 3  # æœ€å¤šé‡è¯•3æ¬¡
        career_retry_count = 0
        career_generation_success = False
        
        while career_retry_count < MAX_CAREER_RETRIES and not career_generation_success:
            try:
                # é‡è¯•æ—¶é‡ç½®ç”Ÿæˆè¿›åº¦
                if career_retry_count > 0:
                    tracker.reset_generating_progress()
                
                yield await tracker.generating(
                    current_chars=0,
                    estimated_total=estimated_total,
                    retry_count=career_retry_count,
                    max_retries=MAX_CAREER_RETRIES
                )
                
                # ä½¿ç”¨æµå¼ç”ŸæˆèŒä¸šä½“ç³»
                career_response = ""
                chunk_count = 0
                
                async for chunk in user_ai_service.generate_text_stream(
                    prompt=career_prompt,
                    provider=provider,
                    model=model,
                ):
                    chunk_count += 1
                    career_response += chunk
                    
                    # å‘é€å†…å®¹å—
                    yield await tracker.generating_chunk(chunk)
                    
                    # å®šæœŸæ›´æ–°è¿›åº¦
                    current_len = len(career_response)
                    if chunk_count % 10 == 0:
                        yield await tracker.generating(
                            current_chars=current_len,
                            estimated_total=estimated_total,
                            retry_count=career_retry_count,
                            max_retries=MAX_CAREER_RETRIES
                        )
                    
                    # æ¯20ä¸ªå—å‘é€å¿ƒè·³
                    if chunk_count % 20 == 0:
                        yield await tracker.heartbeat()
                
                if not career_response or not career_response.strip():
                    logger.warning(f"âš ï¸ AIè¿”å›ç©ºèŒä¸šä½“ç³»ï¼ˆå°è¯•{career_retry_count+1}/{MAX_CAREER_RETRIES}ï¼‰")
                    career_retry_count += 1
                    if career_retry_count < MAX_CAREER_RETRIES:
                        yield await tracker.retry(career_retry_count, MAX_CAREER_RETRIES, "AIè¿”å›ä¸ºç©º")
                        continue
                    else:
                        yield await tracker.error("èŒä¸šä½“ç³»ç”Ÿæˆå¤±è´¥ï¼ˆAIå¤šæ¬¡è¿”å›ä¸ºç©ºï¼‰")
                        return
                
                yield await tracker.parsing("è§£æèŒä¸šä½“ç³»æ•°æ®...")
                
                # æ¸…æ´—å¹¶è§£æJSON
                try:
                    cleaned_response = user_ai_service._clean_json_response(career_response)
                    career_data = json.loads(cleaned_response)
                    logger.info(f"âœ… èŒä¸šä½“ç³»JSONè§£ææˆåŠŸï¼ˆå°è¯•{career_retry_count+1}/{MAX_CAREER_RETRIES}ï¼‰")
                    
                    yield await tracker.saving("ä¿å­˜èŒä¸šæ•°æ®...")
                    
                    # ä¿å­˜ä¸»èŒä¸š
                    main_careers_created = []
                    for idx, career_info in enumerate(career_data.get("main_careers", [])):
                        try:
                            stages_json = json.dumps(career_info.get("stages", []), ensure_ascii=False)
                            attribute_bonuses = career_info.get("attribute_bonuses")
                            attribute_bonuses_json = json.dumps(attribute_bonuses, ensure_ascii=False) if attribute_bonuses else None
                            
                            career = Career(
                                project_id=project.id,
                                name=career_info.get("name", f"æœªå‘½åä¸»èŒä¸š{idx+1}"),
                                type="main",
                                description=career_info.get("description"),
                                category=career_info.get("category"),
                                stages=stages_json,
                                max_stage=career_info.get("max_stage", 10),
                                requirements=career_info.get("requirements"),
                                special_abilities=career_info.get("special_abilities"),
                                worldview_rules=career_info.get("worldview_rules"),
                                attribute_bonuses=attribute_bonuses_json,
                                source="ai"
                            )
                            db.add(career)
                            await db.flush()
                            main_careers_created.append(career.name)
                            logger.info(f"  âœ… åˆ›å»ºä¸»èŒä¸šï¼š{career.name}")
                        except Exception as e:
                            logger.error(f"  âŒ åˆ›å»ºä¸»èŒä¸šå¤±è´¥ï¼š{str(e)}")
                            continue
                    
                    # ä¿å­˜å‰¯èŒä¸š
                    sub_careers_created = []
                    for idx, career_info in enumerate(career_data.get("sub_careers", [])):
                        try:
                            stages_json = json.dumps(career_info.get("stages", []), ensure_ascii=False)
                            attribute_bonuses = career_info.get("attribute_bonuses")
                            attribute_bonuses_json = json.dumps(attribute_bonuses, ensure_ascii=False) if attribute_bonuses else None
                            
                            career = Career(
                                project_id=project.id,
                                name=career_info.get("name", f"æœªå‘½åå‰¯èŒä¸š{idx+1}"),
                                type="sub",
                                description=career_info.get("description"),
                                category=career_info.get("category"),
                                stages=stages_json,
                                max_stage=career_info.get("max_stage", 5),
                                requirements=career_info.get("requirements"),
                                special_abilities=career_info.get("special_abilities"),
                                worldview_rules=career_info.get("worldview_rules"),
                                attribute_bonuses=attribute_bonuses_json,
                                source="ai"
                            )
                            db.add(career)
                            await db.flush()
                            sub_careers_created.append(career.name)
                            logger.info(f"  âœ… åˆ›å»ºå‰¯èŒä¸šï¼š{career.name}")
                        except Exception as e:
                            logger.error(f"  âŒ åˆ›å»ºå‰¯èŒä¸šå¤±è´¥ï¼š{str(e)}")
                            continue
                    
                    # æ›´æ–°å‘å¯¼æ­¥éª¤çŠ¶æ€ä¸º2ï¼ˆèŒä¸šä½“ç³»å·²å®Œæˆï¼‰
                    # wizard_step: 0=æœªå¼€å§‹, 1=ä¸–ç•Œè§‚å·²å®Œæˆ, 2=èŒä¸šä½“ç³»å·²å®Œæˆ, 3=è§’è‰²å·²å®Œæˆ, 4=å¤§çº²å·²å®Œæˆ
                    project.wizard_step = 2
                    
                    await db.commit()
                    db_committed = True
                    
                    # æ ‡è®°æˆåŠŸ
                    career_generation_success = True
                    logger.info(f"ğŸ‰ èŒä¸šä½“ç³»ç”Ÿæˆå®Œæˆï¼šä¸»èŒä¸š{len(main_careers_created)}ä¸ªï¼Œå‰¯èŒä¸š{len(sub_careers_created)}ä¸ª")
                    
                    yield await tracker.complete()
                    
                    # å‘é€ç»“æœ
                    yield await tracker.result({
                        "project_id": project.id,
                        "main_careers_count": len(main_careers_created),
                        "sub_careers_count": len(sub_careers_created),
                        "main_careers": main_careers_created,
                        "sub_careers": sub_careers_created
                    })
                    
                    yield await tracker.done()
                    
                except json.JSONDecodeError as e:
                    logger.error(f"âŒ èŒä¸šä½“ç³»JSONè§£æå¤±è´¥ï¼ˆå°è¯•{career_retry_count+1}/{MAX_CAREER_RETRIES}ï¼‰: {e}")
                    career_retry_count += 1
                    if career_retry_count < MAX_CAREER_RETRIES:
                        yield await tracker.retry(career_retry_count, MAX_CAREER_RETRIES, "JSONè§£æå¤±è´¥")
                        continue
                    else:
                        yield await tracker.error("èŒä¸šä½“ç³»è§£æå¤±è´¥ï¼ˆå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°ï¼‰")
                        return
                except Exception as e:
                    logger.error(f"âŒ èŒä¸šä½“ç³»ä¿å­˜å¤±è´¥ï¼ˆå°è¯•{career_retry_count+1}/{MAX_CAREER_RETRIES}ï¼‰: {e}")
                    career_retry_count += 1
                    if career_retry_count < MAX_CAREER_RETRIES:
                        yield await tracker.retry(career_retry_count, MAX_CAREER_RETRIES, "ä¿å­˜å¤±è´¥")
                        continue
                    else:
                        yield await tracker.error("èŒä¸šä½“ç³»ä¿å­˜å¤±è´¥ï¼ˆå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°ï¼‰")
                        return
            
            except Exception as e:
                logger.error(f"âŒ èŒä¸šä½“ç³»ç”Ÿæˆå¼‚å¸¸ï¼ˆå°è¯•{career_retry_count+1}/{MAX_CAREER_RETRIES}ï¼‰: {e}")
                career_retry_count += 1
                if career_retry_count < MAX_CAREER_RETRIES:
                    yield await tracker.retry(career_retry_count, MAX_CAREER_RETRIES, "ç”Ÿæˆå¼‚å¸¸")
                    continue
                else:
                    yield await tracker.error(f"èŒä¸šä½“ç³»ç”Ÿæˆå¤±è´¥: {str(e)}")
                    return
        
    except GeneratorExit:
        logger.warning("èŒä¸šä½“ç³»ç”Ÿæˆå™¨è¢«æå‰å…³é—­")
        if not db_committed and db.in_transaction():
            await db.rollback()
            logger.info("èŒä¸šä½“ç³»äº‹åŠ¡å·²å›æ»šï¼ˆGeneratorExitï¼‰")
    except Exception as e:
        logger.error(f"èŒä¸šä½“ç³»æµå¼ç”Ÿæˆå¤±è´¥: {str(e)}")
        if not db_committed and db.in_transaction():
            await db.rollback()
            logger.info("èŒä¸šä½“ç³»äº‹åŠ¡å·²å›æ»šï¼ˆå¼‚å¸¸ï¼‰")
        yield await tracker.error(f"ç”Ÿæˆå¤±è´¥: {str(e)}")


@router.post("/career-system", summary="æµå¼ç”ŸæˆèŒä¸šä½“ç³»")
async def generate_career_system_stream(
    request: Request,
    data: Dict[str, Any],
    db: AsyncSession = Depends(get_db),
    user_ai_service: AIService = Depends(get_user_ai_service)
):
    """
    ä½¿ç”¨SSEæµå¼ç”ŸæˆèŒä¸šä½“ç³»ï¼Œé¿å…è¶…æ—¶
    å‰ç«¯ä½¿ç”¨EventSourceæ¥æ”¶å®æ—¶è¿›åº¦å’Œç»“æœ
    """
    # ä»ä¸­é—´ä»¶æ³¨å…¥user_idåˆ°dataä¸­
    if hasattr(request.state, 'user_id'):
        data['user_id'] = request.state.user_id
    
    return create_sse_response(career_system_generator(data, db, user_ai_service))


async def characters_generator(
    data: Dict[str, Any],
    db: AsyncSession,
    user_ai_service: AIService
) -> AsyncGenerator[str, None]:
    """è§’è‰²æ‰¹é‡ç”Ÿæˆæµå¼ç”Ÿæˆå™¨ - ä¼˜åŒ–ç‰ˆ:åˆ†æ‰¹+é‡è¯•+MCPå·¥å…·å¢å¼º"""
    db_committed = False
    # åˆå§‹åŒ–æ ‡å‡†è¿›åº¦è¿½è¸ªå™¨
    tracker = WizardProgressTracker("è§’è‰²")
    
    try:
        yield await tracker.start()
        
        project_id = data.get("project_id")
        count = data.get("count", 5)
        world_context = data.get("world_context")
        theme = data.get("theme", "")
        genre = data.get("genre", "")
        requirements = data.get("requirements", "")
        provider = data.get("provider")
        model = data.get("model")
        enable_mcp = data.get("enable_mcp", True)  # é»˜è®¤å¯ç”¨MCP
        user_id = data.get("user_id")  # ä»ä¸­é—´ä»¶æ³¨å…¥
        
        # éªŒè¯é¡¹ç›®
        yield await tracker.loading("éªŒè¯é¡¹ç›®...", 0.3)
        result = await db.execute(
            select(Project).where(Project.id == project_id)
        )
        project = result.scalar_one_or_none()
        if not project:
            yield await tracker.error("é¡¹ç›®ä¸å­˜åœ¨", 404)
            return
        
        project.wizard_step = 2
        
        world_context = world_context or {
            "time_period": project.world_time_period or "æœªè®¾å®š",
            "location": project.world_location or "æœªè®¾å®š",
            "atmosphere": project.world_atmosphere or "æœªè®¾å®š",
            "rules": project.world_rules or "æœªè®¾å®š"
        }
        
        # è®¾ç½®ç”¨æˆ·ä¿¡æ¯ä»¥å¯ç”¨MCP
        if user_id:
            user_ai_service.user_id = user_id
            user_ai_service.db_session = db
        
        # è·å–é¡¹ç›®çš„èŒä¸šåˆ—è¡¨ï¼Œç”¨äºè§’è‰²èŒä¸šåˆ†é…
        yield await tracker.loading("åŠ è½½èŒä¸šä½“ç³»...", 0.8)
        career_result = await db.execute(
            select(Career).where(Career.project_id == project_id).order_by(Career.type, Career.id)
        )
        careers = career_result.scalars().all()
        
        main_careers = [c for c in careers if c.type == "main"]
        sub_careers = [c for c in careers if c.type == "sub"]
        
        # æ„å»ºèŒä¸šä¸Šä¸‹æ–‡
        careers_context = ""
        if main_careers or sub_careers:
            careers_context = "\n\nã€èŒä¸šä½“ç³»ã€‘\n"
            if main_careers:
                careers_context += "ä¸»èŒä¸šï¼š\n"
                for career in main_careers:
                    careers_context += f"- {career.name}: {career.description or 'æš‚æ— æè¿°'}\n"
            if sub_careers:
                careers_context += "\nå‰¯èŒä¸šï¼š\n"
                for career in sub_careers:
                    careers_context += f"- {career.name}: {career.description or 'æš‚æ— æè¿°'}\n"
            
            careers_context += "\nè¯·ä¸ºæ¯ä¸ªè§’è‰²åˆ†é…èŒä¸šï¼š\n"
            careers_context += "- æ¯ä¸ªè§’è‰²å¿…é¡»æœ‰1ä¸ªä¸»èŒä¸šï¼ˆä»ä¸Šè¿°ä¸»èŒä¸šä¸­é€‰æ‹©ï¼‰\n"
            careers_context += "- æ¯ä¸ªè§’è‰²å¯ä»¥æœ‰0-2ä¸ªå‰¯èŒä¸šï¼ˆä»ä¸Šè¿°å‰¯èŒä¸šä¸­é€‰æ‹©ï¼Œå¯é€‰ï¼‰\n"
            careers_context += "- ä¸»èŒä¸šåˆå§‹é˜¶æ®µå»ºè®®ä¸º1-3\n"
            careers_context += "- å‰¯èŒä¸šåˆå§‹é˜¶æ®µå»ºè®®ä¸º1-2\n"
            careers_context += "- è¯·åœ¨è¿”å›çš„JSONä¸­åŒ…å« career_assignment å­—æ®µï¼š\n"
            careers_context += '  {"main_career": "èŒä¸šåç§°", "main_stage": 2, "sub_careers": [{"career": "å‰¯èŒä¸šåç§°", "stage": 1}]}\n'
            logger.info(f"âœ… åŠ è½½äº†{len(main_careers)}ä¸ªä¸»èŒä¸šå’Œ{len(sub_careers)}ä¸ªå‰¯èŒä¸š")
        else:
            logger.warning("âš ï¸ é¡¹ç›®æ²¡æœ‰èŒä¸šä½“ç³»ï¼Œè·³è¿‡èŒä¸šåˆ†é…")
        
        # ä¼˜åŒ–çš„åˆ†æ‰¹ç­–ç•¥:æ¯æ‰¹ç”Ÿæˆ5ä¸ª,å¹³è¡¡æ•ˆç‡å’ŒæˆåŠŸç‡
        BATCH_SIZE = 5  # æ¯æ‰¹ç”Ÿæˆ5ä¸ªè§’è‰²
        MAX_RETRIES = 3  # æ¯æ‰¹æœ€å¤šé‡è¯•3æ¬¡
        all_characters = []
        total_batches = (count + BATCH_SIZE - 1) // BATCH_SIZE
        
        for batch_idx in range(total_batches):
            # ç²¾ç¡®è®¡ç®—å½“å‰æ‰¹æ¬¡åº”è¯¥ç”Ÿæˆçš„æ•°é‡
            remaining = count - len(all_characters)
            current_batch_size = min(BATCH_SIZE, remaining)
            
            # å¦‚æœå·²ç»è¾¾åˆ°ç›®æ ‡æ•°é‡,ç›´æ¥é€€å‡º
            if current_batch_size <= 0:
                logger.info(f"å·²ç”Ÿæˆ{len(all_characters)}ä¸ªè§’è‰²,è¾¾åˆ°ç›®æ ‡æ•°é‡{count}")
                break
            
            batch_progress = 15 + (batch_idx * 60 // total_batches)
            
            # é‡è¯•é€»è¾‘
            retry_count = 0
            batch_success = False
            batch_error_message = ""
            
            while retry_count < MAX_RETRIES and not batch_success:
                try:
                    # é‡è¯•æ—¶é‡ç½®ç”Ÿæˆè¿›åº¦
                    if retry_count > 0:
                        tracker.reset_generating_progress()
                    
                    yield await tracker.generating(
                        current_chars=0,
                        estimated_total=BATCH_SIZE * 800,
                        message=f"ç”Ÿæˆç¬¬{batch_idx+1}/{total_batches}æ‰¹è§’è‰² ({current_batch_size}ä¸ª)",
                        retry_count=retry_count,
                        max_retries=MAX_RETRIES
                    )
                    
                    # æ„å»ºæ‰¹æ¬¡è¦æ±‚ - åŒ…å«å·²ç”Ÿæˆè§’è‰²ä¿¡æ¯ä¿æŒè¿è´¯
                    existing_chars_context = ""
                    if all_characters:
                        existing_chars_context = "\n\nã€å·²ç”Ÿæˆçš„è§’è‰²ã€‘:\n"
                        for char in all_characters:
                            existing_chars_context += f"- {char.get('name')}: {char.get('role_type', 'æœªçŸ¥')}, {char.get('personality', 'æš‚æ— ')[:50]}...\n"
                        existing_chars_context += "\nè¯·ç¡®ä¿æ–°è§’è‰²ä¸å·²æœ‰è§’è‰²å½¢æˆåˆç†çš„å…³ç³»ç½‘ç»œå’Œäº’åŠ¨ã€‚\n"
                    
                    # æ„å»ºç²¾ç¡®çš„æ‰¹æ¬¡è¦æ±‚,æ˜ç¡®å‘Šè¯‰AIè¦ç”Ÿæˆçš„æ•°é‡
                    if batch_idx == 0:
                        if current_batch_size == 1:
                            batch_requirements = f"{requirements}\nè¯·ç”Ÿæˆ1ä¸ªä¸»è§’(protagonist)"
                        else:
                            batch_requirements = f"{requirements}\nè¯·ç²¾ç¡®ç”Ÿæˆ{current_batch_size}ä¸ªè§’è‰²:1ä¸ªä¸»è§’(protagonist)å’Œ{current_batch_size-1}ä¸ªæ ¸å¿ƒé…è§’(supporting)"
                    else:
                        batch_requirements = f"{requirements}\nè¯·ç²¾ç¡®ç”Ÿæˆ{current_batch_size}ä¸ªè§’è‰²{existing_chars_context}"
                        if batch_idx == total_batches - 1:
                            batch_requirements += "\nå¯ä»¥åŒ…å«ç»„ç»‡æˆ–åæ´¾(antagonist)"
                        else:
                            batch_requirements += "\nä¸»è¦æ˜¯é…è§’(supporting)å’Œåæ´¾(antagonist)"
                    
                    # è·å–è‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿
                    template = await PromptService.get_template("CHARACTERS_BATCH_GENERATION", user_id, db)
                    # æ„å»ºåŸºç¡€æç¤ºè¯
                    base_prompt = PromptService.format_prompt(
                        template,
                        count=current_batch_size,  # ä¼ é€’ç²¾ç¡®æ•°é‡
                        time_period=world_context.get("time_period", ""),
                        location=world_context.get("location", ""),
                        atmosphere=world_context.get("atmosphere", ""),
                        rules=world_context.get("rules", ""),
                        theme=theme or project.theme or "",
                        genre=genre or project.genre or "",
                        requirements=batch_requirements + careers_context  # æ·»åŠ èŒä¸šä¸Šä¸‹æ–‡
                    )
                    
                    prompt = base_prompt
                    
                    # æµå¼ç”Ÿæˆï¼ˆå¸¦å­—æ•°ç»Ÿè®¡ï¼‰
                    accumulated_text = ""
                    chunk_count = 0
                    
                    estimated_total = BATCH_SIZE * 800
                    
                    async for chunk in user_ai_service.generate_text_stream(
                        prompt=prompt,
                        provider=provider,
                        model=model,
                        tool_choice="required",
                    ):
                        chunk_count += 1
                        accumulated_text += chunk
                        
                        # å‘é€å†…å®¹å—
                        yield await tracker.generating_chunk(chunk)
                        
                        # å®šæœŸæ›´æ–°è¿›åº¦
                        current_len = len(accumulated_text)
                        if chunk_count % 10 == 0:
                            yield await tracker.generating(
                                current_chars=current_len,
                                estimated_total=estimated_total,
                                message=f"ç”Ÿæˆç¬¬{batch_idx+1}/{total_batches}æ‰¹è§’è‰²ä¸­",
                                retry_count=retry_count,
                                max_retries=MAX_RETRIES
                            )
                        
                        # æ¯20ä¸ªå—å‘é€å¿ƒè·³
                        if chunk_count % 20 == 0:
                            yield await tracker.heartbeat()
                    
                    # è§£ææ‰¹æ¬¡ç»“æœ - ä½¿ç”¨ç»Ÿä¸€çš„JSONæ¸…æ´—æ–¹æ³•
                    cleaned_text = user_ai_service._clean_json_response(accumulated_text)
                    characters_data = json.loads(cleaned_text)
                    if not isinstance(characters_data, list):
                        characters_data = [characters_data]
                    
                    # ä¸¥æ ¼éªŒè¯ç”Ÿæˆæ•°é‡æ˜¯å¦ç²¾ç¡®åŒ¹é…
                    if len(characters_data) != current_batch_size:
                        error_msg = f"æ‰¹æ¬¡{batch_idx+1}ç”Ÿæˆæ•°é‡ä¸æ­£ç¡®: æœŸæœ›{current_batch_size}ä¸ª, å®é™…{len(characters_data)}ä¸ª"
                        logger.error(error_msg)
                        
                        # å¦‚æœè¿˜æœ‰é‡è¯•æœºä¼šï¼Œç»§ç»­é‡è¯•
                        if retry_count < MAX_RETRIES - 1:
                            retry_count += 1
                            yield await tracker.retry(retry_count, MAX_RETRIES, error_msg)
                            continue
                        else:
                            # æœ€åä¸€æ¬¡é‡è¯•ä»å¤±è´¥ï¼Œç›´æ¥è¿”å›é”™è¯¯
                            yield await tracker.error(error_msg)
                            return
                    
                    all_characters.extend(characters_data)
                    batch_success = True
                    logger.info(f"æ‰¹æ¬¡{batch_idx+1}æˆåŠŸæ·»åŠ {len(characters_data)}ä¸ªè§’è‰²,å½“å‰æ€»æ•°{len(all_characters)}/{count}")
                    
                except json.JSONDecodeError as e:
                    logger.error(f"æ‰¹æ¬¡{batch_idx+1}è§£æå¤±è´¥(å°è¯•{retry_count+1}/{MAX_RETRIES}): {e}")
                    batch_error_message = f"JSONè§£æå¤±è´¥: {str(e)}"
                    retry_count += 1
                    if retry_count < MAX_RETRIES:
                        yield await tracker.retry(retry_count, MAX_RETRIES, "JSONè§£æå¤±è´¥")
                except Exception as e:
                    logger.error(f"æ‰¹æ¬¡{batch_idx+1}ç”Ÿæˆå¼‚å¸¸(å°è¯•{retry_count+1}/{MAX_RETRIES}): {e}")
                    batch_error_message = f"ç”Ÿæˆå¼‚å¸¸: {str(e)}"
                    retry_count += 1
                    if retry_count < MAX_RETRIES:
                        yield await tracker.retry(retry_count, MAX_RETRIES, "ç”Ÿæˆå¼‚å¸¸")
            
            # æ£€æŸ¥æ‰¹æ¬¡æ˜¯å¦æˆåŠŸ
            if not batch_success:
                error_msg = f"æ‰¹æ¬¡{batch_idx+1}åœ¨{MAX_RETRIES}æ¬¡é‡è¯•åä»ç„¶å¤±è´¥"
                if batch_error_message:
                    error_msg += f": {batch_error_message}"
                logger.error(error_msg)
                yield await tracker.error(error_msg)
                return
        
        # ä¿å­˜åˆ°æ•°æ®åº“ - åˆ†é˜¶æ®µå¤„ç†ä»¥ä¿è¯ä¸€è‡´æ€§
        yield await tracker.parsing("éªŒè¯è§’è‰²æ•°æ®...")
        
        # é¢„å¤„ç†ï¼šæ„å»ºæœ¬æ‰¹æ¬¡æ‰€æœ‰å®ä½“çš„åç§°é›†åˆ
        valid_entity_names = set()
        valid_organization_names = set()
        
        for char_data in all_characters:
            entity_name = char_data.get("name", "")
            if entity_name:
                valid_entity_names.add(entity_name)
                if char_data.get("is_organization", False):
                    valid_organization_names.add(entity_name)
        
        # æ¸…ç†å¹»è§‰å¼•ç”¨
        cleaned_count = 0
        for char_data in all_characters:
            # æ¸…ç†å…³ç³»æ•°ç»„ä¸­çš„æ— æ•ˆå¼•ç”¨
            if "relationships_array" in char_data and isinstance(char_data["relationships_array"], list):
                original_rels = char_data["relationships_array"]
                valid_rels = []
                for rel in original_rels:
                    target_name = rel.get("target_character_name", "")
                    if target_name in valid_entity_names:
                        valid_rels.append(rel)
                    else:
                        cleaned_count += 1
                        logger.debug(f"  ğŸ§¹ æ¸…ç†æ— æ•ˆå…³ç³»å¼•ç”¨ï¼š{char_data.get('name')} -> {target_name}")
                char_data["relationships_array"] = valid_rels
            
            # æ¸…ç†ç»„ç»‡æˆå‘˜å…³ç³»ä¸­çš„æ— æ•ˆå¼•ç”¨
            if "organization_memberships" in char_data and isinstance(char_data["organization_memberships"], list):
                original_orgs = char_data["organization_memberships"]
                valid_orgs = []
                for org_mem in original_orgs:
                    org_name = org_mem.get("organization_name", "")
                    if org_name in valid_organization_names:
                        valid_orgs.append(org_mem)
                    else:
                        cleaned_count += 1
                        logger.debug(f"  ğŸ§¹ æ¸…ç†æ— æ•ˆç»„ç»‡å¼•ç”¨ï¼š{char_data.get('name')} -> {org_name}")
                char_data["organization_memberships"] = valid_orgs
        
        if cleaned_count > 0:
            logger.info(f"âœ¨ æ¸…ç†äº†{cleaned_count}ä¸ªAIå¹»è§‰å¼•ç”¨")
            yield await tracker.parsing(f"å·²æ¸…ç†{cleaned_count}ä¸ªæ— æ•ˆå¼•ç”¨", 0.7)
        
        yield await tracker.saving("ä¿å­˜è§’è‰²åˆ°æ•°æ®åº“...")
        
        # ç¬¬ä¸€é˜¶æ®µï¼šåˆ›å»ºæ‰€æœ‰Characterè®°å½•
        created_characters = []
        character_name_to_obj = {}  # åç§°åˆ°å¯¹è±¡çš„æ˜ å°„ï¼Œç”¨äºåç»­å…³ç³»åˆ›å»º
        
        for char_data in all_characters:
            # ä»relationships_arrayæå–æ–‡æœ¬æè¿°ä»¥ä¿æŒå‘åå…¼å®¹
            relationships_text = ""
            relationships_array = char_data.get("relationships_array", [])
            if relationships_array and isinstance(relationships_array, list):
                # å°†å…³ç³»æ•°ç»„è½¬æ¢ä¸ºå¯è¯»æ–‡æœ¬
                rel_descriptions = []
                for rel in relationships_array:
                    target = rel.get("target_character_name", "æœªçŸ¥")
                    rel_type = rel.get("relationship_type", "å…³ç³»")
                    desc = rel.get("description", "")
                    rel_descriptions.append(f"{target}({rel_type}): {desc}")
                relationships_text = "; ".join(rel_descriptions)
            # å…¼å®¹æ—§æ ¼å¼
            elif isinstance(char_data.get("relationships"), dict):
                relationships_text = json.dumps(char_data.get("relationships"), ensure_ascii=False)
            elif isinstance(char_data.get("relationships"), str):
                relationships_text = char_data.get("relationships")
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºç»„ç»‡
            is_organization = char_data.get("is_organization", False)
            
            character = Character(
                project_id=project_id,
                name=char_data.get("name", "æœªå‘½åè§’è‰²"),
                age=str(char_data.get("age", "")) if not is_organization else None,
                gender=char_data.get("gender") if not is_organization else None,
                is_organization=is_organization,
                role_type=char_data.get("role_type", "supporting"),
                personality=char_data.get("personality", ""),
                background=char_data.get("background", ""),
                appearance=char_data.get("appearance", ""),
                relationships=relationships_text,
                organization_type=char_data.get("organization_type") if is_organization else None,
                organization_purpose=char_data.get("organization_purpose") if is_organization else None,
                organization_members=json.dumps(char_data.get("organization_members", []), ensure_ascii=False) if is_organization else None,
                traits=json.dumps(char_data.get("traits", []), ensure_ascii=False) if char_data.get("traits") else None
            )
            db.add(character)
            created_characters.append((character, char_data))
        
        await db.flush()  # è·å–æ‰€æœ‰è§’è‰²çš„ID
        
        # ç¬¬äºŒé˜¶æ®µï¼šä¸ºè§’è‰²åˆ†é…èŒä¸šå¹¶åˆ›å»ºCharacterCareerå…³è”
        if main_careers or sub_careers:
            yield await tracker.saving("åˆ†é…è§’è‰²èŒä¸š...", 0.3)
            careers_assigned = 0
            
            # æ„å»ºèŒä¸šåç§°åˆ°å¯¹è±¡çš„æ˜ å°„
            career_name_to_obj = {c.name: c for c in careers}
            
            for character, char_data in created_characters:
                # è·³è¿‡ç»„ç»‡
                if character.is_organization:
                    continue
                
                try:
                    career_assignment = char_data.get("career_assignment", {})
                    
                    # åˆ†é…ä¸»èŒä¸š
                    main_career_name = career_assignment.get("main_career")
                    main_career_stage = career_assignment.get("main_stage", 1)
                    
                    if main_career_name and main_career_name in career_name_to_obj:
                        main_career = career_name_to_obj[main_career_name]
                        
                        # åˆ›å»ºCharacterCareerå…³è”
                        char_career = CharacterCareer(
                            character_id=character.id,
                            career_id=main_career.id,
                            career_type="main",
                            current_stage=min(main_career_stage, main_career.max_stage),
                            stage_progress=0
                        )
                        db.add(char_career)
                        
                        # æ›´æ–°Characterå†—ä½™å­—æ®µ
                        character.main_career_id = main_career.id
                        character.main_career_stage = char_career.current_stage
                        
                        careers_assigned += 1
                        logger.info(f"  âœ… åˆ†é…ä¸»èŒä¸šï¼š{character.name} -> {main_career.name} (é˜¶æ®µ{char_career.current_stage})")
                    else:
                        if main_career_name:
                            logger.warning(f"  âš ï¸ ä¸»èŒä¸šä¸å­˜åœ¨ï¼š{character.name} -> {main_career_name}")
                    
                    # åˆ†é…å‰¯èŒä¸š
                    sub_career_assignments = career_assignment.get("sub_careers", [])
                    sub_career_list = []
                    
                    for sub_assign in sub_career_assignments[:2]:  # æœ€å¤š2ä¸ªå‰¯èŒä¸š
                        sub_career_name = sub_assign.get("career")
                        sub_career_stage = sub_assign.get("stage", 1)
                        
                        if sub_career_name and sub_career_name in career_name_to_obj:
                            sub_career = career_name_to_obj[sub_career_name]
                            
                            # åˆ›å»ºCharacterCareerå…³è”
                            char_career = CharacterCareer(
                                character_id=character.id,
                                career_id=sub_career.id,
                                career_type="sub",
                                current_stage=min(sub_career_stage, sub_career.max_stage),
                                stage_progress=0
                            )
                            db.add(char_career)
                            
                            # æ·»åŠ åˆ°å‰¯èŒä¸šåˆ—è¡¨
                            sub_career_list.append({
                                "career_id": sub_career.id,
                                "stage": char_career.current_stage
                            })
                            
                            careers_assigned += 1
                            logger.info(f"  âœ… åˆ†é…å‰¯èŒä¸šï¼š{character.name} -> {sub_career.name} (é˜¶æ®µ{char_career.current_stage})")
                        else:
                            if sub_career_name:
                                logger.warning(f"  âš ï¸ å‰¯èŒä¸šä¸å­˜åœ¨ï¼š{character.name} -> {sub_career_name}")
                    
                    # æ›´æ–°Characterå†—ä½™å­—æ®µ
                    if sub_career_list:
                        character.sub_careers = json.dumps(sub_career_list, ensure_ascii=False)
                    
                except Exception as e:
                    logger.warning(f"  âŒ åˆ†é…èŒä¸šå¤±è´¥ï¼š{character.name} - {str(e)}")
                    continue
            
            await db.flush()
            logger.info(f"ğŸ’¼ èŒä¸šåˆ†é…å®Œæˆï¼šå…±åˆ†é…{careers_assigned}ä¸ªèŒä¸š")
            yield await tracker.saving(f"å·²åˆ†é…{careers_assigned}ä¸ªèŒä¸š", 0.4)
        
        # åˆ·æ–°å¹¶å»ºç«‹åç§°æ˜ å°„
        for character, _ in created_characters:
            await db.refresh(character)
            character_name_to_obj[character.name] = character
            logger.info(f"å‘å¯¼åˆ›å»ºè§’è‰²ï¼š{character.name} (ID: {character.id}, æ˜¯å¦ç»„ç»‡: {character.is_organization})")
        
        # ç¬¬ä¸‰é˜¶æ®µï¼šä¸ºis_organization=Trueçš„è§’è‰²åˆ›å»ºOrganizationè®°å½•
        yield await tracker.saving("åˆ›å»ºç»„ç»‡è®°å½•...", 0.5)
        organization_name_to_obj = {}  # ç»„ç»‡åç§°åˆ°Organizationå¯¹è±¡çš„æ˜ å°„
        
        for character, char_data in created_characters:
            if character.is_organization:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨Organizationè®°å½•
                org_check = await db.execute(
                    select(Organization).where(Organization.character_id == character.id)
                )
                existing_org = org_check.scalar_one_or_none()
                
                if not existing_org:
                    # åˆ›å»ºOrganizationè®°å½•
                    org = Organization(
                        character_id=character.id,
                        project_id=project_id,
                        member_count=0,  # åˆå§‹ä¸º0ï¼Œåç»­æ·»åŠ æˆå‘˜æ—¶ä¼šæ›´æ–°
                        power_level=char_data.get("power_level", 50),
                        location=char_data.get("location"),
                        motto=char_data.get("motto"),
                        color=char_data.get("color")
                    )
                    db.add(org)
                    logger.info(f"å‘å¯¼åˆ›å»ºç»„ç»‡è®°å½•ï¼š{character.name}")
                else:
                    org = existing_org
                
                # å»ºç«‹ç»„ç»‡åç§°æ˜ å°„ï¼ˆæ— è®ºæ˜¯æ–°å»ºè¿˜æ˜¯å·²å­˜åœ¨ï¼‰
                organization_name_to_obj[character.name] = org
        
        await db.flush()  # ç¡®ä¿Organizationè®°å½•æœ‰ID
        
        # åˆ·æ–°è§’è‰²ä»¥è·å–ID
        for character, _ in created_characters:
            await db.refresh(character)
        
        # ç¬¬å››é˜¶æ®µï¼šåˆ›å»ºè§’è‰²é—´çš„å…³ç³»
        yield await tracker.saving("åˆ›å»ºè§’è‰²å…³ç³»...", 0.7)
        relationships_created = 0
        
        for character, char_data in created_characters:
            # è·³è¿‡ç»„ç»‡å®ä½“çš„è§’è‰²å…³ç³»å¤„ç†ï¼ˆç»„ç»‡é€šè¿‡æˆå‘˜å…³ç³»å…³è”ï¼‰
            if character.is_organization:
                continue
            
            # å¤„ç†relationshipsæ•°ç»„
            relationships_data = char_data.get("relationships_array", [])
            if not relationships_data and isinstance(char_data.get("relationships"), list):
                relationships_data = char_data.get("relationships")
            
            if relationships_data and isinstance(relationships_data, list):
                for rel in relationships_data:
                    try:
                        target_name = rel.get("target_character_name")
                        if not target_name:
                            logger.debug(f"  âš ï¸  {character.name}çš„å…³ç³»ç¼ºå°‘target_character_nameï¼Œè·³è¿‡")
                            continue
                        
                        # ä½¿ç”¨åç§°æ˜ å°„å¿«é€ŸæŸ¥æ‰¾
                        target_char = character_name_to_obj.get(target_name)
                        
                        if target_char:
                            # é¿å…åˆ›å»ºé‡å¤å…³ç³»
                            existing_rel = await db.execute(
                                select(CharacterRelationship).where(
                                    CharacterRelationship.project_id == project_id,
                                    CharacterRelationship.character_from_id == character.id,
                                    CharacterRelationship.character_to_id == target_char.id
                                )
                            )
                            if existing_rel.scalar_one_or_none():
                                logger.debug(f"  â„¹ï¸  å…³ç³»å·²å­˜åœ¨ï¼š{character.name} -> {target_name}")
                                continue
                            
                            relationship = CharacterRelationship(
                                project_id=project_id,
                                character_from_id=character.id,
                                character_to_id=target_char.id,
                                relationship_name=rel.get("relationship_type", "æœªçŸ¥å…³ç³»"),
                                intimacy_level=rel.get("intimacy_level", 50),
                                description=rel.get("description", ""),
                                started_at=rel.get("started_at"),
                                source="ai"
                            )
                            
                            # åŒ¹é…é¢„å®šä¹‰å…³ç³»ç±»å‹
                            rel_type_result = await db.execute(
                                select(RelationshipType).where(
                                    RelationshipType.name == rel.get("relationship_type")
                                )
                            )
                            rel_type = rel_type_result.scalar_one_or_none()
                            if rel_type:
                                relationship.relationship_type_id = rel_type.id
                            
                            db.add(relationship)
                            relationships_created += 1
                            logger.info(f"  âœ… å‘å¯¼åˆ›å»ºå…³ç³»ï¼š{character.name} -> {target_name} ({rel.get('relationship_type')})")
                        else:
                            logger.warning(f"  âš ï¸  ç›®æ ‡è§’è‰²ä¸å­˜åœ¨ï¼š{character.name} -> {target_name}ï¼ˆå¯èƒ½æ˜¯AIå¹»è§‰ï¼‰")
                    except Exception as e:
                        logger.warning(f"  âŒ å‘å¯¼åˆ›å»ºå…³ç³»å¤±è´¥ï¼š{character.name} - {str(e)}")
                        continue
            
        # ç¬¬äº”é˜¶æ®µï¼šåˆ›å»ºç»„ç»‡æˆå‘˜å…³ç³»
        yield await tracker.saving("åˆ›å»ºç»„ç»‡æˆå‘˜å…³ç³»...", 0.9)
        members_created = 0
        
        for character, char_data in created_characters:
            # è·³è¿‡ç»„ç»‡å®ä½“æœ¬èº«
            if character.is_organization:
                continue
            
            # å¤„ç†ç»„ç»‡æˆå‘˜å…³ç³»
            org_memberships = char_data.get("organization_memberships", [])
            if org_memberships and isinstance(org_memberships, list):
                for membership in org_memberships:
                    try:
                        org_name = membership.get("organization_name")
                        if not org_name:
                            logger.debug(f"  âš ï¸  {character.name}çš„ç»„ç»‡æˆå‘˜å…³ç³»ç¼ºå°‘organization_nameï¼Œè·³è¿‡")
                            continue
                        
                        # ä½¿ç”¨æ˜ å°„å¿«é€ŸæŸ¥æ‰¾ç»„ç»‡
                        org = organization_name_to_obj.get(org_name)
                        
                        if org:
                            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨æˆå‘˜å…³ç³»
                            existing_member = await db.execute(
                                select(OrganizationMember).where(
                                    OrganizationMember.organization_id == org.id,
                                    OrganizationMember.character_id == character.id
                                )
                            )
                            if existing_member.scalar_one_or_none():
                                logger.debug(f"  â„¹ï¸  æˆå‘˜å…³ç³»å·²å­˜åœ¨ï¼š{character.name} -> {org_name}")
                                continue
                            
                            # åˆ›å»ºæˆå‘˜å…³ç³»
                            member = OrganizationMember(
                                organization_id=org.id,
                                character_id=character.id,
                                position=membership.get("position", "æˆå‘˜"),
                                rank=membership.get("rank", 0),
                                loyalty=membership.get("loyalty", 50),
                                joined_at=membership.get("joined_at"),
                                status=membership.get("status", "active"),
                                source="ai"
                            )
                            db.add(member)
                            
                            # æ›´æ–°ç»„ç»‡æˆå‘˜è®¡æ•°
                            org.member_count += 1
                            
                            members_created += 1
                            logger.info(f"  âœ… å‘å¯¼æ·»åŠ æˆå‘˜ï¼š{character.name} -> {org_name} ({membership.get('position')})")
                        else:
                            # è¿™ç§æƒ…å†µç†è®ºä¸Šå·²ç»è¢«é¢„å¤„ç†æ¸…ç†äº†ï¼Œä½†ä¿ç•™æ—¥å¿—ä»¥é˜²ä¸‡ä¸€
                            logger.debug(f"  â„¹ï¸  ç»„ç»‡å¼•ç”¨å·²è¢«æ¸…ç†ï¼š{character.name} -> {org_name}")
                    except Exception as e:
                        logger.warning(f"  âŒ å‘å¯¼æ·»åŠ ç»„ç»‡æˆå‘˜å¤±è´¥ï¼š{character.name} - {str(e)}")
                        continue
        
        logger.info(f"ğŸ“Š å‘å¯¼æ•°æ®ç»Ÿè®¡ï¼š")
        logger.info(f"  - åˆ›å»ºè§’è‰²/ç»„ç»‡ï¼š{len(created_characters)} ä¸ª")
        logger.info(f"  - åˆ›å»ºç»„ç»‡è¯¦æƒ…ï¼š{len(organization_name_to_obj)} ä¸ª")
        logger.info(f"  - åˆ›å»ºè§’è‰²å…³ç³»ï¼š{relationships_created} æ¡")
        logger.info(f"  - åˆ›å»ºç»„ç»‡æˆå‘˜ï¼š{members_created} æ¡")
        
        # æ›´æ–°é¡¹ç›®çš„è§’è‰²æ•°é‡å’Œå‘å¯¼æ­¥éª¤çŠ¶æ€ä¸º3ï¼ˆè§’è‰²å·²å®Œæˆï¼‰
        # wizard_step: 0=æœªå¼€å§‹, 1=ä¸–ç•Œè§‚å·²å®Œæˆ, 2=èŒä¸šä½“ç³»å·²å®Œæˆ, 3=è§’è‰²å·²å®Œæˆ, 4=å¤§çº²å·²å®Œæˆ
        project.character_count = len(created_characters)
        project.wizard_step = 3
        logger.info(f"âœ… æ›´æ–°é¡¹ç›®è§’è‰²æ•°é‡: {project.character_count}")
        
        await db.commit()
        db_committed = True
        
        # é‡æ–°æå–characterå¯¹è±¡
        created_characters = [char for char, _ in created_characters]
        
        yield await tracker.complete()
        
        # å‘é€ç»“æœ
        yield await tracker.result({
            "message": f"æˆåŠŸç”Ÿæˆ{len(created_characters)}ä¸ªè§’è‰²/ç»„ç»‡ï¼ˆåˆ†{total_batches}æ‰¹å®Œæˆï¼‰",
            "count": len(created_characters),
            "batches": total_batches,
            "characters": [
                {
                    "id": char.id,
                    "project_id": char.project_id,
                    "name": char.name,
                    "age": char.age,
                    "gender": char.gender,
                    "is_organization": char.is_organization,
                    "role_type": char.role_type,
                    "personality": char.personality,
                    "background": char.background,
                    "appearance": char.appearance,
                    "relationships": char.relationships,
                    "organization_type": char.organization_type,
                    "organization_purpose": char.organization_purpose,
                    "organization_members": char.organization_members,
                    "traits": char.traits,
                    "created_at": char.created_at.isoformat() if char.created_at else None,
                    "updated_at": char.updated_at.isoformat() if char.updated_at else None
                } for char in created_characters
            ]
        })
        
        yield await tracker.done()
        
    except GeneratorExit:
        logger.warning("è§’è‰²ç”Ÿæˆå™¨è¢«æå‰å…³é—­")
        if not db_committed and db.in_transaction():
            await db.rollback()
            logger.info("è§’è‰²ç”Ÿæˆäº‹åŠ¡å·²å›æ»šï¼ˆGeneratorExitï¼‰")
    except Exception as e:
        logger.error(f"è§’è‰²ç”Ÿæˆå¤±è´¥: {str(e)}")
        if not db_committed and db.in_transaction():
            await db.rollback()
            logger.info("è§’è‰²ç”Ÿæˆäº‹åŠ¡å·²å›æ»šï¼ˆå¼‚å¸¸ï¼‰")
        yield await tracker.error(f"ç”Ÿæˆå¤±è´¥: {str(e)}")


@router.post("/characters", summary="æµå¼æ‰¹é‡ç”Ÿæˆè§’è‰²")
async def generate_characters_stream(
    request: Request,
    data: Dict[str, Any],
    db: AsyncSession = Depends(get_db),
    user_ai_service: AIService = Depends(get_user_ai_service)
):
    """
    ä½¿ç”¨SSEæµå¼æ‰¹é‡ç”Ÿæˆè§’è‰²ï¼Œé¿å…è¶…æ—¶
    æ”¯æŒMCPå·¥å…·å¢å¼º
    """
    # ä»ä¸­é—´ä»¶æ³¨å…¥user_idåˆ°dataä¸­
    if hasattr(request.state, 'user_id'):
        data['user_id'] = request.state.user_id
    
    return create_sse_response(characters_generator(data, db, user_ai_service))


async def outline_generator(
    data: Dict[str, Any],
    db: AsyncSession,
    user_ai_service: AIService
) -> AsyncGenerator[str, None]:
    """å¤§çº²ç”Ÿæˆæµå¼ç”Ÿæˆå™¨ - å‘å¯¼ä»…ç”Ÿæˆå¤§çº²èŠ‚ç‚¹ï¼Œä¸å±•å¼€ç« èŠ‚ï¼ˆé¿å…ç­‰å¾…è¿‡ä¹…ï¼‰"""
    db_committed = False
    # åˆå§‹åŒ–æ ‡å‡†è¿›åº¦è¿½è¸ªå™¨
    tracker = WizardProgressTracker("å¤§çº²")
    
    try:
        yield await tracker.start()
        
        project_id = data.get("project_id")
        # å‘å¯¼å›ºå®šç”Ÿæˆ3ä¸ªå¤§çº²èŠ‚ç‚¹ï¼ˆä¸å±•å¼€ï¼‰
        outline_count = data.get("chapter_count", 3)
        narrative_perspective = data.get("narrative_perspective")
        target_words = data.get("target_words", 100000)
        requirements = data.get("requirements", "")
        provider = data.get("provider")
        model = data.get("model")
        enable_mcp = data.get("enable_mcp", True)  # é»˜è®¤å¯ç”¨MCP
        user_id = data.get("user_id")  # ä»ä¸­é—´ä»¶æ³¨å…¥
        
        # è·å–é¡¹ç›®ä¿¡æ¯
        yield await tracker.loading("åŠ è½½é¡¹ç›®ä¿¡æ¯...", 0.3)
        result = await db.execute(
            select(Project).where(Project.id == project_id)
        )
        project = result.scalar_one_or_none()
        if not project:
            yield await tracker.error("é¡¹ç›®ä¸å­˜åœ¨", 404)
            return
        
        # è·å–è§’è‰²ä¿¡æ¯
        yield await tracker.loading("åŠ è½½è§’è‰²ä¿¡æ¯...", 0.8)
        result = await db.execute(
            select(Character).where(Character.project_id == project_id)
        )
        characters = result.scalars().all()
        
        characters_info = "\n".join([
            f"- {char.name} ({'ç»„ç»‡' if char.is_organization else 'è§’è‰²'}, {char.role_type}): {char.personality[:100] if char.personality else 'æš‚æ— æè¿°'}"
            for char in characters
        ])
        
        # å‡†å¤‡æç¤ºè¯
        yield await tracker.preparing(f"å‡†å¤‡ç”Ÿæˆ{outline_count}ä¸ªå¤§çº²èŠ‚ç‚¹...")
        
        outline_requirements = f"{requirements}\n\nã€é‡è¦è¯´æ˜ã€‘è¿™æ˜¯å°è¯´çš„å¼€å±€éƒ¨åˆ†ï¼Œè¯·ç”Ÿæˆ{outline_count}ä¸ªå¤§çº²èŠ‚ç‚¹ï¼Œé‡ç‚¹å…³æ³¨ï¼š\n"
        outline_requirements += "1. å¼•å…¥ä¸»è¦è§’è‰²å’Œä¸–ç•Œè§‚è®¾å®š\n"
        outline_requirements += "2. å»ºç«‹ä¸»çº¿å†²çªå’Œæ•…äº‹é’©å­\n"
        outline_requirements += "3. å±•å¼€åˆæœŸæƒ…èŠ‚ï¼Œä¸ºåç»­å‘å±•åŸ‹ä¸‹ä¼ç¬”\n"
        outline_requirements += "4. ä¸è¦è¯•å›¾å®Œç»“æ•…äº‹ï¼Œè¿™åªæ˜¯å¼€å§‹éƒ¨åˆ†\n"
        outline_requirements += "5. ä¸è¦åœ¨JSONå­—ç¬¦ä¸²å€¼ä¸­ä½¿ç”¨ä¸­æ–‡å¼•å·ï¼ˆ""''ï¼‰ï¼Œè¯·ä½¿ç”¨ã€ã€‘æˆ–ã€Šã€‹æ ‡è®°\n"
        
        # è·å–è‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿
        template = await PromptService.get_template("OUTLINE_CREATE", user_id, db)
        outline_prompt = PromptService.format_prompt(
            template,
            title=project.title,
            theme=project.theme or "æœªè®¾å®š",
            genre=project.genre or "é€šç”¨",
            chapter_count=outline_count,
            narrative_perspective=narrative_perspective,
            target_words=target_words // 10,  # å¼€å±€çº¦å æ€»å­—æ•°çš„1/10
            time_period=project.world_time_period or "æœªè®¾å®š",
            location=project.world_location or "æœªè®¾å®š",
            atmosphere=project.world_atmosphere or "æœªè®¾å®š",
            rules=project.world_rules or "æœªè®¾å®š",
            characters_info=characters_info or "æš‚æ— è§’è‰²ä¿¡æ¯",
            mcp_references="",
            requirements=outline_requirements
        )
        
        # æµå¼ç”Ÿæˆå¤§çº²
        estimated_total = 1000
        accumulated_text = ""
        chunk_count = 0
        
        yield await tracker.generating(current_chars=0, estimated_total=estimated_total)
        
        async for chunk in user_ai_service.generate_text_stream(
            prompt=outline_prompt,
            provider=provider,
            model=model,
        ):
            chunk_count += 1
            accumulated_text += chunk
            
            # å‘é€å†…å®¹å—
            yield await tracker.generating_chunk(chunk)
            
            # å®šæœŸæ›´æ–°è¿›åº¦
            current_len = len(accumulated_text)
            if chunk_count % 10 == 0:
                yield await tracker.generating(
                    current_chars=current_len,
                    estimated_total=estimated_total
                )
            
            # æ¯20ä¸ªå—å‘é€å¿ƒè·³
            if chunk_count % 20 == 0:
                yield await tracker.heartbeat()
        
        # è§£æå¤§çº²ç»“æœ - ä½¿ç”¨ç»Ÿä¸€çš„JSONæ¸…æ´—æ–¹æ³•
        yield await tracker.parsing("è§£æå¤§çº²æ•°æ®...")
        
        try:
            cleaned_text = user_ai_service._clean_json_response(accumulated_text)
            outline_data = json.loads(cleaned_text)
            if not isinstance(outline_data, list):
                outline_data = [outline_data]
        except json.JSONDecodeError as e:
            logger.error(f"å¤§çº²JSONè§£æå¤±è´¥: {e}")
            yield await tracker.error("å¤§çº²ç”Ÿæˆå¤±è´¥ï¼Œè¯·é‡è¯•")
            return
        
        # ä¿å­˜å¤§çº²åˆ°æ•°æ®åº“
        yield await tracker.saving("ä¿å­˜å¤§çº²åˆ°æ•°æ®åº“...")
        created_outlines = []
        for index, outline_item in enumerate(outline_data[:outline_count], 1):
            outline = Outline(
                project_id=project_id,
                title=outline_item.get("title", f"ç¬¬{index}èŠ‚"),
                content=outline_item.get("summary", outline_item.get("content", "")),
                structure=json.dumps(outline_item, ensure_ascii=False),
                order_index=index
            )
            db.add(outline)
            created_outlines.append(outline)
        
        await db.flush()  # è·å–å¤§çº²ID
        for outline in created_outlines:
            await db.refresh(outline)
        
        logger.info(f"âœ… æˆåŠŸåˆ›å»º{len(created_outlines)}ä¸ªå¤§çº²èŠ‚ç‚¹")
        
        # æ ¹æ®é¡¹ç›®çš„å¤§çº²æ¨¡å¼å†³å®šæ˜¯å¦è‡ªåŠ¨åˆ›å»ºç« èŠ‚
        created_chapters = []
        if project.outline_mode == 'one-to-one':
            # ä¸€å¯¹ä¸€æ¨¡å¼ï¼šè‡ªåŠ¨ä¸ºæ¯ä¸ªå¤§çº²åˆ›å»ºå¯¹åº”çš„ç« èŠ‚
            yield await tracker.saving("ä¸€å¯¹ä¸€æ¨¡å¼ï¼šè‡ªåŠ¨åˆ›å»ºç« èŠ‚...", 0.7)
            
            for outline in created_outlines:
                chapter = Chapter(
                    project_id=project_id,
                    title=outline.title,
                    content="",  # ç©ºå†…å®¹ï¼Œç­‰å¾…ç”¨æˆ·ç”Ÿæˆ
                    outline_id=None,  # ä¸€å¯¹ä¸€æ¨¡å¼ä¸‹ä¸å…³è”outline_id
                    chapter_number=outline.order_index,  # ä½¿ç”¨chapter_numberè€Œä¸æ˜¯order_index
                    status="pending"
                )
                db.add(chapter)
                created_chapters.append(chapter)
            
            await db.flush()
            for chapter in created_chapters:
                await db.refresh(chapter)
            
            logger.info(f"âœ… ä¸€å¯¹ä¸€æ¨¡å¼ï¼šè‡ªåŠ¨åˆ›å»ºäº†{len(created_chapters)}ä¸ªç« èŠ‚")
            yield await tracker.saving(f"å·²è‡ªåŠ¨åˆ›å»º{len(created_chapters)}ä¸ªç« èŠ‚", 0.9)
        else:
            # ä¸€å¯¹å¤šæ¨¡å¼ï¼šè·³è¿‡è‡ªåŠ¨åˆ›å»ºï¼Œç”¨æˆ·å¯æ‰‹åŠ¨å±•å¼€
            yield await tracker.saving("ç»†åŒ–æ¨¡å¼ï¼šè·³è¿‡è‡ªåŠ¨åˆ›å»ºç« èŠ‚", 0.9)
            logger.info(f"ğŸ“ ç»†åŒ–æ¨¡å¼ï¼šè·³è¿‡ç« èŠ‚åˆ›å»ºï¼Œç”¨æˆ·å¯åœ¨å¤§çº²é¡µé¢æ‰‹åŠ¨å±•å¼€")
        
        # æ›´æ–°é¡¹ç›®ä¿¡æ¯
        # wizard_step: 0=æœªå¼€å§‹, 1=ä¸–ç•Œè§‚å·²å®Œæˆ, 2=èŒä¸šä½“ç³»å·²å®Œæˆ, 3=è§’è‰²å·²å®Œæˆ, 4=å¤§çº²å·²å®Œæˆ
        project.chapter_count = len(created_chapters)  # è®°å½•å®é™…åˆ›å»ºçš„ç« èŠ‚æ•°
        project.narrative_perspective = narrative_perspective
        project.target_words = target_words
        project.status = "writing"
        project.wizard_status = "completed"
        project.wizard_step = 4
        
        await db.commit()
        db_committed = True
        
        logger.info(f"ğŸ“Š å‘å¯¼å¤§çº²ç”Ÿæˆå®Œæˆï¼š")
        logger.info(f"  - åˆ›å»ºå¤§çº²èŠ‚ç‚¹ï¼š{len(created_outlines)} ä¸ª")
        logger.info(f"  - åˆ›å»ºç« èŠ‚ï¼š{len(created_chapters)} ä¸ª")
        logger.info(f"  - å¤§çº²æ¨¡å¼ï¼š{project.outline_mode}")
        
        # æ„å»ºç»“æœæ¶ˆæ¯
        if project.outline_mode == 'one-to-one':
            result_message = f"æˆåŠŸç”Ÿæˆ{len(created_outlines)}ä¸ªå¤§çº²èŠ‚ç‚¹å¹¶è‡ªåŠ¨åˆ›å»º{len(created_chapters)}ä¸ªç« èŠ‚ï¼ˆä¼ ç»Ÿæ¨¡å¼ï¼‰"
            result_note = "å·²è‡ªåŠ¨åˆ›å»ºç« èŠ‚ï¼Œå¯ç›´æ¥ç”Ÿæˆå†…å®¹"
        else:
            result_message = f"æˆåŠŸç”Ÿæˆ{len(created_outlines)}ä¸ªå¤§çº²èŠ‚ç‚¹ï¼ˆç»†åŒ–æ¨¡å¼ï¼Œå¯åœ¨å¤§çº²é¡µé¢æ‰‹åŠ¨å±•å¼€ï¼‰"
            result_note = "å¯åœ¨å¤§çº²é¡µé¢å±•å¼€ä¸ºå¤šä¸ªç« èŠ‚"
        
        yield await tracker.complete()
        
        # å‘é€ç»“æœ
        yield await tracker.result({
            "message": result_message,
            "outline_count": len(created_outlines),
            "chapter_count": len(created_chapters),
            "outline_mode": project.outline_mode,
            "outlines": [
                {
                    "id": outline.id,
                    "order_index": outline.order_index,
                    "title": outline.title,
                    "content": outline.content[:100] + "..." if len(outline.content) > 100 else outline.content,
                    "note": result_note
                } for outline in created_outlines
            ],
            "chapters": [
                {
                    "id": chapter.id,
                    "chapter_number": chapter.chapter_number,
                    "title": chapter.title,
                    "status": chapter.status
                } for chapter in created_chapters
            ] if created_chapters else []
        })
        
        yield await tracker.done()
        
    except GeneratorExit:
        logger.warning("å¤§çº²ç”Ÿæˆå™¨è¢«æå‰å…³é—­")
        if not db_committed and db.in_transaction():
            await db.rollback()
            logger.info("å¤§çº²ç”Ÿæˆäº‹åŠ¡å·²å›æ»šï¼ˆGeneratorExitï¼‰")
    except Exception as e:
        logger.error(f"å¤§çº²ç”Ÿæˆå¤±è´¥: {str(e)}")
        if not db_committed and db.in_transaction():
            await db.rollback()
            logger.info("å¤§çº²ç”Ÿæˆäº‹åŠ¡å·²å›æ»šï¼ˆå¼‚å¸¸ï¼‰")
        yield await tracker.error(f"ç”Ÿæˆå¤±è´¥: {str(e)}")

@router.post("/outline", summary="æµå¼ç”Ÿæˆå®Œæ•´å¤§çº²")
async def generate_outline_stream(
    data: Dict[str, Any],
    db: AsyncSession = Depends(get_db),
    user_ai_service: AIService = Depends(get_user_ai_service)
):
    """
    ä½¿ç”¨SSEæµå¼ç”Ÿæˆå®Œæ•´å¤§çº²ï¼Œé¿å…è¶…æ—¶
    """
    return create_sse_response(outline_generator(data, db, user_ai_service))


async def world_building_regenerate_generator(
    project_id: str,
    data: Dict[str, Any],
    db: AsyncSession,
    user_ai_service: AIService
) -> AsyncGenerator[str, None]:
    """ä¸–ç•Œè§‚é‡æ–°ç”Ÿæˆæµå¼ç”Ÿæˆå™¨"""
    db_committed = False
    # åˆå§‹åŒ–æ ‡å‡†è¿›åº¦è¿½è¸ªå™¨
    tracker = WizardProgressTracker("ä¸–ç•Œè§‚")
    
    try:
        yield await tracker.start("å¼€å§‹é‡æ–°ç”Ÿæˆä¸–ç•Œè§‚...")
        
        # è·å–é¡¹ç›®ä¿¡æ¯
        yield await tracker.loading("åŠ è½½é¡¹ç›®ä¿¡æ¯...")
        result = await db.execute(
            select(Project).where(Project.id == project_id)
        )
        project = result.scalar_one_or_none()
        if not project:
            yield await tracker.error("é¡¹ç›®ä¸å­˜åœ¨", 404)
            return
        
        # æå–å‚æ•°
        provider = data.get("provider")
        model = data.get("model")
        enable_mcp = data.get("enable_mcp", True)
        user_id = data.get("user_id")
        
        # è·å–åŸºç¡€æç¤ºè¯ï¼ˆæ”¯æŒè‡ªå®šä¹‰ï¼‰
        yield await tracker.preparing("å‡†å¤‡AIæç¤ºè¯...")
        template = await PromptService.get_template("WORLD_BUILDING", user_id, db)
        base_prompt = PromptService.format_prompt(
            template,
            title=project.title,
            theme=project.theme or "æœªè®¾å®š",
            genre=project.genre or "é€šç”¨",
            description=project.description or "æš‚æ— ç®€ä»‹"
        )
        
        # è®¾ç½®ç”¨æˆ·ä¿¡æ¯ä»¥å¯ç”¨MCP
        if user_id:
            user_ai_service.user_id = user_id
            user_ai_service.db_session = db
        
        # ===== æµå¼ç”Ÿæˆä¸–ç•Œè§‚ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰ =====
        MAX_WORLD_RETRIES = 3  # æœ€å¤šé‡è¯•3æ¬¡
        world_retry_count = 0
        world_generation_success = False
        world_data = {}
        estimated_total = 1000
        
        while world_retry_count < MAX_WORLD_RETRIES and not world_generation_success:
            try:
                # é‡è¯•æ—¶é‡ç½®ç”Ÿæˆè¿›åº¦
                if world_retry_count > 0:
                    tracker.reset_generating_progress()
                
                yield await tracker.generating(
                    current_chars=0,
                    estimated_total=estimated_total,
                    message="é‡æ–°ç”Ÿæˆä¸–ç•Œè§‚",
                    retry_count=world_retry_count,
                    max_retries=MAX_WORLD_RETRIES
                )
                
                # æµå¼ç”Ÿæˆä¸–ç•Œè§‚
                accumulated_text = ""
                chunk_count = 0
                
                async for chunk in user_ai_service.generate_text_stream(
                    prompt=base_prompt,
                    provider=provider,
                    model=model,
                    tool_choice="required",
                ):
                    chunk_count += 1
                    accumulated_text += chunk
                    
                    yield await tracker.generating_chunk(chunk)
                    
                    # å®šæœŸæ›´æ–°è¿›åº¦
                    current_len = len(accumulated_text)
                    if chunk_count % 10 == 0:
                        yield await tracker.generating(
                            current_chars=current_len,
                            estimated_total=estimated_total,
                            message="é‡æ–°ç”Ÿæˆä¸–ç•Œè§‚",
                            retry_count=world_retry_count,
                            max_retries=MAX_WORLD_RETRIES
                        )
                    
                    if chunk_count % 20 == 0:
                        yield await tracker.heartbeat()
                
                # æ£€æŸ¥æ˜¯å¦è¿”å›ç©ºå“åº”
                if not accumulated_text or not accumulated_text.strip():
                    logger.warning(f"âš ï¸ AIè¿”å›ç©ºä¸–ç•Œè§‚ï¼ˆå°è¯•{world_retry_count+1}/{MAX_WORLD_RETRIES}ï¼‰")
                    world_retry_count += 1
                    if world_retry_count < MAX_WORLD_RETRIES:
                        yield await tracker.retry(world_retry_count, MAX_WORLD_RETRIES, "AIè¿”å›ä¸ºç©º")
                        continue
                    else:
                        # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼
                        logger.error("âŒ ä¸–ç•Œè§‚é‡æ–°ç”Ÿæˆå¤šæ¬¡è¿”å›ç©ºå“åº”")
                        world_data = {
                            "time_period": "AIå¤šæ¬¡è¿”å›ä¸ºç©ºï¼Œè¯·ç¨åé‡è¯•",
                            "location": "AIå¤šæ¬¡è¿”å›ä¸ºç©ºï¼Œè¯·ç¨åé‡è¯•",
                            "atmosphere": "AIå¤šæ¬¡è¿”å›ä¸ºç©ºï¼Œè¯·ç¨åé‡è¯•",
                            "rules": "AIå¤šæ¬¡è¿”å›ä¸ºç©ºï¼Œè¯·ç¨åé‡è¯•"
                        }
                        world_generation_success = True
                        break
                
                # è§£æç»“æœ - ä½¿ç”¨ç»Ÿä¸€çš„JSONæ¸…æ´—æ–¹æ³•
                yield await tracker.parsing("è§£æAIè¿”å›ç»“æœ...")
                
                try:
                    logger.info(f"ğŸ” å¼€å§‹æ¸…æ´—JSONï¼ŒåŸå§‹é•¿åº¦: {len(accumulated_text)}")
                    cleaned_text = user_ai_service._clean_json_response(accumulated_text)
                    logger.info(f"âœ… JSONæ¸…æ´—å®Œæˆï¼Œæ¸…æ´—åé•¿åº¦: {len(cleaned_text)}")
                    
                    world_data = json.loads(cleaned_text)
                    logger.info(f"âœ… ä¸–ç•Œè§‚é‡æ–°ç”ŸæˆJSONè§£ææˆåŠŸï¼ˆå°è¯•{world_retry_count+1}/{MAX_WORLD_RETRIES}ï¼‰")
                    world_generation_success = True
                            
                except json.JSONDecodeError as e:
                    logger.error(f"âŒ ä¸–ç•Œæ„å»ºJSONè§£æå¤±è´¥ï¼ˆå°è¯•{world_retry_count+1}/{MAX_WORLD_RETRIES}ï¼‰: {e}")
                    logger.error(f"   åŸå§‹å†…å®¹é•¿åº¦: {len(accumulated_text)}")
                    logger.error(f"   åŸå§‹å†…å®¹é¢„è§ˆ: {accumulated_text[:200]}")
                    world_retry_count += 1
                    if world_retry_count < MAX_WORLD_RETRIES:
                        yield await tracker.retry(world_retry_count, MAX_WORLD_RETRIES, "JSONè§£æå¤±è´¥")
                        continue
                    else:
                        # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼
                        world_data = {
                            "time_period": "AIè¿”å›æ ¼å¼é”™è¯¯ï¼Œè¯·é‡è¯•",
                            "location": "AIè¿”å›æ ¼å¼é”™è¯¯ï¼Œè¯·é‡è¯•",
                            "atmosphere": "AIè¿”å›æ ¼å¼é”™è¯¯ï¼Œè¯·é‡è¯•",
                            "rules": "AIè¿”å›æ ¼å¼é”™è¯¯ï¼Œè¯·é‡è¯•"
                        }
                        world_generation_success = True
                        
            except Exception as e:
                logger.error(f"âŒ ä¸–ç•Œè§‚é‡æ–°ç”Ÿæˆå¼‚å¸¸ï¼ˆå°è¯•{world_retry_count+1}/{MAX_WORLD_RETRIES}ï¼‰: {type(e).__name__}: {e}")
                world_retry_count += 1
                if world_retry_count < MAX_WORLD_RETRIES:
                    yield await tracker.retry(world_retry_count, MAX_WORLD_RETRIES, "ç”Ÿæˆå¼‚å¸¸")
                    continue
                else:
                    # æœ€åä¸€æ¬¡é‡è¯•ä»å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
                    logger.error(f"   accumulated_text é•¿åº¦: {len(accumulated_text) if 'accumulated_text' in locals() else 'N/A'}")
                    raise
        
        # ä¸ä¿å­˜åˆ°æ•°æ®åº“ï¼Œä»…è¿”å›ç”Ÿæˆç»“æœä¾›ç”¨æˆ·é¢„è§ˆ
        yield await tracker.saving("ç”Ÿæˆå®Œæˆï¼Œç­‰å¾…ç”¨æˆ·ç¡®è®¤...", 0.5)
        
        yield await tracker.complete()
        
        # å‘é€æœ€ç»ˆç»“æœï¼ˆä¸åŒ…å«project_idï¼Œè¡¨ç¤ºæœªä¿å­˜ï¼‰
        yield await tracker.result({
            "time_period": world_data.get("time_period"),
            "location": world_data.get("location"),
            "atmosphere": world_data.get("atmosphere"),
            "rules": world_data.get("rules")
        })
        
        yield await tracker.done()
        
    except GeneratorExit:
        logger.warning("ä¸–ç•Œè§‚é‡æ–°ç”Ÿæˆå™¨è¢«æå‰å…³é—­")
        if not db_committed and db.in_transaction():
            await db.rollback()
            logger.info("ä¸–ç•Œè§‚é‡æ–°ç”Ÿæˆäº‹åŠ¡å·²å›æ»šï¼ˆGeneratorExitï¼‰")
    except Exception as e:
        logger.error(f"ä¸–ç•Œè§‚é‡æ–°ç”Ÿæˆå¤±è´¥: {str(e)}")
        if not db_committed and db.in_transaction():
            await db.rollback()
            logger.info("ä¸–ç•Œè§‚é‡æ–°ç”Ÿæˆäº‹åŠ¡å·²å›æ»šï¼ˆå¼‚å¸¸ï¼‰")
        yield await tracker.error(f"ç”Ÿæˆå¤±è´¥: {str(e)}")


@router.post("/world-building/{project_id}/regenerate", summary="æµå¼é‡æ–°ç”Ÿæˆä¸–ç•Œè§‚")
async def regenerate_world_building_stream(
    project_id: str,
    request: Request,
    data: Dict[str, Any],
    db: AsyncSession = Depends(get_db),
    user_ai_service: AIService = Depends(get_user_ai_service)
):
    """
    ä½¿ç”¨SSEæµå¼é‡æ–°ç”Ÿæˆä¸–ç•Œè§‚ï¼Œé¿å…è¶…æ—¶
    å‰ç«¯ä½¿ç”¨EventSourceæ¥æ”¶å®æ—¶è¿›åº¦å’Œç»“æœ
    """
    # ä»ä¸­é—´ä»¶æ³¨å…¥user_idåˆ°dataä¸­
    if hasattr(request.state, 'user_id'):
        data['user_id'] = request.state.user_id
    return create_sse_response(world_building_regenerate_generator(project_id, data, db, user_ai_service))
