"""ç« èŠ‚ç®¡ç†API"""
from fastapi import APIRouter, Depends, HTTPException, Request, Query, BackgroundTasks
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func
from sqlalchemy.orm import selectinload
import json
import asyncio
from typing import Optional
from datetime import datetime
from asyncio import Queue, Lock

from app.database import get_db
from app.models.chapter import Chapter
from app.models.project import Project
from app.models.outline import Outline
from app.models.character import Character
from app.models.generation_history import GenerationHistory
from app.models.writing_style import WritingStyle
from app.models.analysis_task import AnalysisTask
from app.models.memory import PlotAnalysis, StoryMemory
from app.models.batch_generation_task import BatchGenerationTask
from app.models.regeneration_task import RegenerationTask
from app.schemas.chapter import (
    ChapterCreate,
    ChapterUpdate,
    ChapterResponse,
    ChapterListResponse,
    ChapterGenerateRequest,
    BatchGenerateRequest,
    BatchGenerateResponse,
    BatchGenerateStatusResponse,
    ExpansionPlanUpdate
)
from app.schemas.regeneration import (
    ChapterRegenerateRequest,
    RegenerationTaskResponse,
    RegenerationTaskStatus
)
from app.services.ai_service import AIService
from app.services.prompt_service import prompt_service, PromptService, WritingStyleManager
from app.services.plot_analyzer import PlotAnalyzer
from app.services.memory_service import memory_service
from app.services.chapter_regenerator import ChapterRegenerator
from app.logger import get_logger
from app.api.settings import get_user_ai_service
from app.utils.sse_response import create_sse_response

router = APIRouter(prefix="/chapters", tags=["ç« èŠ‚ç®¡ç†"])
logger = get_logger(__name__)

# å…¨å±€æ•°æ®åº“å†™å…¥é”ï¼ˆæ¯ä¸ªç”¨æˆ·ä¸€ä¸ªé”ï¼Œç”¨äºä¿æŠ¤SQLiteå†™å…¥æ“ä½œï¼‰
db_write_locks: dict[str, Lock] = {}


async def verify_project_access(project_id: str, user_id: str, db: AsyncSession) -> Project:
    """
    éªŒè¯ç”¨æˆ·æ˜¯å¦æœ‰æƒè®¿é—®æŒ‡å®šé¡¹ç›®
    
    Args:
        project_id: é¡¹ç›®ID
        user_id: ç”¨æˆ·ID
        db: æ•°æ®åº“ä¼šè¯
        
    Returns:
        Project: é¡¹ç›®å¯¹è±¡
        
    Raises:
        HTTPException: 401 æœªç™»å½•ï¼Œ404 é¡¹ç›®ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®
    """
    if not user_id:
        raise HTTPException(status_code=401, detail="æœªç™»å½•")
    
    result = await db.execute(
        select(Project).where(
            Project.id == project_id,
            Project.user_id == user_id
        )
    )
    project = result.scalar_one_or_none()
    
    if not project:
        logger.warning(f"é¡¹ç›®è®¿é—®è¢«æ‹’ç»: project_id={project_id}, user_id={user_id}")
        raise HTTPException(status_code=404, detail="é¡¹ç›®ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®")
    
    return project


async def get_db_write_lock(user_id: str) -> Lock:
    """è·å–æˆ–åˆ›å»ºç”¨æˆ·çš„æ•°æ®åº“å†™å…¥é”"""
    if user_id not in db_write_locks:
        db_write_locks[user_id] = Lock()
        logger.debug(f"ğŸ”’ ä¸ºç”¨æˆ· {user_id} åˆ›å»ºæ•°æ®åº“å†™å…¥é”")
    return db_write_locks[user_id]


@router.post("", response_model=ChapterResponse, summary="åˆ›å»ºç« èŠ‚")
async def create_chapter(
    chapter: ChapterCreate,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """åˆ›å»ºæ–°çš„ç« èŠ‚"""
    # éªŒè¯ç”¨æˆ·æƒé™å’Œé¡¹ç›®æ˜¯å¦å­˜åœ¨
    user_id = getattr(request.state, 'user_id', None)
    project = await verify_project_access(chapter.project_id, user_id, db)
    
    # è®¡ç®—å­—æ•°(å¤„ç†contentå¯èƒ½ä¸ºNoneçš„æƒ…å†µ)
    word_count = len(chapter.content) if chapter.content else 0
    
    db_chapter = Chapter(
        **chapter.model_dump(),
        word_count=word_count
    )
    db.add(db_chapter)
    
    # æ›´æ–°é¡¹ç›®çš„å½“å‰å­—æ•°
    project.current_words = project.current_words + word_count
    
    await db.commit()
    await db.refresh(db_chapter)
    return db_chapter


@router.get("/project/{project_id}", response_model=ChapterListResponse, summary="è·å–é¡¹ç›®çš„æ‰€æœ‰ç« èŠ‚")
async def get_project_chapters(
    project_id: str,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """è·å–æŒ‡å®šé¡¹ç›®çš„æ‰€æœ‰ç« èŠ‚ï¼ˆå¸¦å¤§çº²ä¿¡æ¯ï¼‰"""
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    await verify_project_access(project_id, user_id, db)
    
    # è·å–æ€»æ•°
    count_result = await db.execute(
        select(func.count(Chapter.id)).where(Chapter.project_id == project_id)
    )
    total = count_result.scalar_one()
    
    # è·å–ç« èŠ‚åˆ—è¡¨ï¼ŒåŒæ—¶åŠ è½½å…³è”çš„å¤§çº²ä¿¡æ¯
    result = await db.execute(
        select(Chapter)
        .where(Chapter.project_id == project_id)
        .order_by(Chapter.chapter_number)
    )
    chapters = result.scalars().all()
    
    # è·å–æ‰€æœ‰å¤§çº²ä¿¡æ¯ï¼ˆç”¨äºå¡«å……outline_titleï¼‰
    outline_ids = [ch.outline_id for ch in chapters if ch.outline_id]
    outlines_map = {}
    if outline_ids:
        outlines_result = await db.execute(
            select(Outline).where(Outline.id.in_(outline_ids))
        )
        outlines_map = {o.id: o for o in outlines_result.scalars().all()}
    
    # ä¸ºæ‰€æœ‰ç« èŠ‚æ·»åŠ å¤§çº²ä¿¡æ¯ï¼ˆç»Ÿä¸€å¤„ç†ï¼‰
    chapters_with_outline = []
    for chapter in chapters:
        chapter_dict = {
            "id": chapter.id,
            "project_id": chapter.project_id,
            "chapter_number": chapter.chapter_number,
            "title": chapter.title,
            "content": chapter.content,
            "summary": chapter.summary,
            "word_count": chapter.word_count,
            "status": chapter.status,
            "outline_id": chapter.outline_id,
            "sub_index": chapter.sub_index,
            "expansion_plan": chapter.expansion_plan,
            "created_at": chapter.created_at,
            "updated_at": chapter.updated_at,
        }
        
        # æ·»åŠ å¤§çº²ä¿¡æ¯
        if chapter.outline_id and chapter.outline_id in outlines_map:
            outline = outlines_map[chapter.outline_id]
            chapter_dict["outline_title"] = outline.title
            chapter_dict["outline_order"] = outline.order_index
        else:
            chapter_dict["outline_title"] = None
            chapter_dict["outline_order"] = None
        
        chapters_with_outline.append(chapter_dict)
    
    return ChapterListResponse(total=total, items=chapters_with_outline)


@router.get("/{chapter_id}", response_model=ChapterResponse, summary="è·å–ç« èŠ‚è¯¦æƒ…")
async def get_chapter(
    chapter_id: str,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """æ ¹æ®IDè·å–ç« èŠ‚è¯¦æƒ…"""
    result = await db.execute(
        select(Chapter).where(Chapter.id == chapter_id)
    )
    chapter = result.scalar_one_or_none()
    
    if not chapter:
        raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
    
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    await verify_project_access(chapter.project_id, user_id, db)
    
    return chapter


@router.get("/{chapter_id}/navigation", summary="è·å–ç« èŠ‚å¯¼èˆªä¿¡æ¯")
async def get_chapter_navigation(
    chapter_id: str,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """
    è·å–ç« èŠ‚çš„å¯¼èˆªä¿¡æ¯ï¼ˆä¸Šä¸€ç« /ä¸‹ä¸€ç« ï¼‰
    ç”¨äºç« èŠ‚é˜…è¯»å™¨çš„ç¿»é¡µåŠŸèƒ½
    """
    # è·å–å½“å‰ç« èŠ‚
    result = await db.execute(
        select(Chapter).where(Chapter.id == chapter_id)
    )
    current_chapter = result.scalar_one_or_none()
    
    if not current_chapter:
        raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
    
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    await verify_project_access(current_chapter.project_id, user_id, db)
    
    # è·å–ä¸Šä¸€ç« 
    prev_result = await db.execute(
        select(Chapter)
        .where(Chapter.project_id == current_chapter.project_id)
        .where(Chapter.chapter_number < current_chapter.chapter_number)
        .order_by(Chapter.chapter_number.desc())
        .limit(1)
    )
    prev_chapter = prev_result.scalar_one_or_none()
    
    # è·å–ä¸‹ä¸€ç« 
    next_result = await db.execute(
        select(Chapter)
        .where(Chapter.project_id == current_chapter.project_id)
        .where(Chapter.chapter_number > current_chapter.chapter_number)
        .order_by(Chapter.chapter_number.asc())
        .limit(1)
    )
    next_chapter = next_result.scalar_one_or_none()
    
    return {
        "current": {
            "id": current_chapter.id,
            "chapter_number": current_chapter.chapter_number,
            "title": current_chapter.title
        },
        "previous": {
            "id": prev_chapter.id,
            "chapter_number": prev_chapter.chapter_number,
            "title": prev_chapter.title
        } if prev_chapter else None,
        "next": {
            "id": next_chapter.id,
            "chapter_number": next_chapter.chapter_number,
            "title": next_chapter.title
        } if next_chapter else None
    }


@router.put("/{chapter_id}", response_model=ChapterResponse, summary="æ›´æ–°ç« èŠ‚")
async def update_chapter(
    chapter_id: str,
    chapter_update: ChapterUpdate,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """æ›´æ–°ç« èŠ‚ä¿¡æ¯"""
    result = await db.execute(
        select(Chapter).where(Chapter.id == chapter_id)
    )
    chapter = result.scalar_one_or_none()
    
    if not chapter:
        raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
    
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    await verify_project_access(chapter.project_id, user_id, db)
    
    # è®°å½•æ—§å­—æ•°
    old_word_count = chapter.word_count or 0
    
    # æ›´æ–°å­—æ®µ
    update_data = chapter_update.model_dump(exclude_unset=True)
    for field, value in update_data.items():
        setattr(chapter, field, value)
    
    # å¦‚æœå†…å®¹æ›´æ–°äº†ï¼Œé‡æ–°è®¡ç®—å­—æ•°ï¼ˆåŒ…æ‹¬æ¸…ç©ºå†…å®¹çš„æƒ…å†µï¼‰
    if "content" in update_data:
        new_word_count = len(chapter.content) if chapter.content else 0
        chapter.word_count = new_word_count
        
        # æ›´æ–°é¡¹ç›®å­—æ•°
        result = await db.execute(
            select(Project).where(Project.id == chapter.project_id)
        )
        project = result.scalar_one_or_none()
        if project:
            project.current_words = project.current_words - old_word_count + new_word_count
        
        # å¦‚æœå†…å®¹è¢«æ¸…ç©ºï¼Œæ¸…ç†ç›¸å…³æ•°æ®
        if not chapter.content or chapter.content.strip() == "":
            chapter.status = "draft"
            
            # æ¸…ç†åˆ†æä»»åŠ¡
            analysis_tasks_result = await db.execute(
                select(AnalysisTask).where(AnalysisTask.chapter_id == chapter_id)
            )
            analysis_tasks = analysis_tasks_result.scalars().all()
            for task in analysis_tasks:
                await db.delete(task)
            
            # æ¸…ç†åˆ†æç»“æœ
            plot_analysis_result = await db.execute(
                select(PlotAnalysis).where(PlotAnalysis.chapter_id == chapter_id)
            )
            plot_analyses = plot_analysis_result.scalars().all()
            for analysis in plot_analyses:
                await db.delete(analysis)
            
            # æ¸…ç†æ•…äº‹è®°å¿†ï¼ˆå…³ç³»æ•°æ®åº“ï¼‰
            story_memories_result = await db.execute(
                select(StoryMemory).where(StoryMemory.chapter_id == chapter_id)
            )
            story_memories = story_memories_result.scalars().all()
            for memory in story_memories:
                await db.delete(memory)
            
            # æ¸…ç†å‘é‡æ•°æ®åº“ä¸­çš„è®°å¿†æ•°æ®
            try:
                await memory_service.delete_chapter_memories(
                    user_id=user_id,
                    project_id=chapter.project_id,
                    chapter_id=chapter_id
                )
                logger.info(f"âœ… å·²æ¸…ç†ç« èŠ‚ {chapter_id[:8]} çš„å‘é‡è®°å¿†æ•°æ®")
            except Exception as e:
                logger.warning(f"âš ï¸ æ¸…ç†å‘é‡è®°å¿†æ•°æ®å¤±è´¥: {str(e)}")
            
            logger.info(f"ğŸ—‘ï¸ ç« èŠ‚ {chapter_id[:8]} å†…å®¹å·²æ¸…ç©ºï¼Œå·²æ¸…ç†åˆ†æå’Œè®°å¿†æ•°æ®")
    
    await db.commit()
    await db.refresh(chapter)
    
    chapter_dict = {
        "id": chapter.id,
        "project_id": chapter.project_id,
        "chapter_number": chapter.chapter_number,
        "title": chapter.title,
        "content": chapter.content,
        "summary": chapter.summary,
        "word_count": chapter.word_count,
        "status": chapter.status,
        "outline_id": chapter.outline_id,
        "sub_index": chapter.sub_index,
        "expansion_plan": chapter.expansion_plan,
        "created_at": chapter.created_at,
        "updated_at": chapter.updated_at,
        "outline_title": None,
        "outline_order": None
    }
    
    # å¦‚æœç« èŠ‚å…³è”äº†å¤§çº²ï¼ŒæŸ¥è¯¢å¤§çº²ä¿¡æ¯
    if chapter.outline_id:
        outline_result = await db.execute(
            select(Outline).where(Outline.id == chapter.outline_id)
        )
        outline = outline_result.scalar_one_or_none()
        if outline:
            chapter_dict["outline_title"] = outline.title
            chapter_dict["outline_order"] = outline.order_index
    
    return chapter_dict


@router.delete("/{chapter_id}", summary="åˆ é™¤ç« èŠ‚")
async def delete_chapter(
    chapter_id: str,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """åˆ é™¤ç« èŠ‚"""
    result = await db.execute(
        select(Chapter).where(Chapter.id == chapter_id)
    )
    chapter = result.scalar_one_or_none()
    
    if not chapter:
        raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
    
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    await verify_project_access(chapter.project_id, user_id, db)
    
    # æ›´æ–°é¡¹ç›®å­—æ•°
    result = await db.execute(
        select(Project).where(Project.id == chapter.project_id)
    )
    project = result.scalar_one_or_none()
    if project:
        project.current_words = max(0, project.current_words - chapter.word_count)
    
    # ğŸ—‘ï¸ æ¸…ç†å‘é‡æ•°æ®åº“ä¸­çš„è®°å¿†æ•°æ®
    try:
        await memory_service.delete_chapter_memories(
            user_id=user_id,
            project_id=chapter.project_id,
            chapter_id=chapter_id
        )
        logger.info(f"âœ… å·²æ¸…ç†ç« èŠ‚ {chapter_id[:8]} çš„å‘é‡è®°å¿†æ•°æ®")
    except Exception as e:
        logger.warning(f"âš ï¸ æ¸…ç†å‘é‡è®°å¿†æ•°æ®å¤±è´¥: {str(e)}")
        # ä¸é˜»æ–­åˆ é™¤æµç¨‹ï¼Œç»§ç»­æ‰§è¡Œ
    
    # åˆ é™¤ç« èŠ‚ï¼ˆå…³ç³»æ•°æ®åº“ä¸­çš„è®°å¿†ä¼šè¢«çº§è”åˆ é™¤ï¼‰
    await db.delete(chapter)
    await db.commit()
    
    return {"message": "ç« èŠ‚åˆ é™¤æˆåŠŸ"}


async def check_prerequisites(db: AsyncSession, chapter: Chapter) -> tuple[bool, str, list[Chapter]]:
    """
    æ£€æŸ¥ç« èŠ‚å‰ç½®æ¡ä»¶
    
    Args:
        db: æ•°æ®åº“ä¼šè¯
        chapter: å½“å‰ç« èŠ‚
        
    Returns:
        (å¯å¦ç”Ÿæˆ, é”™è¯¯ä¿¡æ¯, å‰ç½®ç« èŠ‚åˆ—è¡¨)
    """
    # å¦‚æœæ˜¯ç¬¬ä¸€ç« ï¼Œæ— éœ€æ£€æŸ¥å‰ç½®
    if chapter.chapter_number == 1:
        return True, "", []
    
    # æŸ¥è¯¢æ‰€æœ‰å‰ç½®ç« èŠ‚ï¼ˆåºå·å°äºå½“å‰ç« èŠ‚çš„ï¼‰
    result = await db.execute(
        select(Chapter)
        .where(Chapter.project_id == chapter.project_id)
        .where(Chapter.chapter_number < chapter.chapter_number)
        .order_by(Chapter.chapter_number)
    )
    previous_chapters = result.scalars().all()
    
    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å‰ç½®ç« èŠ‚éƒ½æœ‰å†…å®¹
    incomplete_chapters = [
        ch for ch in previous_chapters
        if not ch.content or ch.content.strip() == ""
    ]
    
    if incomplete_chapters:
        missing_numbers = [str(ch.chapter_number) for ch in incomplete_chapters]
        error_msg = f"éœ€è¦å…ˆå®Œæˆå‰ç½®ç« èŠ‚ï¼šç¬¬ {', '.join(missing_numbers)} ç« "
        return False, error_msg, previous_chapters
    
    return True, "", previous_chapters


async def build_smart_chapter_context(
    db: AsyncSession,
    project_id: str,
    current_chapter_number: int,
    user_id: str
) -> dict:
    """
    æ™ºèƒ½æ„å»ºç« èŠ‚ç”Ÿæˆä¸Šä¸‹æ–‡ï¼ˆæ”¯æŒæµ·é‡ç« èŠ‚åœºæ™¯ï¼‰
    
    ç­–ç•¥ï¼š
    1. æ•…äº‹éª¨æ¶ï¼šæ¯50ç« é‡‡æ ·1ç« ï¼ˆæ ‡é¢˜+æ‘˜è¦ï¼‰
    2. ç›¸å…³å†å²ï¼šé€šè¿‡chapter_summaryè®°å¿†è¯­ä¹‰æ£€ç´¢15ä¸ªæœ€ç›¸å…³ç« èŠ‚
    3. è¿‘æœŸæ¦‚è¦ï¼šæœ€è¿‘30ç« çš„ç®€è¦æ‘˜è¦ï¼ˆ200å­—/ç« ï¼‰
    4. æœ€è¿‘å®Œæ•´ï¼šæœ€è¿‘3ç« çš„å®Œæ•´å†…å®¹
    
    Args:
        db: æ•°æ®åº“ä¼šè¯
        project_id: é¡¹ç›®ID
        current_chapter_number: å½“å‰ç« èŠ‚åºå·
        user_id: ç”¨æˆ·ID
        
    Returns:
        åŒ…å«å„éƒ¨åˆ†ä¸Šä¸‹æ–‡çš„å­—å…¸
    """
    context_parts = {
        'story_skeleton': '',      # æ•…äº‹éª¨æ¶
        'relevant_history': '',    # ç›¸å…³å†å²ç« èŠ‚
        'recent_summary': '',      # è¿‘æœŸæ¦‚è¦
        'recent_full': '',         # æœ€è¿‘å®Œæ•´å†…å®¹
        'stats': {}                # ç»Ÿè®¡ä¿¡æ¯
    }
    
    try:
        # 1. è·å–æ‰€æœ‰å·²å®Œæˆçš„å‰ç½®ç« èŠ‚ï¼ˆåªå–IDå’Œåºå·ï¼‰
        all_chapters_result = await db.execute(
            select(Chapter.id, Chapter.chapter_number, Chapter.title)
            .where(Chapter.project_id == project_id)
            .where(Chapter.chapter_number < current_chapter_number)
            .where(Chapter.content != None)
            .where(Chapter.content != "")
            .order_by(Chapter.chapter_number)
        )

        all_chapters_info = all_chapters_result.all()
        total_previous = len(all_chapters_info)
        
        if total_previous == 0:
            logger.info("ğŸ“š è¿™æ˜¯ç¬¬ä¸€ç« ï¼Œæ— éœ€æ„å»ºå‰ç½®ä¸Šä¸‹æ–‡")
            return context_parts
        
        logger.info(f"ğŸ“š å¼€å§‹æ„å»ºæ™ºèƒ½ä¸Šä¸‹æ–‡ï¼šå…±{total_previous}ç« å‰ç½®å†…å®¹")
        
        # 2. æ„å»ºæ•…äº‹éª¨æ¶ï¼ˆæ¯50ç« é‡‡æ ·ï¼‰
        skeleton_chapters = []
        if total_previous > 50:
            sample_interval = 50
            skeleton_indices = list(range(0, total_previous, sample_interval))
            
            for idx in skeleton_indices:
                chapter_info = all_chapters_info[idx]
                # è·å–ç« èŠ‚æ‘˜è¦ï¼ˆä¼˜å…ˆä»chapter_summaryè®°å¿†è·å–ï¼‰
                summary_result = await db.execute(
                    select(StoryMemory.content)
                    .where(StoryMemory.project_id == project_id)
                    .where(StoryMemory.chapter_id == chapter_info.id)
                    .where(StoryMemory.memory_type == 'chapter_summary')
                    .limit(1)
                )
                summary_row = summary_result.scalar_one_or_none()
                summary = summary_row if summary_row else "ï¼ˆæ— æ‘˜è¦ï¼‰"
                
                skeleton_chapters.append({
                    'number': chapter_info.chapter_number,
                    'title': chapter_info.title,
                    'summary': summary
                })
            
            context_parts['story_skeleton'] = "ã€æ•…äº‹éª¨æ¶ã€‘\n" + "\n".join([
                f"ç¬¬{ch['number']}ç« ã€Š{ch['title']}ã€‹ï¼š{ch['summary']}"
                for ch in skeleton_chapters
            ])
            logger.info(f"  âœ… æ•…äº‹éª¨æ¶ï¼šé‡‡æ ·{len(skeleton_chapters)}ç« ï¼ˆæ¯50ç« 1ä¸ªï¼‰")
        
        # 3. è¯­ä¹‰æ£€ç´¢ç›¸å…³å†å²ç« èŠ‚ï¼ˆä½¿ç”¨chapter_summaryè®°å¿†ï¼‰
        # è·å–å½“å‰ç« èŠ‚çš„å¤§çº²ä½œä¸ºæŸ¥è¯¢
        current_outline_result = await db.execute(
            select(Outline.content)
            .where(Outline.project_id == project_id)
            .where(Outline.order_index == current_chapter_number)
        )
        current_outline = current_outline_result.scalar_one_or_none()
        
        if current_outline and total_previous > 3:
            # ä½¿ç”¨è®°å¿†æœåŠ¡è¿›è¡Œè¯­ä¹‰æ£€ç´¢
            relevant_memories = await memory_service.search_memories(
                user_id=user_id,
                project_id=project_id,
                query=current_outline,
                memory_types=['chapter_summary'],
                limit=15,  # æ£€ç´¢15ä¸ªæœ€ç›¸å…³çš„ç« èŠ‚
                min_importance=0.0  # ä¸è¿‡æ»¤é‡è¦æ€§ï¼Œä¾èµ–è¯­ä¹‰ç›¸å…³åº¦
            )
            
            if relevant_memories:
                relevant_chapters_text = []
                for mem in relevant_memories:
                    # è·å–ç« èŠ‚ä¿¡æ¯
                    chapter_result = await db.execute(
                        select(Chapter.chapter_number, Chapter.title)
                        .where(Chapter.id == mem['metadata'].get('chapter_id'))
                    )
                    chapter_info = chapter_result.first()
                    if chapter_info:
                        relevant_chapters_text.append(
                            f"ç¬¬{chapter_info.chapter_number}ç« ã€Š{chapter_info.title}ã€‹ï¼š{mem['content']} "
                            f"(ç›¸å…³åº¦:{mem['similarity']:.2f})"
                        )
                
                context_parts['relevant_history'] = "ã€ç›¸å…³å†å²ç« èŠ‚ã€‘\n" + "\n".join(relevant_chapters_text)
                logger.info(f"  âœ… ç›¸å…³å†å²ï¼šè¯­ä¹‰æ£€ç´¢åˆ°{len(relevant_chapters_text)}ç« ")
        
        # 4. è¿‘æœŸæ¦‚è¦ï¼ˆæœ€è¿‘30ç« ï¼Œæ¯ç« 200å­—æ‘˜è¦ï¼‰
        recent_summary_count = min(30, total_previous)
        recent_for_summary = all_chapters_info[-recent_summary_count:] if total_previous > 3 else []
        
        if recent_for_summary and len(recent_for_summary) > 3:  # è‡³å°‘è¦æœ‰3ç« æ‰åšæ‘˜è¦
            recent_summaries = []
            for chapter_info in recent_for_summary[:-3]:  # æ’é™¤æœ€å3ç« ï¼ˆå®ƒä»¬ä¼šå®Œæ•´å±•ç¤ºï¼‰
                # ä¼˜å…ˆè·å–chapter_summaryè®°å¿†
                summary_result = await db.execute(
                    select(StoryMemory.content)
                    .where(StoryMemory.project_id == project_id)
                    .where(StoryMemory.chapter_id == chapter_info.id)
                    .where(StoryMemory.memory_type == 'chapter_summary')
                    .limit(1)
                )
                summary = summary_result.scalar_one_or_none()
                
                if summary:
                    recent_summaries.append(
                        f"ç¬¬{chapter_info.chapter_number}ç« ã€Š{chapter_info.title}ã€‹ï¼š{summary}"
                    )
            
            if recent_summaries:
                context_parts['recent_summary'] = "ã€è¿‘æœŸç« èŠ‚æ¦‚è¦ã€‘\n" + "\n".join(recent_summaries)
                logger.info(f"  âœ… è¿‘æœŸæ¦‚è¦ï¼š{len(recent_summaries)}ç« æ‘˜è¦")
        
        # 5. æœ€è¿‘å®Œæ•´å†…å®¹ï¼ˆæœ€è¿‘3ç« ï¼‰
        recent_full_count = min(3, total_previous)
        recent_full_chapters = all_chapters_info[-recent_full_count:]
        
        # è·å–å®Œæ•´å†…å®¹
        recent_full_texts = []
        for chapter_info in recent_full_chapters:
            chapter_result = await db.execute(
                select(Chapter.content)
                .where(Chapter.id == chapter_info.id)
            )
            content = chapter_result.scalar_one_or_none()
            if content:
                recent_full_texts.append(
                    f"=== ç¬¬{chapter_info.chapter_number}ç« ï¼š{chapter_info.title} ===\n{content}"
                )
        
        context_parts['recent_full'] = "ã€æœ€è¿‘ç« èŠ‚å®Œæ•´å†…å®¹ã€‘\n" + "\n\n".join(recent_full_texts)
        logger.info(f"  âœ… æœ€è¿‘å®Œæ•´ï¼š{len(recent_full_texts)}ç« å…¨æ–‡")
        
        # 6. ç»Ÿè®¡ä¿¡æ¯
        context_parts['stats'] = {
            'total_previous': total_previous,
            'skeleton_samples': len(skeleton_chapters),
            'relevant_history': len(relevant_memories) if current_outline and total_previous > 3 else 0,
            'recent_summaries': len(recent_summaries) if recent_for_summary and len(recent_for_summary) > 3 else 0,
            'recent_full': len(recent_full_texts)
        }
        
        # è®¡ç®—æ€»é•¿åº¦
        total_length = sum([
            len(context_parts['story_skeleton']),
            len(context_parts['relevant_history']),
            len(context_parts['recent_summary']),
            len(context_parts['recent_full'])
        ])
        context_parts['stats']['total_length'] = total_length
        
        logger.info(f"ğŸ“Š æ™ºèƒ½ä¸Šä¸‹æ–‡æ„å»ºå®Œæˆï¼šæ€»é•¿åº¦ {total_length} å­—ç¬¦")
        
    except Exception as e:
        logger.error(f"âŒ æ„å»ºæ™ºèƒ½ä¸Šä¸‹æ–‡å¤±è´¥: {str(e)}", exc_info=True)
    
    return context_parts


@router.get("/{chapter_id}/can-generate", summary="æ£€æŸ¥ç« èŠ‚æ˜¯å¦å¯ä»¥ç”Ÿæˆ")
async def check_can_generate(
    chapter_id: str,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """
    æ£€æŸ¥ç« èŠ‚æ˜¯å¦æ»¡è¶³ç”Ÿæˆæ¡ä»¶
    è¿”å›å¯ç”ŸæˆçŠ¶æ€å’Œå‰ç½®ç« èŠ‚ä¿¡æ¯
    """
    # è·å–ç« èŠ‚
    result = await db.execute(
        select(Chapter).where(Chapter.id == chapter_id)
    )
    chapter = result.scalar_one_or_none()
    if not chapter:
        raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
    
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    await verify_project_access(chapter.project_id, user_id, db)
    
    # æ£€æŸ¥å‰ç½®æ¡ä»¶
    can_generate, error_msg, previous_chapters = await check_prerequisites(db, chapter)
    
    # æ„å»ºå‰ç½®ç« èŠ‚ä¿¡æ¯
    previous_info = [
        {
            "id": ch.id,
            "chapter_number": ch.chapter_number,
            "title": ch.title,
            "has_content": bool(ch.content and ch.content.strip()),
            "word_count": ch.word_count or 0
        }
        for ch in previous_chapters
    ]
    
    return {
        "can_generate": can_generate,
        "reason": error_msg if not can_generate else "",
        "previous_chapters": previous_info,
        "chapter_number": chapter.chapter_number
    }


async def analyze_chapter_background(
    chapter_id: str,
    user_id: str,
    project_id: str,
    task_id: str,
    ai_service: AIService
):
    """
    åå°å¼‚æ­¥åˆ†æç« èŠ‚ï¼ˆæ”¯æŒå¹¶å‘ï¼Œä½¿ç”¨é”ä¿æŠ¤æ•°æ®åº“å†™å…¥ï¼‰
    
    Args:
        chapter_id: ç« èŠ‚ID
        user_id: ç”¨æˆ·ID
        project_id: é¡¹ç›®ID
        task_id: ä»»åŠ¡ID
        ai_service: AIæœåŠ¡å®ä¾‹
    """
    db_session = None
    write_lock = await get_db_write_lock(user_id)
    
    try:
        logger.info(f"ğŸ” å¼€å§‹åˆ†æç« èŠ‚: {chapter_id}, ä»»åŠ¡ID: {task_id}")
        
        # åˆ›å»ºç‹¬ç«‹æ•°æ®åº“ä¼šè¯
        from app.database import get_engine
        from sqlalchemy.ext.asyncio import async_sessionmaker, AsyncSession
        
        engine = await get_engine(user_id)
        AsyncSessionLocal = async_sessionmaker(
            engine,
            class_=AsyncSession,
            expire_on_commit=False
        )
        db_session = AsyncSessionLocal()
        
        # 1. è·å–ä»»åŠ¡ï¼ˆè¯»æ“ä½œï¼‰
        task_result = await db_session.execute(
            select(AnalysisTask).where(AnalysisTask.id == task_id)
        )
        task = task_result.scalar_one_or_none()
        
        if not task:
            logger.error(f"âŒ ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
            return
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ï¼ˆå†™æ“ä½œï¼Œéœ€è¦é”ï¼‰
        async with write_lock:
            task.status = 'running'
            task.started_at = datetime.now()
            task.progress = 10
            await db_session.commit()
        
        # 2. è·å–ç« èŠ‚ä¿¡æ¯ï¼ˆè¯»æ“ä½œï¼‰
        chapter_result = await db_session.execute(
            select(Chapter).where(Chapter.id == chapter_id)
        )
        chapter = chapter_result.scalar_one_or_none()
        if not chapter or not chapter.content:
            async with write_lock:
                task.status = 'failed'
                task.error_message = 'ç« èŠ‚ä¸å­˜åœ¨æˆ–å†…å®¹ä¸ºç©º'
                task.completed_at = datetime.now()
                await db_session.commit()
            logger.error(f"âŒ ç« èŠ‚ä¸å­˜åœ¨æˆ–å†…å®¹ä¸ºç©º: {chapter_id}")
            return
        
        async with write_lock:
            task.progress = 20
            await db_session.commit()
        
        # 3. ä½¿ç”¨PlotAnalyzeråˆ†æç« èŠ‚
        analyzer = PlotAnalyzer(ai_service)
        analysis_result = await analyzer.analyze_chapter(
            chapter_number=chapter.chapter_number,
            title=chapter.title,
            content=chapter.content,
            word_count=chapter.word_count or len(chapter.content)
        )
        
        if not analysis_result:
            async with write_lock:
                task.status = 'failed'
                task.error_message = 'AIåˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—'
                task.completed_at = datetime.now()
                await db_session.commit()
            logger.error(f"âŒ AIåˆ†æå¤±è´¥: {chapter_id}")
            return
        
        async with write_lock:
            task.progress = 60
            await db_session.commit()
        
        # 4. ä¿å­˜åˆ†æç»“æœåˆ°æ•°æ®åº“ï¼ˆå†™æ“ä½œï¼Œéœ€è¦é”ï¼‰
        async with write_lock:
            existing_analysis_result = await db_session.execute(
                select(PlotAnalysis).where(PlotAnalysis.chapter_id == chapter_id)
            )
            existing_analysis = existing_analysis_result.scalar_one_or_none()
            
            if existing_analysis:
                # æ›´æ–°ç°æœ‰è®°å½•
                logger.info(f"  æ›´æ–°ç°æœ‰åˆ†æè®°å½•: {existing_analysis.id}")
                existing_analysis.plot_stage = analysis_result.get('plot_stage', 'å‘å±•')
                existing_analysis.conflict_level = analysis_result.get('conflict', {}).get('level', 0)
                existing_analysis.conflict_types = analysis_result.get('conflict', {}).get('types', [])
                existing_analysis.emotional_tone = analysis_result.get('emotional_arc', {}).get('primary_emotion', '')
                existing_analysis.emotional_intensity = analysis_result.get('emotional_arc', {}).get('intensity', 0) / 10.0
                existing_analysis.hooks = analysis_result.get('hooks', [])
                existing_analysis.hooks_count = len(analysis_result.get('hooks', []))
                existing_analysis.foreshadows = analysis_result.get('foreshadows', [])
                existing_analysis.foreshadows_planted = sum(1 for f in analysis_result.get('foreshadows', []) if f.get('type') == 'planted')
                existing_analysis.foreshadows_resolved = sum(1 for f in analysis_result.get('foreshadows', []) if f.get('type') == 'resolved')
                existing_analysis.plot_points = analysis_result.get('plot_points', [])
                existing_analysis.plot_points_count = len(analysis_result.get('plot_points', []))
                existing_analysis.character_states = analysis_result.get('character_states', [])
                existing_analysis.scenes = analysis_result.get('scenes', [])
                existing_analysis.pacing = analysis_result.get('pacing', 'moderate')
                existing_analysis.overall_quality_score = analysis_result.get('scores', {}).get('overall', 0)
                existing_analysis.pacing_score = analysis_result.get('scores', {}).get('pacing', 0)
                existing_analysis.engagement_score = analysis_result.get('scores', {}).get('engagement', 0)
                existing_analysis.coherence_score = analysis_result.get('scores', {}).get('coherence', 0)
                existing_analysis.analysis_report = analyzer.generate_analysis_summary(analysis_result)
                existing_analysis.suggestions = analysis_result.get('suggestions', [])
                existing_analysis.dialogue_ratio = analysis_result.get('dialogue_ratio', 0)
                existing_analysis.description_ratio = analysis_result.get('description_ratio', 0)
            else:
                # åˆ›å»ºæ–°è®°å½•
                logger.info(f"  åˆ›å»ºæ–°çš„åˆ†æè®°å½•")
                plot_analysis = PlotAnalysis(
                    chapter_id=chapter_id,
                    project_id=project_id,
                    plot_stage=analysis_result.get('plot_stage', 'å‘å±•'),
                    conflict_level=analysis_result.get('conflict', {}).get('level', 0),
                    conflict_types=analysis_result.get('conflict', {}).get('types', []),
                    emotional_tone=analysis_result.get('emotional_arc', {}).get('primary_emotion', ''),
                    emotional_intensity=analysis_result.get('emotional_arc', {}).get('intensity', 0) / 10.0,
                    hooks=analysis_result.get('hooks', []),
                    hooks_count=len(analysis_result.get('hooks', [])),
                    foreshadows=analysis_result.get('foreshadows', []),
                    foreshadows_planted=sum(1 for f in analysis_result.get('foreshadows', []) if f.get('type') == 'planted'),
                    foreshadows_resolved=sum(1 for f in analysis_result.get('foreshadows', []) if f.get('type') == 'resolved'),
                    plot_points=analysis_result.get('plot_points', []),
                    plot_points_count=len(analysis_result.get('plot_points', [])),
                    character_states=analysis_result.get('character_states', []),
                    scenes=analysis_result.get('scenes', []),
                    pacing=analysis_result.get('pacing', 'moderate'),
                    overall_quality_score=analysis_result.get('scores', {}).get('overall', 0),
                    pacing_score=analysis_result.get('scores', {}).get('pacing', 0),
                    engagement_score=analysis_result.get('scores', {}).get('engagement', 0),
                    coherence_score=analysis_result.get('scores', {}).get('coherence', 0),
                    analysis_report=analyzer.generate_analysis_summary(analysis_result),
                    suggestions=analysis_result.get('suggestions', []),
                    dialogue_ratio=analysis_result.get('dialogue_ratio', 0),
                    description_ratio=analysis_result.get('description_ratio', 0)
                )
                db_session.add(plot_analysis)
            
            await db_session.commit()
            
            task.progress = 80
            await db_session.commit()
        
        # 5. æå–è®°å¿†å¹¶ä¿å­˜åˆ°å‘é‡æ•°æ®åº“ï¼ˆä¼ å…¥ç« èŠ‚å†…å®¹ç”¨äºè®¡ç®—ä½ç½®ï¼‰
        memories = analyzer.extract_memories_from_analysis(
            analysis=analysis_result,
            chapter_id=chapter_id,
            chapter_number=chapter.chapter_number,
            chapter_content=chapter.content or "",
            chapter_title=chapter.title or ""
        )
        
        # å…ˆåˆ é™¤è¯¥ç« èŠ‚çš„æ—§è®°å¿†ï¼ˆå†™æ“ä½œï¼Œéœ€è¦é”ï¼‰
        async with write_lock:
            old_memories_result = await db_session.execute(
                select(StoryMemory).where(StoryMemory.chapter_id == chapter_id)
            )
            old_memories = old_memories_result.scalars().all()
            for old_mem in old_memories:
                await db_session.delete(old_mem)
            await db_session.commit()
            logger.info(f"  åˆ é™¤æ—§è®°å¿†: {len(old_memories)}æ¡")
        
        # å‡†å¤‡æ‰¹é‡æ·»åŠ çš„è®°å¿†æ•°æ®ï¼ˆä¸éœ€è¦é”ï¼‰
        memory_records = []
        for mem in memories:
            memory_id = f"{chapter_id}_{mem['type']}_{len(memory_records)}"
            memory_records.append({
                'id': memory_id,
                'content': mem['content'],
                'type': mem['type'],
                'metadata': mem['metadata']
            })
            
        # ä¿å­˜åˆ°å…³ç³»æ•°æ®åº“ï¼ˆå†™æ“ä½œï¼Œéœ€è¦é”ï¼‰
        async with write_lock:
            for mem in memories:
                memory_id = memory_records[memories.index(mem)]['id']
                text_position = mem['metadata'].get('text_position', -1)
                text_length = mem['metadata'].get('text_length', 0)
                
                story_memory = StoryMemory(
                    id=memory_id,
                    project_id=project_id,
                    chapter_id=chapter_id,
                    memory_type=mem['type'],
                    content=mem['content'],
                    title=mem['title'],
                    importance_score=mem['metadata'].get('importance_score', 0.5),
                    tags=mem['metadata'].get('tags', []),
                    is_foreshadow=mem['metadata'].get('is_foreshadow', 0),
                    story_timeline=chapter.chapter_number,
                    chapter_position=text_position,
                    text_length=text_length,
                    related_characters=mem['metadata'].get('related_characters', []),
                    related_locations=mem['metadata'].get('related_locations', [])
                )
                db_session.add(story_memory)
                
                if text_position >= 0:
                    logger.debug(f"  ä¿å­˜è®°å¿† {memory_id}: position={text_position}, length={text_length}")
            
            await db_session.commit()
        
        # æ‰¹é‡æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
        if memory_records:
            added_count = await memory_service.batch_add_memories(
                user_id=user_id,
                project_id=project_id,
                memories=memory_records
            )
            logger.info(f"âœ… æ·»åŠ {added_count}æ¡è®°å¿†åˆ°å‘é‡åº“")
        
        # æœ€ç»ˆæ›´æ–°ä»»åŠ¡çŠ¶æ€ï¼ˆå†™æ“ä½œï¼Œéœ€è¦é”ï¼‰- å¢åŠ é‡è¯•æœºåˆ¶
        update_success = False
        for retry in range(3):
            try:
                async with write_lock:
                    task.progress = 100
                    task.status = 'completed'
                    task.completed_at = datetime.now()
                    await db_session.commit()
                    update_success = True
                    logger.info(f"âœ… ç« èŠ‚åˆ†æå®Œæˆ: {chapter_id}, æå–{len(memories)}æ¡è®°å¿†")
                    break
            except Exception as commit_error:
                logger.error(f"âŒ æäº¤ä»»åŠ¡å®ŒæˆçŠ¶æ€å¤±è´¥(é‡è¯•{retry+1}/3): {str(commit_error)}")
                if retry < 2:
                    await asyncio.sleep(0.1)
                else:
                    logger.error(f"âŒ æ— æ³•æ›´æ–°ä»»åŠ¡ä¸ºcompletedçŠ¶æ€: {task_id}")
                    # å³ä½¿å¤±è´¥ä¹Ÿä¸æŠ›å‡ºå¼‚å¸¸ï¼Œå› ä¸ºåˆ†ææœ¬èº«å·²ç»å®Œæˆ
        
        if not update_success:
            logger.warning(f"âš ï¸  ç« èŠ‚åˆ†æå®Œæˆä½†çŠ¶æ€æ›´æ–°å¤±è´¥: {chapter_id}")
        
    except Exception as e:
        logger.error(f"âŒ åå°åˆ†æå¼‚å¸¸: {str(e)}", exc_info=True)
        # ç¡®ä¿ä»»åŠ¡çŠ¶æ€è¢«æ›´æ–°ä¸ºfailedï¼ˆå†™æ“ä½œï¼Œéœ€è¦é”ï¼‰
        if db_session:
            # å¤šæ¬¡é‡è¯•æ›´æ–°ä»»åŠ¡çŠ¶æ€
            for retry in range(3):
                try:
                    async with write_lock:
                        # é‡æ–°è·å–ä»»åŠ¡ï¼ˆå¯èƒ½æ˜¯æ—§ä¼šè¯å¯¼è‡´çš„é—®é¢˜ï¼‰
                        task_result = await db_session.execute(
                            select(AnalysisTask).where(AnalysisTask.id == task_id)
                        )
                        task = task_result.scalar_one_or_none()
                        if task:
                            task.status = 'failed'
                            task.error_message = str(e)[:500]
                            task.completed_at = datetime.now()
                            task.progress = 0
                            await db_session.commit()
                            logger.info(f"âœ… ä»»åŠ¡çŠ¶æ€å·²æ›´æ–°ä¸ºfailed: {task_id} (é‡è¯•{retry+1}æ¬¡)")
                            break
                        else:
                            logger.error(f"âŒ æ— æ³•æ‰¾åˆ°ä»»åŠ¡è¿›è¡ŒçŠ¶æ€æ›´æ–°: {task_id}")
                            break
                except Exception as update_error:
                    logger.error(f"âŒ æ›´æ–°ä»»åŠ¡çŠ¶æ€å¤±è´¥(é‡è¯•{retry+1}/3): {str(update_error)}")
                    if retry < 2:
                        await asyncio.sleep(0.1)  # çŸ­æš‚ç­‰å¾…åé‡è¯•
                    else:
                        logger.error(f"âŒ ä»»åŠ¡çŠ¶æ€æ›´æ–°å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°: {task_id}")
    finally:
        if db_session:
            await db_session.close()


@router.post("/{chapter_id}/generate-stream", summary="AIåˆ›ä½œç« èŠ‚å†…å®¹ï¼ˆæµå¼ï¼‰")
async def generate_chapter_content_stream(
    chapter_id: str,
    request: Request,
    background_tasks: BackgroundTasks,
    generate_request: ChapterGenerateRequest = ChapterGenerateRequest(),
    user_ai_service: AIService = Depends(get_user_ai_service)
):
    """
    æ ¹æ®å¤§çº²ã€å‰ç½®ç« èŠ‚å†…å®¹å’Œé¡¹ç›®ä¿¡æ¯AIåˆ›ä½œç« èŠ‚å®Œæ•´å†…å®¹ï¼ˆæµå¼è¿”å›ï¼‰
    è¦æ±‚ï¼šå¿…é¡»æŒ‰é¡ºåºç”Ÿæˆï¼Œç¡®ä¿å‰ç½®ç« èŠ‚éƒ½å·²å®Œæˆ
    
    è¯·æ±‚ä½“å‚æ•°ï¼š
    - style_id: å¯é€‰ï¼ŒæŒ‡å®šä½¿ç”¨çš„å†™ä½œé£æ ¼IDã€‚ä¸æä¾›åˆ™ä¸ä½¿ç”¨ä»»ä½•é£æ ¼
    - target_word_count: å¯é€‰ï¼Œç›®æ ‡å­—æ•°ï¼Œé»˜è®¤3000å­—ï¼ŒèŒƒå›´500-10000å­—
    - enable_mcp: å¯é€‰ï¼Œæ˜¯å¦å¯ç”¨MCPå·¥å…·å¢å¼ºï¼Œé»˜è®¤True
    
    æ³¨æ„ï¼šæ­¤å‡½æ•°ä¸ä½¿ç”¨ä¾èµ–æ³¨å…¥çš„dbï¼Œè€Œæ˜¯åœ¨ç”Ÿæˆå™¨å†…éƒ¨åˆ›å»ºç‹¬ç«‹çš„æ•°æ®åº“ä¼šè¯
    ä»¥é¿å…æµå¼å“åº”æœŸé—´çš„è¿æ¥æ³„æ¼é—®é¢˜
    """
    style_id = generate_request.style_id
    target_word_count = generate_request.target_word_count or 3000
    enable_mcp = generate_request.enable_mcp if hasattr(generate_request, 'enable_mcp') else True
    custom_model = generate_request.model if hasattr(generate_request, 'model') else None
    temp_narrative_perspective = generate_request.narrative_perspective if hasattr(generate_request, 'narrative_perspective') else None
    # é¢„å…ˆéªŒè¯ç« èŠ‚å­˜åœ¨æ€§ï¼ˆä½¿ç”¨ä¸´æ—¶ä¼šè¯ï¼‰
    async for temp_db in get_db(request):
        try:
            result = await temp_db.execute(
                select(Chapter).where(Chapter.id == chapter_id)
            )
            chapter = result.scalar_one_or_none()
            if not chapter:
                raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
            
            # æ£€æŸ¥å‰ç½®æ¡ä»¶
            can_generate, error_msg, previous_chapters = await check_prerequisites(temp_db, chapter)
            if not can_generate:
                raise HTTPException(status_code=400, detail=error_msg)
            
            # ä¿å­˜å‰ç½®ç« èŠ‚æ•°æ®ä¾›ç”Ÿæˆå™¨ä½¿ç”¨
            previous_chapters_data = [
                {
                    'id': ch.id,
                    'chapter_number': ch.chapter_number,
                    'title': ch.title,
                    'content': ch.content
                }
                for ch in previous_chapters
            ]
        finally:
            await temp_db.close()
        break
    
    async def event_generator():
        # åœ¨ç”Ÿæˆå™¨å†…éƒ¨åˆ›å»ºç‹¬ç«‹çš„æ•°æ®åº“ä¼šè¯
        db_session = None
        db_committed = False
        # è·å–å½“å‰ç”¨æˆ·IDï¼ˆåœ¨ç”Ÿæˆå™¨å¤–éƒ¨å°±éœ€è¦ï¼‰
        current_user_id = getattr(request.state, "user_id", "system")
        
        try:
            # åˆ›å»ºæ–°çš„æ•°æ®åº“ä¼šè¯
            async for db_session in get_db(request):
                # é‡æ–°è·å–ç« èŠ‚ä¿¡æ¯
                chapter_result = await db_session.execute(
                    select(Chapter).where(Chapter.id == chapter_id)
                )
                current_chapter = chapter_result.scalar_one_or_none()
                if not current_chapter:
                    yield f"data: {json.dumps({'type': 'error', 'error': 'ç« èŠ‚ä¸å­˜åœ¨'}, ensure_ascii=False)}\n\n"
                    return
            
                # è·å–é¡¹ç›®ä¿¡æ¯
                project_result = await db_session.execute(
                    select(Project).where(Project.id == current_chapter.project_id)
                )
                project = project_result.scalar_one_or_none()
                if not project:
                    yield f"data: {json.dumps({'type': 'error', 'error': 'é¡¹ç›®ä¸å­˜åœ¨'}, ensure_ascii=False)}\n\n"
                    return
                
                # è·å–é¡¹ç›®çš„å¤§çº²æ¨¡å¼
                outline_mode = project.outline_mode if project else 'one-to-many'
                logger.info(f"ğŸ“‹ é¡¹ç›®å¤§çº²æ¨¡å¼: {outline_mode}")
                
                # è·å–å¯¹åº”çš„å¤§çº²
                outline_result = await db_session.execute(
                    select(Outline)
                    .where(Outline.project_id == current_chapter.project_id)
                    .where(Outline.order_index == current_chapter.chapter_number)
                    .execution_options(populate_existing=True)
                )
                outline = outline_result.scalar_one_or_none()
                
                # è·å–æ‰€æœ‰å¤§çº²ç”¨äºä¸Šä¸‹æ–‡
                all_outlines_result = await db_session.execute(
                    select(Outline)
                    .where(Outline.project_id == current_chapter.project_id)
                    .order_by(Outline.order_index)
                    .execution_options(populate_existing=True)
                )
                all_outlines = all_outlines_result.scalars().all()
                outlines_context = "\n".join([
                    f"ç¬¬{o.order_index}ç«  {o.title}: {o.content[:100]}..."
                    for o in all_outlines
                ])
                
                # è·å–è§’è‰²ä¿¡æ¯
                characters_result = await db_session.execute(
                    select(Character).where(Character.project_id == current_chapter.project_id)
                )
                characters = characters_result.scalars().all()
                characters_info = "\n".join([
                    f"- {c.name}({'ç»„ç»‡' if c.is_organization else 'è§’è‰²'}, {c.role_type}): {c.personality[:100] if c.personality else ''}"
                    for c in characters
                ])
                
                # è·å–å†™ä½œé£æ ¼
                style_content = ""
                if style_id:
                    # ä½¿ç”¨æŒ‡å®šçš„é£æ ¼
                    style_result = await db_session.execute(
                        select(WritingStyle).where(WritingStyle.id == style_id)
                    )
                    style = style_result.scalar_one_or_none()
                    if style:
                        # éªŒè¯é£æ ¼æ˜¯å¦å¯ç”¨ï¼šå…¨å±€é¢„è®¾é£æ ¼ï¼ˆuser_idä¸ºNULLï¼‰æˆ–è€…å½“å‰ç”¨æˆ·çš„è‡ªå®šä¹‰é£æ ¼
                        if style.user_id is None or style.user_id == current_user_id:
                            style_content = style.prompt_content or ""
                            style_type = "å…¨å±€é¢„è®¾" if style.user_id is None else "ç”¨æˆ·è‡ªå®šä¹‰"
                            logger.info(f"ä½¿ç”¨æŒ‡å®šé£æ ¼: {style.name} ({style_type})")
                        else:
                            logger.warning(f"é£æ ¼ {style_id} ä¸å±äºå½“å‰é¡¹ç›®ï¼Œæ— æ³•ä½¿ç”¨")
                    else:
                        logger.warning(f"æœªæ‰¾åˆ°é£æ ¼ {style_id}")
                else:
                    logger.info("æœªæŒ‡å®šå†™ä½œé£æ ¼ï¼Œä½¿ç”¨åŸå§‹æç¤ºè¯")
                
                # ğŸš€ ä½¿ç”¨æ™ºèƒ½ä¸Šä¸‹æ–‡æ„å»ºï¼ˆæ”¯æŒæµ·é‡ç« èŠ‚ï¼‰
                smart_context = await build_smart_chapter_context(
                    db=db_session,
                    project_id=project.id,
                    current_chapter_number=current_chapter.chapter_number,
                    user_id=current_user_id
                )
                
                # ç»„è£…ä¸Šä¸‹æ–‡
                previous_content = ""
                if smart_context['story_skeleton']:
                    previous_content += smart_context['story_skeleton'] + "\n\n"
                if smart_context['relevant_history']:
                    previous_content += smart_context['relevant_history'] + "\n\n"
                if smart_context['recent_summary']:
                    previous_content += smart_context['recent_summary'] + "\n\n"
                if smart_context['recent_full']:
                    previous_content += smart_context['recent_full']
                    
                    # ğŸ”§ ä¿®å¤1-næ¨¡å¼é‡å¤é—®é¢˜: æå–ä¸Šä¸€ç« ç»“å°¾ä½œä¸ºç²¾ç¡®è¡”æ¥ç‚¹
                    if current_chapter.chapter_number > 1:
                        recent_chapters_parts = smart_context['recent_full'].split('===')
                        if len(recent_chapters_parts) >= 2:
                            # æå–æœ€åä¸€ç« (recent_fullåŒ…å«æœ€è¿‘3ç« ,æœ€åä¸€ä¸ªæ˜¯ä¸Šä¸€ç« )
                            last_chapter_content = recent_chapters_parts[-1].strip()
                            # æå–ç»“å°¾500å­—
                            last_chapter_ending = last_chapter_content[-600:] if len(last_chapter_content) > 600 else last_chapter_content
                            
                            previous_content += f"\n\n{'='*50}\n"
                            previous_content += f"ã€âš ï¸ ä¸Šä¸€ç« ç»“å°¾å†…å®¹(å¿…è¯»,ç”¨äºè¡”æ¥)ã€‘\n"
                            previous_content += f"ä»¥ä¸‹æ˜¯ä¸Šä¸€ç« (ç¬¬{current_chapter.chapter_number-1}ç« )çš„ç»“å°¾éƒ¨åˆ†:\n\n"
                            previous_content += last_chapter_ending + "\n"
                            previous_content += f"\n{'='*50}\n"
                            previous_content += f"ã€æœ¬ç« ({current_chapter.chapter_number}ç« )åˆ›ä½œè¦æ±‚ã€‘\n"
                            previous_content += f"1. å¿…é¡»è‡ªç„¶æ‰¿æ¥ä¸Šè¿°ç»“å°¾çš„åœºæ™¯/æƒ…èŠ‚/å¯¹è¯\n"
                            previous_content += f"2. ä¸è¦é‡å¤å™è¿°ä¸Šä¸€ç« å·²ç»å‘ç”Ÿçš„äº‹ä»¶\n"
                            previous_content += f"3. ä»æ–°çš„æƒ…èŠ‚ç‚¹ã€æ–°çš„åœºæ™¯æˆ–æ–°çš„æ—¶é—´ç‚¹å¼€å§‹\n"
                            previous_content += f"4. è§’è‰²çŠ¶æ€è¦å»¶ç»­,ä¸è¦é‡æ–°ä»‹ç»å·²å‡ºåœºè§’è‰²\n"
                            previous_content += f"{'='*50}\n"
                
                # æ—¥å¿—è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
                stats = smart_context['stats']
                logger.info(f"ğŸ“Š æ™ºèƒ½ä¸Šä¸‹æ–‡ç»Ÿè®¡:")
                logger.info(f"  - å‰ç½®ç« èŠ‚æ€»æ•°: {stats.get('total_previous', 0)}")
                logger.info(f"  - æ•…äº‹éª¨æ¶é‡‡æ ·: {stats.get('skeleton_samples', 0)}ç« ")
                logger.info(f"  - ç›¸å…³å†å²æ£€ç´¢: {stats.get('relevant_history', 0)}ç« ")
                logger.info(f"  - è¿‘æœŸç« èŠ‚æ¦‚è¦: {stats.get('recent_summaries', 0)}ç« ")
                logger.info(f"  - æœ€è¿‘å®Œæ•´å†…å®¹: {stats.get('recent_full', 0)}ç« ")
                logger.info(f"  - ä¸Šä¸‹æ–‡æ€»é•¿åº¦: {stats.get('total_length', 0)}å­—ç¬¦")
                
                # ğŸ§  æ„å»ºè®°å¿†å¢å¼ºä¸Šä¸‹æ–‡
                logger.info(f"ğŸ§  å¼€å§‹æ„å»ºè®°å¿†å¢å¼ºä¸Šä¸‹æ–‡...")
                memory_context = await memory_service.build_context_for_generation(
                    user_id=current_user_id,
                    project_id=project.id,
                    current_chapter=current_chapter.chapter_number,
                    chapter_outline=outline.content if outline else current_chapter.summary or "",
                    character_names=[c.name for c in characters] if characters else None
                )
                
                # è®¡ç®—å„éƒ¨åˆ†çš„å­—ç¬¦é•¿åº¦
                context_lengths = {
                    'recent_context': len(memory_context.get('recent_context', '')),
                    'relevant_memories': len(memory_context.get('relevant_memories', '')),
                    'foreshadows': len(memory_context.get('foreshadows', '')),
                    'character_states': len(memory_context.get('character_states', '')),
                    'plot_points': len(memory_context.get('plot_points', ''))
                }
                total_memory_length = sum(context_lengths.values())
                
                logger.info(f"âœ… è®°å¿†ä¸Šä¸‹æ–‡æ„å»ºå®Œæˆ: {memory_context['stats']}")
                logger.info(f"ğŸ“ è®°å¿†ä¸Šä¸‹æ–‡é•¿åº¦ç»Ÿè®¡:")
                logger.info(f"  - æœ€è¿‘ç« èŠ‚è®°å¿†: {context_lengths['recent_context']} å­—ç¬¦")
                logger.info(f"  - è¯­ä¹‰ç›¸å…³è®°å¿†: {context_lengths['relevant_memories']} å­—ç¬¦")
                logger.info(f"  - æœªå®Œç»“ä¼ç¬”: {context_lengths['foreshadows']} å­—ç¬¦")
                logger.info(f"  - è§’è‰²çŠ¶æ€è®°å¿†: {context_lengths['character_states']} å­—ç¬¦")
                logger.info(f"  - é‡è¦æƒ…èŠ‚ç‚¹: {context_lengths['plot_points']} å­—ç¬¦")
                logger.info(f"  - è®°å¿†æ€»é•¿åº¦: {total_memory_length} å­—ç¬¦")
                logger.info(f"  - å‰ç½®ç« èŠ‚ä¸Šä¸‹æ–‡é•¿åº¦: {len(previous_content)} å­—ç¬¦")
                logger.info(f"  - æ€»ä¸Šä¸‹æ–‡é•¿åº¦(ä¼°ç®—): {total_memory_length + len(previous_content) + 2000} å­—ç¬¦")
            
                # å‘é€å¼€å§‹äº‹ä»¶
                yield f"data: {json.dumps({'type': 'start', 'message': 'å¼€å§‹AIåˆ›ä½œ...'}, ensure_ascii=False)}\n\n"
                
                # å‘é€åˆå§‹è¿›åº¦0%
                yield f"data: {json.dumps({'type': 'progress', 'progress': 0, 'message': 'å‡†å¤‡ç”Ÿæˆ...', 'status': 'processing'}, ensure_ascii=False)}\n\n"
                
                # ğŸ”§ MCPå·¥å…·å¢å¼ºï¼šæ”¶é›†ç« èŠ‚å‚è€ƒèµ„æ–™ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
                mcp_reference_materials = ""
                if enable_mcp and current_user_id:
                    try:
                        # 1ï¸âƒ£ é™é»˜æ£€æŸ¥å·¥å…·å¯ç”¨æ€§
                        from app.services.mcp_tool_service import mcp_tool_service
                        available_tools = await mcp_tool_service.get_user_enabled_tools(
                            user_id=current_user_id,
                            db_session=db_session
                        )
                        
                        # 2ï¸âƒ£ åªåœ¨æœ‰å·¥å…·æ—¶æ‰æ˜¾ç¤ºæ¶ˆæ¯å’Œè°ƒç”¨
                        if available_tools:
                            yield f"data: {json.dumps({'type': 'progress', 'message': 'ğŸ” ä½¿ç”¨MCPå·¥å…·æ”¶é›†å‚è€ƒèµ„æ–™...', 'progress': 28}, ensure_ascii=False)}\n\n"
                            
                            # æ„å»ºèµ„æ–™æ”¶é›†æç¤ºè¯
                            planning_prompt = f"""ä½ æ­£åœ¨ä¸ºå°è¯´ã€Š{project.title}ã€‹åˆ›ä½œç¬¬{current_chapter.chapter_number}ç« ã€Š{current_chapter.title}ã€‹ã€‚

ã€ç« èŠ‚å¤§çº²ã€‘
{outline.content if outline else current_chapter.summary or 'æš‚æ— å¤§çº²'}

ã€å°è¯´ä¿¡æ¯ã€‘
- é¢˜æï¼š{project.genre or 'æœªè®¾å®š'}
- ä¸»é¢˜ï¼š{project.theme or 'æœªè®¾å®š'}
- æ—¶ä»£èƒŒæ™¯ï¼š{project.world_time_period or 'æœªè®¾å®š'}
- åœ°ç†ä½ç½®ï¼š{project.world_location or 'æœªè®¾å®š'}

ã€ä»»åŠ¡ã€‘
è¯·ä½¿ç”¨å¯ç”¨å·¥å…·æœç´¢ç›¸å…³èƒŒæ™¯èµ„æ–™ï¼Œå¸®åŠ©åˆ›ä½œæ›´çœŸå®ã€æ›´æœ‰æ·±åº¦çš„ç« èŠ‚å†…å®¹ã€‚
ä½ å¯ä»¥æŸ¥è¯¢ï¼š
1. è¯¥ç« èŠ‚æ¶‰åŠçš„å†å²äº‹ä»¶æˆ–æ—¶ä»£èƒŒæ™¯
2. åœ°ç†ç¯å¢ƒå’Œåœºæ™¯æå†™å‚è€ƒ
3. ç›¸å…³é¢†åŸŸçš„ä¸“ä¸šçŸ¥è¯†ï¼ˆå¦‚æ­¦æœ¯ã€ç§‘æŠ€ã€é­”æ³•ç­‰ï¼‰
4. æ–‡åŒ–ä¹ ä¿—å’Œç”Ÿæ´»ç»†èŠ‚

è¯·æ ¹æ®ç« èŠ‚å†…å®¹ï¼Œæœ‰é’ˆå¯¹æ€§åœ°æŸ¥è¯¢1-2ä¸ªæœ€å…³é”®çš„é—®é¢˜ã€‚"""
                            
                            # è°ƒç”¨MCPå¢å¼ºçš„AIï¼ˆéæµå¼ï¼Œé™åˆ¶1è½®é¿å…è¶…æ—¶ï¼‰
                            planning_result = await user_ai_service.generate_text_with_mcp(
                                prompt=planning_prompt,
                                user_id=current_user_id,
                                db_session=db_session,
                                enable_mcp=True,
                                max_tool_rounds=1,  # âœ… å‡å°‘ä¸º1è½®ï¼Œé¿å…è¶…æ—¶
                                tool_choice="auto",
                                provider=None,
                                model=None
                            )
                            
                            # 3ï¸âƒ£ æå–å‚è€ƒèµ„æ–™å¹¶æ˜¾ç¤ºç»“æœ
                            if planning_result.get("tool_calls_made", 0) > 0:
                                tool_count = planning_result["tool_calls_made"]
                                yield f"data: {json.dumps({'type': 'progress', 'message': f'âœ… MCPå·¥å…·è°ƒç”¨æˆåŠŸï¼ˆ{tool_count}æ¬¡ï¼‰', 'progress': 32}, ensure_ascii=False)}\n\n"
                                mcp_reference_materials = planning_result.get("content", "")
                                logger.info(f"ğŸ“š MCPå·¥å…·æ”¶é›†å‚è€ƒèµ„æ–™ï¼š{len(mcp_reference_materials)} å­—ç¬¦")
                            else:
                                yield f"data: {json.dumps({'type': 'progress', 'message': 'â„¹ï¸ MCPæœªä½¿ç”¨å·¥å…·ï¼Œç»§ç»­', 'progress': 32}, ensure_ascii=False)}\n\n"
                        else:
                            logger.debug(f"ç”¨æˆ· {current_user_id} æœªå¯ç”¨MCPå·¥å…·ï¼Œè·³è¿‡MCPå¢å¼º")
                            # æœªå¯ç”¨MCPæ—¶ä¹Ÿå‘é€è¿›åº¦ï¼Œä¿æŒè¿è´¯æ€§
                            yield f"data: {json.dumps({'type': 'progress', 'message': 'å‡†å¤‡ç”Ÿæˆå†…å®¹...', 'progress': 10}, ensure_ascii=False)}\n\n"
                            
                    except Exception as e:
                        logger.warning(f"âš ï¸ MCPå·¥å…·è°ƒç”¨å¤±è´¥ï¼Œé™çº§ä¸ºåŸºç¡€æ¨¡å¼: {str(e)}")
                        yield f"data: {json.dumps({'type': 'progress', 'message': 'âš ï¸ MCPå·¥å…·æš‚æ—¶ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€æ¨¡å¼', 'progress': 10}, ensure_ascii=False)}\n\n"
                else:
                    # å¦‚æœæœªå¯ç”¨MCPï¼Œä¹Ÿå‘é€åŸºç¡€è¿›åº¦
                    yield f"data: {json.dumps({'type': 'progress', 'message': 'å¼€å§‹æ„å»ºåˆ›ä½œä¸Šä¸‹æ–‡...', 'progress': 10}, ensure_ascii=False)}\n\n"
                
                # ğŸ­ ç¡®å®šä½¿ç”¨çš„å™äº‹äººç§°ï¼ˆä¸´æ—¶æŒ‡å®š > é¡¹ç›®é»˜è®¤ > ç³»ç»Ÿé»˜è®¤ï¼‰
                chapter_perspective = (
                    temp_narrative_perspective or
                    project.narrative_perspective or
                    'ç¬¬ä¸‰äººç§°'
                )
                logger.info(f"ğŸ“ ä½¿ç”¨å™äº‹äººç§°: {chapter_perspective}")
                
                # ğŸ“‹ æ ¹æ®å¤§çº²æ¨¡å¼æ„å»ºå·®å¼‚åŒ–çš„ç« èŠ‚å¤§çº²ä¸Šä¸‹æ–‡
                chapter_outline_content = ""
                if outline_mode == 'one-to-one':
                    # ä¸€å¯¹ä¸€æ¨¡å¼ï¼šä½¿ç”¨å¤§çº²çš„ content
                    chapter_outline_content = outline.content if outline else current_chapter.summary or 'æš‚æ— å¤§çº²'
                    logger.info(f"âœï¸ ä¸€å¯¹ä¸€æ¨¡å¼ï¼šä½¿ç”¨å¤§çº²å†…å®¹ä½œä¸ºç« èŠ‚æŒ‡å¯¼")
                else:
                    # ä¸€å¯¹å¤šæ¨¡å¼ï¼šä¼˜å…ˆä½¿ç”¨ expansion_plan çš„è¯¦ç»†è§„åˆ’
                    if current_chapter.expansion_plan:
                        try:
                            plan = json.loads(current_chapter.expansion_plan)
                            chapter_outline_content = f"""ã€æœ¬ç« è¯¦ç»†è§„åˆ’ã€‘
å‰§æƒ…æ‘˜è¦ï¼š{plan.get('plot_summary', 'æ— ')}

å…³é”®äº‹ä»¶ï¼š
{chr(10).join(f'- {event}' for event in plan.get('key_events', []))}

è§’è‰²ç„¦ç‚¹ï¼š{', '.join(plan.get('character_focus', []))}

æƒ…æ„ŸåŸºè°ƒï¼š{plan.get('emotional_tone', 'æœªè®¾å®š')}

å™äº‹ç›®æ ‡ï¼š{plan.get('narrative_goal', 'æœªè®¾å®š')}

å†²çªç±»å‹ï¼š{plan.get('conflict_type', 'æœªè®¾å®š')}"""
                            
                            # å¯é€‰ï¼šé™„åŠ ç« èŠ‚ summary
                            if current_chapter.summary and current_chapter.summary.strip():
                                chapter_outline_content += f"\n\nã€ç« èŠ‚è¡¥å……è¯´æ˜ã€‘\n{current_chapter.summary}"
                            
                            # å¯é€‰ï¼šé™„åŠ å¤§çº²çš„èƒŒæ™¯ä¿¡æ¯
                            if outline:
                                chapter_outline_content += f"\n\nã€å¤§çº²èŠ‚ç‚¹èƒŒæ™¯ã€‘\n{outline.content}"
                            
                            logger.info(f"âœï¸ ä¸€å¯¹å¤šæ¨¡å¼ï¼šä½¿ç”¨expansion_planè¯¦ç»†è§„åˆ’ï¼ˆ{len(chapter_outline_content)}å­—ç¬¦ï¼‰")
                        except json.JSONDecodeError as e:
                            logger.warning(f"âš ï¸ expansion_planè§£æå¤±è´¥: {e}ï¼Œå›é€€åˆ°å¤§çº²å†…å®¹")
                            chapter_outline_content = outline.content if outline else current_chapter.summary or 'æš‚æ— å¤§çº²'
                    else:
                        # æ²¡æœ‰expansion_planï¼Œä½¿ç”¨å¤§çº²å†…å®¹
                        chapter_outline_content = outline.content if outline else current_chapter.summary or 'æš‚æ— å¤§çº²'
                        logger.warning(f"âš ï¸ ä¸€å¯¹å¤šæ¨¡å¼ä½†æ— expansion_planï¼Œä½¿ç”¨å¤§çº²å†…å®¹")
                
                # æ ¹æ®æ˜¯å¦æœ‰å‰ç½®å†…å®¹é€‰æ‹©ä¸åŒçš„æç¤ºè¯ï¼Œå¹¶åº”ç”¨å†™ä½œé£æ ¼ã€è®°å¿†å¢å¼ºå’ŒMCPå‚è€ƒèµ„æ–™ï¼ˆæ”¯æŒè‡ªå®šä¹‰ï¼‰
                if previous_content:
                    template = await PromptService.get_template("CHAPTER_GENERATION_WITH_CONTEXT", current_user_id, db_session)
                    base_prompt = PromptService.format_prompt(
                        template,
                        title=project.title,
                        theme=project.theme or '',
                        genre=project.genre or '',
                        narrative_perspective=chapter_perspective,
                        time_period=project.world_time_period or 'æœªè®¾å®š',
                        location=project.world_location or 'æœªè®¾å®š',
                        atmosphere=project.world_atmosphere or 'æœªè®¾å®š',
                        rules=project.world_rules or 'æœªè®¾å®š',
                        characters_info=characters_info or 'æš‚æ— è§’è‰²ä¿¡æ¯',
                        outlines_context=outlines_context,
                        previous_content=previous_content,
                        chapter_number=current_chapter.chapter_number,
                        chapter_title=current_chapter.title,
                        chapter_outline=chapter_outline_content,
                        target_word_count=target_word_count,
                        max_word_count=target_word_count + 1000,
                        memory_context=memory_context.get('recent_context', '') + "\n" + memory_context.get('relevant_memories', '') + "\n" + memory_context.get('foreshadows', '') + "\n" + memory_context.get('character_states', '') + "\n" + memory_context.get('plot_points', '') if memory_context else "æš‚æ— ç›¸å…³è®°å¿†"
                    )
                    # æ’å…¥æ¨¡å¼è¯´æ˜å’ŒMCPå‚è€ƒ
                    mode_instruction = "\n\nã€åˆ›ä½œæ¨¡å¼è¯´æ˜ã€‘\næœ¬ç« é‡‡ç”¨ç»†çº²æ¨¡å¼ï¼šæœ¬ç« æ˜¯å¤§çº²èŠ‚ç‚¹çš„ç»†åŒ–å±•å¼€ä¹‹ä¸€ã€‚è¯·ä¸¥æ ¼éµå¾ªä¸Šè¿°è¯¦ç»†è§„åˆ’ï¼ˆexpansion_planï¼‰ä¸­çš„å‰§æƒ…ç‚¹ã€è§’è‰²ç„¦ç‚¹ã€æƒ…æ„ŸåŸºè°ƒå’Œå™äº‹ç›®æ ‡ï¼Œç¡®ä¿ä¸æ•´ä½“è§„åˆ’ä¿æŒä¸€è‡´ï¼ŒåŒæ—¶è‡ªç„¶è¡”æ¥å‰æ–‡å†…å®¹ã€‚\n" if outline_mode == 'one-to-many' else "\n\nã€åˆ›ä½œæ¨¡å¼è¯´æ˜ã€‘\næœ¬ç« é‡‡ç”¨ä¸€å¯¹ä¸€æ¨¡å¼ï¼šä¸€ä¸ªå¤§çº²èŠ‚ç‚¹å¯¹åº”ä¸€ä¸ªç« èŠ‚ã€‚è¯·åœ¨æ‰¿æ¥å‰æ–‡çš„åŸºç¡€ä¸Šï¼Œå……åˆ†å±•å¼€å¤§çº²ä¸­çš„æƒ…èŠ‚ï¼Œä¿æŒå™äº‹çš„å®Œæ•´æ€§ã€‚\n"
                    mcp_text = ""
                    if mcp_reference_materials:
                        mcp_text = "\nã€ğŸ“š MCPå·¥å…·æœç´¢ - å‚è€ƒèµ„æ–™ã€‘\nä»¥ä¸‹æ˜¯é€šè¿‡MCPå·¥å…·æœç´¢åˆ°çš„ç›¸å…³å‚è€ƒèµ„æ–™ï¼Œå¯ç”¨äºä¸°å¯Œæƒ…èŠ‚å’Œç»†èŠ‚ï¼š\n\n" + mcp_reference_materials + "\n"
                    base_prompt = base_prompt.replace("æœ¬ç« ä¿¡æ¯ï¼š", mcp_text + mode_instruction + "\næœ¬ç« ä¿¡æ¯ï¼š")
                    # åº”ç”¨å†™ä½œé£æ ¼
                    if style_content:
                        prompt = WritingStyleManager.apply_style_to_prompt(base_prompt, style_content)
                    else:
                        prompt = base_prompt
                else:
                    template = await PromptService.get_template("CHAPTER_GENERATION", current_user_id, db_session)
                    base_prompt = PromptService.format_prompt(
                        template,
                        title=project.title,
                        theme=project.theme or '',
                        genre=project.genre or '',
                        narrative_perspective=chapter_perspective,
                        time_period=project.world_time_period or 'æœªè®¾å®š',
                        location=project.world_location or 'æœªè®¾å®š',
                        atmosphere=project.world_atmosphere or 'æœªè®¾å®š',
                        rules=project.world_rules or 'æœªè®¾å®š',
                        characters_info=characters_info or 'æš‚æ— è§’è‰²ä¿¡æ¯',
                        outlines_context=outlines_context,
                        chapter_number=current_chapter.chapter_number,
                        chapter_title=current_chapter.title,
                        chapter_outline=chapter_outline_content,
                        target_word_count=target_word_count,
                        max_word_count=target_word_count + 1000
                    )
                    # æ’å…¥æ¨¡å¼è¯´æ˜å’Œè®°å¿†ã€MCPå‚è€ƒ
                    mode_instruction = "\n\nã€åˆ›ä½œæ¨¡å¼è¯´æ˜ã€‘\næœ¬ç« é‡‡ç”¨ç»†çº²æ¨¡å¼ï¼šæœ¬ç« æ˜¯å¤§çº²èŠ‚ç‚¹çš„ç»†åŒ–å±•å¼€ä¹‹ä¸€ã€‚è¯·ä¸¥æ ¼éµå¾ªä¸Šè¿°è¯¦ç»†è§„åˆ’ä¸­çš„å‰§æƒ…ç‚¹ã€è§’è‰²ç„¦ç‚¹å’Œæƒ…æ„ŸåŸºè°ƒï¼Œç¡®ä¿ä¸æ•´ä½“è§„åˆ’ä¿æŒä¸€è‡´ã€‚\n" if outline_mode == 'one-to-many' else "\n\nã€åˆ›ä½œæ¨¡å¼è¯´æ˜ã€‘\næœ¬ç« é‡‡ç”¨ä¸€å¯¹ä¸€æ¨¡å¼ï¼šä¸€ä¸ªå¤§çº²èŠ‚ç‚¹å¯¹åº”ä¸€ä¸ªç« èŠ‚ã€‚è¯·å……åˆ†å±•å¼€å¤§çº²ä¸­çš„æƒ…èŠ‚ï¼Œæ³¨é‡å™äº‹çš„å®Œæ•´æ€§å’Œä¸°æ»¡åº¦ã€‚\n"
                    memory_text = ""
                    if memory_context:
                        memory_text = "\nã€ğŸ§  æ™ºèƒ½è®°å¿†ç³»ç»Ÿ - é‡è¦å‚è€ƒã€‘\n" + memory_context.get('recent_context', '') + "\n" + memory_context.get('relevant_memories', '') + "\n" + memory_context.get('foreshadows', '') + "\n" + memory_context.get('character_states', '') + "\n" + memory_context.get('plot_points', '')
                    mcp_text = ""
                    if mcp_reference_materials:
                        mcp_text = "\nã€ğŸ“š MCPå·¥å…·æœç´¢ - å‚è€ƒèµ„æ–™ã€‘\nä»¥ä¸‹æ˜¯é€šè¿‡MCPå·¥å…·æœç´¢åˆ°çš„ç›¸å…³å‚è€ƒèµ„æ–™ï¼Œå¯ç”¨äºä¸°å¯Œæƒ…èŠ‚å’Œç»†èŠ‚ï¼š\n\n" + mcp_reference_materials + "\n"
                    base_prompt = base_prompt.replace("æœ¬ç« ä¿¡æ¯ï¼š", memory_text + mcp_text + mode_instruction + "\n\næœ¬ç« ä¿¡æ¯ï¼š")
                    # åº”ç”¨å†™ä½œé£æ ¼
                    if style_content:
                        prompt = WritingStyleManager.apply_style_to_prompt(base_prompt, style_content)
                    else:
                        prompt = base_prompt
                
                if mcp_reference_materials:
                    logger.info(f"ğŸ“– å·²æ•´åˆMCPå‚è€ƒèµ„æ–™ï¼ˆ{len(mcp_reference_materials)}å­—ç¬¦ï¼‰åˆ°ç« èŠ‚ç”Ÿæˆæç¤ºè¯")
                
                logger.info(f"å¼€å§‹AIæµå¼åˆ›ä½œç« èŠ‚ {chapter_id}")
                
                # å‘é€å¼€å§‹ç”Ÿæˆçš„è¿›åº¦
                yield f"data: {json.dumps({'type': 'progress', 'progress': 35, 'message': 'å¼€å§‹AIåˆ›ä½œ...', 'status': 'processing'}, ensure_ascii=False)}\n\n"
                
                # å‡†å¤‡ç”Ÿæˆå‚æ•°
                generate_kwargs = {"prompt": prompt}
                if custom_model:
                    logger.info(f"  ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹: {custom_model}")
                    generate_kwargs["model"] = custom_model
                    # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨ç”¨æˆ·é…ç½®çš„AIæœåŠ¡ï¼Œæ¨¡å‹å‚æ•°ä¼šè¦†ç›–é»˜è®¤æ¨¡å‹
                    # å¦‚æœéœ€è¦åˆ‡æ¢providerï¼Œéœ€è¦åœ¨å‰ç«¯ä¼ é€’providerå‚æ•°
                
                # æµå¼ç”Ÿæˆå†…å®¹
                full_content = ""
                chunk_count = 0
                last_progress = 0
                
                async for chunk in user_ai_service.generate_text_stream(**generate_kwargs):
                    full_content += chunk
                    chunk_count += 1
                    
                    # å‘é€å†…å®¹å—
                    yield f"data: {json.dumps({'type': 'content', 'content': chunk}, ensure_ascii=False)}\n\n"
                    
                    # æ¯20ä¸ªchunkå‘é€ä¸€æ¬¡è¿›åº¦æ›´æ–°ï¼ˆæé«˜é¢‘ç‡ï¼‰
                    if chunk_count % 20 == 0:
                        current_word_count = len(full_content)
                        # æ ¹æ®ç›®æ ‡å­—æ•°ä¼°ç®—è¿›åº¦ï¼ˆ40%èµ·æ­¥ï¼Œæœ€é«˜95%ï¼Œä¸ºåç»­ä¿å­˜ç•™5%ï¼‰
                        estimated_progress = min(95, 40 + int((current_word_count / target_word_count) * 55))
                        
                        # åªåœ¨è¿›åº¦å˜åŒ–æ—¶å‘é€
                        if estimated_progress > last_progress:
                            progress_data = {
                                'type': 'progress',
                                'progress': estimated_progress,
                                'message': f'æ­£åœ¨åˆ›ä½œä¸­... å·²ç”Ÿæˆ {current_word_count} å­—',
                                'word_count': current_word_count,
                                'status': 'processing'
                            }
                            yield f"data: {json.dumps(progress_data, ensure_ascii=False)}\n\n"
                            last_progress = estimated_progress
                    
                    await asyncio.sleep(0)  # è®©å‡ºæ§åˆ¶æƒ
                
                # å‘é€ä¿å­˜è¿›åº¦
                yield f"data: {json.dumps({'type': 'progress', 'progress': 98, 'message': 'æ­£åœ¨ä¿å­˜ç« èŠ‚...', 'status': 'processing'}, ensure_ascii=False)}\n\n"
                
                # æ›´æ–°ç« èŠ‚å†…å®¹åˆ°æ•°æ®åº“
                old_word_count = current_chapter.word_count or 0
                current_chapter.content = full_content
                new_word_count = len(full_content)
                current_chapter.word_count = new_word_count
                current_chapter.status = "completed"
                
                # æ›´æ–°é¡¹ç›®å­—æ•°
                project.current_words = project.current_words - old_word_count + new_word_count
                
                # è®°å½•ç”Ÿæˆå†å²
                history = GenerationHistory(
                    project_id=current_chapter.project_id,
                    chapter_id=current_chapter.id,
                    prompt=f"åˆ›ä½œç« èŠ‚: ç¬¬{current_chapter.chapter_number}ç«  {current_chapter.title}",
                    generated_content=full_content[:500] if len(full_content) > 500 else full_content,
                    model="default"
                )
                db_session.add(history)
                
                await db_session.commit()
                db_committed = True
                await db_session.refresh(current_chapter)
                
                logger.info(f"æˆåŠŸåˆ›ä½œç« èŠ‚ {chapter_id}ï¼Œå…± {new_word_count} å­—")
                
                # åˆ›å»ºåˆ†æä»»åŠ¡
                analysis_task = AnalysisTask(
                    chapter_id=chapter_id,
                    user_id=current_user_id,
                    project_id=project.id,
                    status='pending',
                    progress=0
                )
                db_session.add(analysis_task)
                await db_session.commit()
                await db_session.refresh(analysis_task)
                
                task_id = analysis_task.id
                logger.info(f"ğŸ“‹ å·²åˆ›å»ºåˆ†æä»»åŠ¡: {task_id}")
                
                # çŸ­æš‚å»¶è¿Ÿç¡®ä¿SQLite WALå®Œæˆå†™å…¥
                await asyncio.sleep(0.05)
                
                # ç›´æ¥å¯åŠ¨åå°åˆ†æï¼ˆå¹¶å‘æ‰§è¡Œï¼‰
                background_tasks.add_task(
                    analyze_chapter_background,
                    chapter_id=chapter_id,
                    user_id=current_user_id,
                    project_id=project.id,
                    task_id=task_id,
                    ai_service=user_ai_service
                )
                
                # å‘é€æœ€ç»ˆè¿›åº¦100%
                yield f"data: {json.dumps({'type': 'progress', 'progress': 100, 'message': 'åˆ›ä½œå®Œæˆï¼', 'word_count': new_word_count, 'status': 'success'}, ensure_ascii=False)}\n\n"
                
                # å‘é€å®Œæˆäº‹ä»¶ï¼ˆåŒ…å«åˆ†æä»»åŠ¡IDï¼‰
                completion_data = {
                    'type': 'done',
                    'message': 'åˆ›ä½œå®Œæˆ',
                    'word_count': new_word_count,
                    'analysis_task_id': task_id
                }
                yield f"data: {json.dumps(completion_data, ensure_ascii=False)}\n\n"
                
                # å‘é€åˆ†æå¼€å§‹äº‹ä»¶
                analysis_started_data = {
                    'type': 'analysis_started',
                    'task_id': task_id,
                    'message': 'ç« èŠ‚åˆ†æå·²å¼€å§‹'
                }
                yield f"data: {json.dumps(analysis_started_data, ensure_ascii=False)}\n\n"
                
                break  # é€€å‡ºasync for db_sessionå¾ªç¯
        
        except GeneratorExit:
            # SSEè¿æ¥æ–­å¼€
            logger.warning("ç« èŠ‚ç”Ÿæˆå™¨è¢«æå‰å…³é—­ï¼ˆSSEæ–­å¼€ï¼‰")
            if db_session and not db_committed:
                try:
                    if db_session.in_transaction():
                        await db_session.rollback()
                        logger.info("ç« èŠ‚ç”Ÿæˆäº‹åŠ¡å·²å›æ»šï¼ˆGeneratorExitï¼‰")
                except Exception as e:
                    logger.error(f"GeneratorExitå›æ»šå¤±è´¥: {str(e)}")
        except Exception as e:
            logger.error(f"æµå¼åˆ›ä½œç« èŠ‚å¤±è´¥: {str(e)}")
            if db_session and not db_committed:
                try:
                    if db_session.in_transaction():
                        await db_session.rollback()
                        logger.info("ç« èŠ‚ç”Ÿæˆäº‹åŠ¡å·²å›æ»šï¼ˆå¼‚å¸¸ï¼‰")
                except Exception as rollback_error:
                    logger.error(f"å›æ»šå¤±è´¥: {str(rollback_error)}")
            yield f"data: {json.dumps({'type': 'error', 'error': str(e)}, ensure_ascii=False)}\n\n"
        finally:
            # ç¡®ä¿æ•°æ®åº“ä¼šè¯è¢«æ­£ç¡®å…³é—­
            if db_session:
                try:
                    # æœ€åæ£€æŸ¥ï¼šç¡®ä¿æ²¡æœ‰æœªæäº¤çš„äº‹åŠ¡
                    if not db_committed and db_session.in_transaction():
                        await db_session.rollback()
                        logger.warning("åœ¨finallyä¸­å‘ç°æœªæäº¤äº‹åŠ¡ï¼Œå·²å›æ»š")
                    
                    await db_session.close()
                    logger.info("æ•°æ®åº“ä¼šè¯å·²å…³é—­")
                except Exception as close_error:
                    logger.error(f"å…³é—­æ•°æ®åº“ä¼šè¯å¤±è´¥: {str(close_error)}")
                    # å¼ºåˆ¶å…³é—­
                    try:
                        await db_session.close()
                    except:
                        pass
    
    return create_sse_response(event_generator())


@router.get("/{chapter_id}/analysis/status", summary="æŸ¥è¯¢ç« èŠ‚åˆ†æä»»åŠ¡çŠ¶æ€")
async def get_analysis_task_status(
    chapter_id: str,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """
    æŸ¥è¯¢æŒ‡å®šç« èŠ‚çš„æœ€æ–°åˆ†æä»»åŠ¡çŠ¶æ€
    
    è‡ªåŠ¨æ¢å¤æœºåˆ¶ï¼š
    - å¦‚æœä»»åŠ¡çŠ¶æ€ä¸ºrunningä¸”è¶…è¿‡1åˆ†é’Ÿæœªæ›´æ–°ï¼Œè‡ªåŠ¨æ ‡è®°ä¸ºfailed
    - å¦‚æœä»»åŠ¡çŠ¶æ€ä¸ºpendingä¸”è¶…è¿‡2åˆ†é’Ÿæœªå¯åŠ¨ï¼Œè‡ªåŠ¨æ ‡è®°ä¸ºfailed
    
    è¿”å›:
    - has_task: æ˜¯å¦å­˜åœ¨åˆ†æä»»åŠ¡
    - task_id: ä»»åŠ¡IDï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    - status: pending/running/completed/failed/noneï¼ˆå¦‚æœä¸å­˜åœ¨åˆ™ä¸ºnoneï¼‰
    - progress: 0-100
    - error_message: é”™è¯¯ä¿¡æ¯(å¦‚æœå¤±è´¥)
    - auto_recovered: æ˜¯å¦è¢«è‡ªåŠ¨æ¢å¤
    - created_at: åˆ›å»ºæ—¶é—´
    - completed_at: å®Œæˆæ—¶é—´
    
    æ³¨æ„ï¼šå½“ç« èŠ‚ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®æ—¶è¿”å›404ï¼Œå½“æ²¡æœ‰åˆ†æä»»åŠ¡æ—¶è¿”å›has_task=false
    """
    from datetime import timedelta
    
    # å…ˆè·å–ç« èŠ‚ä»¥éªŒè¯å­˜åœ¨æ€§å’Œæƒé™
    chapter_result = await db.execute(
        select(Chapter).where(Chapter.id == chapter_id)
    )
    chapter = chapter_result.scalar_one_or_none()
    
    if not chapter:
        raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
    
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    await verify_project_access(chapter.project_id, user_id, db)
    
    # è·å–è¯¥ç« èŠ‚æœ€æ–°çš„åˆ†æä»»åŠ¡
    result = await db.execute(
        select(AnalysisTask)
        .where(AnalysisTask.chapter_id == chapter_id)
        .order_by(AnalysisTask.created_at.desc())
        .limit(1)
    )
    task = result.scalar_one_or_none()
    
    if not task:
        # è¿”å›æ— ä»»åŠ¡çŠ¶æ€ï¼Œè€Œä¸æ˜¯æŠ›å‡º404é”™è¯¯
        return {
            "has_task": False,
            "chapter_id": chapter_id,
            "status": "none",
            "progress": 0,
            "error_message": None,
            "auto_recovered": False,
            "task_id": None,
            "created_at": None,
            "started_at": None,
            "completed_at": None
        }
    
    auto_recovered = False
    current_time = datetime.now()
    
    # è‡ªåŠ¨æ¢å¤å¡ä½çš„ä»»åŠ¡
    if task.status == 'running':
        # å¦‚æœä»»åŠ¡åœ¨runningçŠ¶æ€è¶…è¿‡1åˆ†é’Ÿï¼Œæ ‡è®°ä¸ºå¤±è´¥
        if task.started_at and (current_time - task.started_at) > timedelta(minutes=1):
            task.status = 'failed'
            task.error_message = 'ä»»åŠ¡è¶…æ—¶ï¼ˆè¶…è¿‡1åˆ†é’Ÿæœªå®Œæˆï¼Œå·²è‡ªåŠ¨æ¢å¤ï¼‰'
            task.completed_at = current_time
            task.progress = 0
            auto_recovered = True
            await db.commit()
            await db.refresh(task)
            logger.warning(f"ğŸ”„ è‡ªåŠ¨æ¢å¤å¡ä½çš„ä»»åŠ¡: {task.id}, ç« èŠ‚: {chapter_id}")
    
    elif task.status == 'pending':
        # å¦‚æœä»»åŠ¡åœ¨pendingçŠ¶æ€è¶…è¿‡2åˆ†é’Ÿä»æœªå¼€å§‹ï¼Œæ ‡è®°ä¸ºå¤±è´¥
        if task.created_at and (current_time - task.created_at) > timedelta(minutes=2):
            task.status = 'failed'
            task.error_message = 'ä»»åŠ¡å¯åŠ¨è¶…æ—¶ï¼ˆè¶…è¿‡2åˆ†é’Ÿæœªå¯åŠ¨ï¼Œå·²è‡ªåŠ¨æ¢å¤ï¼‰'
            task.completed_at = current_time
            task.progress = 0
            auto_recovered = True
            await db.commit()
            await db.refresh(task)
            logger.warning(f"ğŸ”„ è‡ªåŠ¨æ¢å¤æœªå¯åŠ¨çš„ä»»åŠ¡: {task.id}, ç« èŠ‚: {chapter_id}")
    
    return {
        "has_task": True,
        "task_id": task.id,
        "chapter_id": task.chapter_id,
        "status": task.status,
        "progress": task.progress,
        "error_message": task.error_message,
        "auto_recovered": auto_recovered,
        "created_at": task.created_at.isoformat() if task.created_at else None,
        "started_at": task.started_at.isoformat() if task.started_at else None,
        "completed_at": task.completed_at.isoformat() if task.completed_at else None
    }


@router.get("/{chapter_id}/analysis", summary="è·å–ç« èŠ‚åˆ†æç»“æœ")
async def get_chapter_analysis(
    chapter_id: str,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """
    è·å–ç« èŠ‚çš„å®Œæ•´åˆ†æç»“æœ
    
    è¿”å›:
    - analysis_data: å®Œæ•´çš„åˆ†ææ•°æ®(JSON)
    - summary: åˆ†ææ‘˜è¦æ–‡æœ¬
    - memories: æå–çš„è®°å¿†åˆ—è¡¨
    - created_at: åˆ†ææ—¶é—´
    """
    # å…ˆè·å–ç« èŠ‚ä»¥éªŒè¯æƒé™
    chapter_result_check = await db.execute(
        select(Chapter).where(Chapter.id == chapter_id)
    )
    chapter_check = chapter_result_check.scalar_one_or_none()
    if chapter_check:
        # éªŒè¯ç”¨æˆ·æƒé™
        user_id = getattr(request.state, 'user_id', None)
        await verify_project_access(chapter_check.project_id, user_id, db)
    
    # è·å–åˆ†æç»“æœ
    analysis_result = await db.execute(
        select(PlotAnalysis)
        .where(PlotAnalysis.chapter_id == chapter_id)
        .order_by(PlotAnalysis.created_at.desc())
        .limit(1)
    )
    analysis = analysis_result.scalar_one_or_none()
    
    if not analysis:
        raise HTTPException(status_code=404, detail="è¯¥ç« èŠ‚æš‚æ— åˆ†æç»“æœ")
    
    # è·å–ç›¸å…³è®°å¿†
    memories_result = await db.execute(
        select(StoryMemory)
        .where(StoryMemory.chapter_id == chapter_id)
        .order_by(StoryMemory.importance_score.desc())
    )
    memories = memories_result.scalars().all()
    
    return {
        "chapter_id": chapter_id,
        "analysis": analysis.to_dict(),  # ä½¿ç”¨to_dict()æ–¹æ³•
        "memories": [
            {
                "id": mem.id,
                "type": mem.memory_type,
                "title": mem.title,
                "content": mem.content,
                "importance": mem.importance_score,
                "tags": mem.tags,
                "is_foreshadow": mem.is_foreshadow,
                "position": mem.chapter_position,
                "related_characters": mem.related_characters
            }
            for mem in memories
        ],
        "created_at": analysis.created_at.isoformat() if analysis.created_at else None
    }


@router.get("/{chapter_id}/annotations", summary="è·å–ç« èŠ‚æ ‡æ³¨æ•°æ®")
async def get_chapter_annotations(
    chapter_id: str,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """
    è·å–ç« èŠ‚çš„æ ‡æ³¨æ•°æ®ï¼ˆç”¨äºå‰ç«¯å±•ç¤ºæ ‡æ³¨ï¼‰
    
    è¿”å›æ ¼å¼åŒ–çš„æ ‡æ³¨åˆ—è¡¨ï¼ŒåŒ…å«ç²¾ç¡®ä½ç½®ä¿¡æ¯
    é€‚ç”¨äºç« èŠ‚å†…å®¹çš„å¯è§†åŒ–æ ‡æ³¨å±•ç¤º
    """
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    
    # è·å–ç« èŠ‚
    chapter_result = await db.execute(
        select(Chapter).where(Chapter.id == chapter_id)
    )
    chapter = chapter_result.scalar_one_or_none()
    
    if not chapter:
        raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
    
    # éªŒè¯é¡¹ç›®è®¿é—®æƒé™
    await verify_project_access(chapter.project_id, user_id, db)
    
    # è·å–åˆ†æç»“æœ
    analysis_result = await db.execute(
        select(PlotAnalysis)
        .where(PlotAnalysis.chapter_id == chapter_id)
        .order_by(PlotAnalysis.created_at.desc())
        .limit(1)
    )
    analysis = analysis_result.scalar_one_or_none()
    
    # è·å–è®°å¿†
    memories_result = await db.execute(
        select(StoryMemory)
        .where(StoryMemory.chapter_id == chapter_id)
        .order_by(StoryMemory.importance_score.desc())
    )
    memories = memories_result.scalars().all()
    
    # æ„å»ºæ ‡æ³¨æ•°æ®
    annotations = []
    
    for mem in memories:
        # ä¼˜å…ˆä»æ•°æ®åº“è¯»å–ä½ç½®ä¿¡æ¯
        position = mem.chapter_position if mem.chapter_position is not None else -1
        length = mem.text_length if hasattr(mem, 'text_length') and mem.text_length is not None else 0
        metadata_extra = {}
        
        # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰ä½ç½®ä¿¡æ¯ï¼Œå°è¯•ä»åˆ†ææ•°æ®ä¸­é‡æ–°è®¡ç®—
        if position == -1 and analysis and chapter.content:
            # æ ¹æ®è®°å¿†ç±»å‹ä»åˆ†ææ•°æ®ä¸­æŸ¥æ‰¾å¯¹åº”é¡¹
            if mem.memory_type == 'hook' and analysis.hooks:
                for hook in analysis.hooks:
                    # é€šè¿‡æ ‡é¢˜æˆ–å†…å®¹åŒ¹é…
                    if mem.title and hook.get('type') in mem.title:
                        keyword = hook.get('keyword', '')
                        if keyword:
                            pos = chapter.content.find(keyword)
                            if pos != -1:
                                position = pos
                                length = len(keyword)
                        metadata_extra["strength"] = hook.get('strength', 5)
                        metadata_extra["position_desc"] = hook.get('position', '')
                        break
            
            elif mem.memory_type == 'foreshadow' and analysis.foreshadows:
                for foreshadow in analysis.foreshadows:
                    if foreshadow.get('content') in mem.content:
                        keyword = foreshadow.get('keyword', '')
                        if keyword:
                            pos = chapter.content.find(keyword)
                            if pos != -1:
                                position = pos
                                length = len(keyword)
                        metadata_extra["foreshadow_type"] = foreshadow.get('type', 'planted')
                        metadata_extra["strength"] = foreshadow.get('strength', 5)
                        break
            
            elif mem.memory_type == 'plot_point' and analysis.plot_points:
                for plot_point in analysis.plot_points:
                    if plot_point.get('content') in mem.content:
                        keyword = plot_point.get('keyword', '')
                        if keyword:
                            pos = chapter.content.find(keyword)
                            if pos != -1:
                                position = pos
                                length = len(keyword)
                        break
        else:
            # å¦‚æœæ•°æ®åº“æœ‰ä½ç½®ï¼Œä¹Ÿä»åˆ†ææ•°æ®ä¸­æå–é¢å¤–çš„å…ƒæ•°æ®
            if analysis:
                if mem.memory_type == 'hook' and analysis.hooks:
                    for hook in analysis.hooks:
                        if mem.title and hook.get('type') in mem.title:
                            metadata_extra["strength"] = hook.get('strength', 5)
                            metadata_extra["position_desc"] = hook.get('position', '')
                            break
                
                elif mem.memory_type == 'foreshadow' and analysis.foreshadows:
                    for foreshadow in analysis.foreshadows:
                        if foreshadow.get('content') in mem.content:
                            metadata_extra["foreshadow_type"] = foreshadow.get('type', 'planted')
                            metadata_extra["strength"] = foreshadow.get('strength', 5)
                            break
        
        annotation = {
            "id": mem.id,
            "type": mem.memory_type,
            "title": mem.title,
            "content": mem.content,
            "importance": mem.importance_score or 0.5,
            "position": position,
            "length": length,
            "tags": mem.tags or [],
            "metadata": {
                "is_foreshadow": mem.is_foreshadow,
                "related_characters": mem.related_characters or [],
                "related_locations": mem.related_locations or [],
                **metadata_extra
            }
        }
        
        annotations.append(annotation)
    
    return {
        "chapter_id": chapter_id,
        "chapter_number": chapter.chapter_number,
        "title": chapter.title,
        "word_count": chapter.word_count or 0,
        "annotations": annotations,
        "has_analysis": analysis is not None,
        "summary": {
            "total_annotations": len(annotations),
            "hooks": len([a for a in annotations if a["type"] == "hook"]),
            "foreshadows": len([a for a in annotations if a["type"] == "foreshadow"]),
            "plot_points": len([a for a in annotations if a["type"] == "plot_point"]),
            "character_events": len([a for a in annotations if a["type"] == "character_event"])
        }
    }


@router.post("/{chapter_id}/analyze", summary="æ‰‹åŠ¨è§¦å‘ç« èŠ‚åˆ†æ")
async def trigger_chapter_analysis(
    chapter_id: str,
    request: Request,
    background_tasks: BackgroundTasks,
    db: AsyncSession = Depends(get_db),
    user_ai_service: AIService = Depends(get_user_ai_service)
):
    """
    æ‰‹åŠ¨è§¦å‘ç« èŠ‚åˆ†æ(ç”¨äºé‡æ–°åˆ†ææˆ–åˆ†ææ—§ç« èŠ‚)
    """
    # ä»è¯·æ±‚ä¸­è·å–ç”¨æˆ·ID
    user_id = getattr(request.state, "user_id", None)
    if not user_id:
        raise HTTPException(status_code=401, detail="æœªç™»å½•")
    
    # éªŒè¯ç« èŠ‚å­˜åœ¨
    chapter_result = await db.execute(
        select(Chapter).where(Chapter.id == chapter_id)
    )
    chapter = chapter_result.scalar_one_or_none()
    
    if not chapter:
        raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
    
    if not chapter.content or chapter.content.strip() == "":
        raise HTTPException(status_code=400, detail="ç« èŠ‚å†…å®¹ä¸ºç©ºï¼Œæ— æ³•åˆ†æ")
    
    # è·å–é¡¹ç›®ä¿¡æ¯
    project_result = await db.execute(
        select(Project).where(Project.id == chapter.project_id)
    )
    project = project_result.scalar_one_or_none()
    
    if not project:
        raise HTTPException(status_code=404, detail="é¡¹ç›®ä¸å­˜åœ¨")
    
    # åˆ›å»ºåˆ†æä»»åŠ¡
    analysis_task = AnalysisTask(
        chapter_id=chapter_id,
        user_id=user_id,
        project_id=project.id,
        status='pending',
        progress=0
    )
    db.add(analysis_task)
    await db.commit()
    
    task_id = analysis_task.id
    logger.info(f"ğŸ“‹ åˆ›å»ºåˆ†æä»»åŠ¡: {task_id}, ç« èŠ‚: {chapter_id}")
    
    # åˆ·æ–°æ•°æ®åº“ä¼šè¯ï¼Œç¡®ä¿å…¶ä»–ä¼šè¯å¯ä»¥çœ‹åˆ°æ–°ä»»åŠ¡
    await db.refresh(analysis_task)
    
    # çŸ­æš‚å»¶è¿Ÿç¡®ä¿SQLite WALå®Œæˆå†™å…¥ï¼ˆè®©å…¶ä»–ä¼šè¯å¯è§ï¼‰
    await asyncio.sleep(3)
    
    # ç›´æ¥å¯åŠ¨åå°åˆ†æï¼ˆå¹¶å‘æ‰§è¡Œï¼‰
    background_tasks.add_task(
        analyze_chapter_background,
        chapter_id=chapter_id,
        user_id=user_id,
        project_id=project.id,
        task_id=task_id,
        ai_service=user_ai_service
    )
    
    return {
        "task_id": task_id,
        "chapter_id": chapter_id,
        "status": "pending",
        "message": "åˆ†æä»»åŠ¡å·²åˆ›å»ºå¹¶å¼€å§‹æ‰§è¡Œ"
    }



def calculate_estimated_time(
    chapter_count: int,
    target_word_count: int,
    enable_analysis: bool
) -> int:
    """
    è®¡ç®—é¢„ä¼°è€—æ—¶ï¼ˆåˆ†é’Ÿï¼‰
    
    åŸºå‡†ï¼š
    - ç”Ÿæˆ3000å­—çº¦éœ€2åˆ†é’Ÿ
    - åˆ†æçº¦éœ€1åˆ†é’Ÿ
    """
    generation_time_per_chapter = (target_word_count / 3000) * 2
    analysis_time_per_chapter = 1 if enable_analysis else 0
    
    total_time = chapter_count * (generation_time_per_chapter + analysis_time_per_chapter)
    
    return max(1, int(total_time))


@router.post("/project/{project_id}/batch-generate", response_model=BatchGenerateResponse, summary="æ‰¹é‡é¡ºåºç”Ÿæˆç« èŠ‚å†…å®¹")
async def batch_generate_chapters_in_order(
    project_id: str,
    batch_request: BatchGenerateRequest,
    request: Request,
    background_tasks: BackgroundTasks,
    db: AsyncSession = Depends(get_db),
    user_ai_service: AIService = Depends(get_user_ai_service)
):
    """
    ä»æŒ‡å®šç« èŠ‚å¼€å§‹ï¼ŒæŒ‰é¡ºåºæ‰¹é‡ç”ŸæˆæŒ‡å®šæ•°é‡çš„ç« èŠ‚
    
    ç‰¹æ€§ï¼š
    1. ä¸¥æ ¼æŒ‰ç« èŠ‚åºå·é¡ºåºç”Ÿæˆï¼ˆä¸å¯è·³è¿‡ï¼‰
    2. è‡ªåŠ¨æ£€æµ‹èµ·å§‹ç« èŠ‚æ˜¯å¦å¯ç”Ÿæˆ
    3. å¯é€‰åŒæ­¥åˆ†æï¼ˆå½±å“è€—æ—¶å’Œè´¨é‡ï¼‰
    4. å¤±è´¥åç»ˆæ­¢ï¼Œä¸ç»§ç»­åç»­ç« èŠ‚
    """
    user_id = getattr(request.state, "user_id", None)
    if not user_id:
        raise HTTPException(status_code=401, detail="æœªç™»å½•")
    
    # éªŒè¯é¡¹ç›®å­˜åœ¨å’Œç”¨æˆ·æƒé™
    project = await verify_project_access(project_id, user_id, db)
    
    # è·å–é¡¹ç›®çš„æ‰€æœ‰ç« èŠ‚ï¼ŒæŒ‰åºå·æ’åº
    result = await db.execute(
        select(Chapter)
        .where(Chapter.project_id == project_id)
        .order_by(Chapter.chapter_number)
    )
    all_chapters = result.scalars().all()
    
    if not all_chapters:
        raise HTTPException(status_code=404, detail="é¡¹ç›®æ²¡æœ‰ç« èŠ‚")
    
    # è®¡ç®—è¦ç”Ÿæˆçš„ç« èŠ‚èŒƒå›´
    start_number = batch_request.start_chapter_number
    end_number = start_number + batch_request.count - 1
    
    # ç­›é€‰å‡ºè¦ç”Ÿæˆçš„ç« èŠ‚
    chapters_to_generate = [
        ch for ch in all_chapters
        if start_number <= ch.chapter_number <= end_number
    ]
    
    if not chapters_to_generate:
        raise HTTPException(status_code=404, detail="æŒ‡å®šèŒƒå›´å†…æ²¡æœ‰ç« èŠ‚")
    
    # éªŒè¯èµ·å§‹ç« èŠ‚çš„å‰ç½®æ¡ä»¶
    first_chapter = chapters_to_generate[0]
    can_generate, error_msg, _ = await check_prerequisites(db, first_chapter)
    if not can_generate:
        raise HTTPException(status_code=400, detail=f"èµ·å§‹ç« èŠ‚æ— æ³•ç”Ÿæˆï¼š{error_msg}")
    
    # åˆ›å»ºæ‰¹é‡ç”Ÿæˆä»»åŠ¡
    batch_task = BatchGenerationTask(
        project_id=project_id,
        user_id=user_id,
        start_chapter_number=start_number,
        chapter_count=len(chapters_to_generate),
        chapter_ids=[ch.id for ch in chapters_to_generate],
        style_id=batch_request.style_id,
        target_word_count=batch_request.target_word_count,
        enable_analysis=batch_request.enable_analysis,
        max_retries=batch_request.max_retries,
        status='pending',
        total_chapters=len(chapters_to_generate),
        completed_chapters=0,
        failed_chapters=[],
        current_retry_count=0
    )
    db.add(batch_task)
    await db.commit()
    await db.refresh(batch_task)
    
    batch_id = batch_task.id
    
    # è®¡ç®—é¢„ä¼°è€—æ—¶
    estimated_time = calculate_estimated_time(
        chapter_count=len(chapters_to_generate),
        target_word_count=batch_request.target_word_count,
        enable_analysis=batch_request.enable_analysis
    )
    
    logger.info(f"ğŸ“¦ åˆ›å»ºæ‰¹é‡ç”Ÿæˆä»»åŠ¡: {batch_id}, ç« èŠ‚: ç¬¬{start_number}-{end_number}ç« , é¢„ä¼°è€—æ—¶: {estimated_time}åˆ†é’Ÿ")
    
    # å¯åŠ¨åå°æ‰¹é‡ç”Ÿæˆä»»åŠ¡ï¼Œä¼ é€’modelå‚æ•°
    background_tasks.add_task(
        execute_batch_generation_in_order,
        batch_id=batch_id,
        user_id=user_id,
        ai_service=user_ai_service,
        custom_model=batch_request.model
    )
    
    return BatchGenerateResponse(
        batch_id=batch_id,
        message=f"æ‰¹é‡ç”Ÿæˆä»»åŠ¡å·²åˆ›å»ºï¼Œå°†ç”Ÿæˆ {len(chapters_to_generate)} ä¸ªç« èŠ‚",
        chapters_to_generate=[
            {
                "id": ch.id,
                "chapter_number": ch.chapter_number,
                "title": ch.title
            }
            for ch in chapters_to_generate
        ],
        estimated_time_minutes=estimated_time
    )


@router.get("/batch-generate/{batch_id}/status", response_model=BatchGenerateStatusResponse, summary="æŸ¥è¯¢æ‰¹é‡ç”Ÿæˆä»»åŠ¡çŠ¶æ€")
async def get_batch_generation_status(
    batch_id: str,
    db: AsyncSession = Depends(get_db)
):
    """æŸ¥è¯¢æ‰¹é‡ç”Ÿæˆä»»åŠ¡çš„çŠ¶æ€å’Œè¿›åº¦"""
    result = await db.execute(
        select(BatchGenerationTask).where(BatchGenerationTask.id == batch_id)
    )
    task = result.scalar_one_or_none()
    
    if not task:
        raise HTTPException(status_code=404, detail="æ‰¹é‡ç”Ÿæˆä»»åŠ¡ä¸å­˜åœ¨")
    
    return BatchGenerateStatusResponse(
        batch_id=task.id,
        status=task.status,
        total=task.total_chapters,
        completed=task.completed_chapters,
        current_chapter_id=task.current_chapter_id,
        current_chapter_number=task.current_chapter_number,
        current_retry_count=task.current_retry_count,
        max_retries=task.max_retries,
        failed_chapters=task.failed_chapters or [],
        created_at=task.created_at.isoformat() if task.created_at else None,
        started_at=task.started_at.isoformat() if task.started_at else None,
        completed_at=task.completed_at.isoformat() if task.completed_at else None,
        error_message=task.error_message
    )


@router.get("/project/{project_id}/batch-generate/active", summary="è·å–é¡¹ç›®å½“å‰è¿è¡Œä¸­çš„æ‰¹é‡ç”Ÿæˆä»»åŠ¡")
async def get_active_batch_generation(
    project_id: str,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """
    è·å–é¡¹ç›®å½“å‰è¿è¡Œä¸­çš„æ‰¹é‡ç”Ÿæˆä»»åŠ¡
    ç”¨äºé¡µé¢åˆ·æ–°åæ¢å¤ä»»åŠ¡çŠ¶æ€
    """
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    await verify_project_access(project_id, user_id, db)
    
    result = await db.execute(
        select(BatchGenerationTask)
        .where(BatchGenerationTask.project_id == project_id)
        .where(BatchGenerationTask.status.in_(['pending', 'running']))
        .order_by(BatchGenerationTask.created_at.desc())
        .limit(1)
    )
    task = result.scalar_one_or_none()
    
    if not task:
        return {
            "has_active_task": False,
            "task": None
        }
    
    return {
        "has_active_task": True,
        "task": {
            "batch_id": task.id,
            "status": task.status,
            "total": task.total_chapters,
            "completed": task.completed_chapters,
            "current_chapter_id": task.current_chapter_id,
            "current_chapter_number": task.current_chapter_number,
            "created_at": task.created_at.isoformat() if task.created_at else None,
            "started_at": task.started_at.isoformat() if task.started_at else None
        }
    }


@router.post("/batch-generate/{batch_id}/cancel", summary="å–æ¶ˆæ‰¹é‡ç”Ÿæˆä»»åŠ¡")
async def cancel_batch_generation(
    batch_id: str,
    db: AsyncSession = Depends(get_db)
):
    """å–æ¶ˆæ­£åœ¨è¿›è¡Œçš„æ‰¹é‡ç”Ÿæˆä»»åŠ¡"""
    result = await db.execute(
        select(BatchGenerationTask).where(BatchGenerationTask.id == batch_id)
    )
    task = result.scalar_one_or_none()
    
    if not task:
        raise HTTPException(status_code=404, detail="æ‰¹é‡ç”Ÿæˆä»»åŠ¡ä¸å­˜åœ¨")
    
    if task.status in ['completed', 'failed', 'cancelled']:
        raise HTTPException(status_code=400, detail=f"ä»»åŠ¡å·²å¤„äº {task.status} çŠ¶æ€ï¼Œæ— æ³•å–æ¶ˆ")
    
    task.status = 'cancelled'
    task.completed_at = datetime.now()
    await db.commit()
    
    logger.info(f"ğŸ›‘ æ‰¹é‡ç”Ÿæˆä»»åŠ¡å·²å–æ¶ˆ: {batch_id}")
    
    return {
        "message": "æ‰¹é‡ç”Ÿæˆä»»åŠ¡å·²å–æ¶ˆ",
        "batch_id": batch_id,
        "completed_chapters": task.completed_chapters,
        "total_chapters": task.total_chapters
    }


async def execute_batch_generation_in_order(
    batch_id: str,
    user_id: str,
    ai_service: AIService,
    custom_model: Optional[str] = None
):
    """
    æŒ‰é¡ºåºæ‰§è¡Œæ‰¹é‡ç”Ÿæˆä»»åŠ¡ï¼ˆåå°ä»»åŠ¡ï¼‰
    - ä¸¥æ ¼æŒ‰ç« èŠ‚åºå·é¡ºåº
    - ä»»ä¸€ç« èŠ‚å¤±è´¥åˆ™ç»ˆæ­¢åç»­ç”Ÿæˆ
    - å¯é€‰åŒæ­¥åˆ†æ
    """
    db_session = None
    write_lock = await get_db_write_lock(user_id)
    
    try:
        logger.info(f"ğŸ“¦ å¼€å§‹æ‰§è¡Œé¡ºåºæ‰¹é‡ç”Ÿæˆä»»åŠ¡: {batch_id}")
        
        # åˆ›å»ºç‹¬ç«‹æ•°æ®åº“ä¼šè¯
        from app.database import get_engine
        from sqlalchemy.ext.asyncio import async_sessionmaker, AsyncSession
        
        engine = await get_engine(user_id)
        AsyncSessionLocal = async_sessionmaker(
            engine,
            class_=AsyncSession,
            expire_on_commit=False
        )
        db_session = AsyncSessionLocal()
        
        # è·å–ä»»åŠ¡
        task_result = await db_session.execute(
            select(BatchGenerationTask).where(BatchGenerationTask.id == batch_id)
        )
        task = task_result.scalar_one_or_none()
        
        if not task:
            logger.error(f"âŒ æ‰¹é‡ç”Ÿæˆä»»åŠ¡ä¸å­˜åœ¨: {batch_id}")
            return
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºè¿è¡Œä¸­
        async with write_lock:
            task.status = 'running'
            task.started_at = datetime.now()
            await db_session.commit()
        
        # æŒ‰é¡ºåºç”Ÿæˆæ¯ä¸ªç« èŠ‚
        for idx, chapter_id in enumerate(task.chapter_ids, 1):
            # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦è¢«å–æ¶ˆ
            await db_session.refresh(task)
            if task.status == 'cancelled':
                logger.info(f"ğŸ›‘ æ‰¹é‡ç”Ÿæˆä»»åŠ¡å·²è¢«å–æ¶ˆ: {batch_id}")
                return
            
            # æ›´æ–°å½“å‰ç« èŠ‚
            async with write_lock:
                task.current_chapter_id = chapter_id
                task.current_retry_count = 0  # é‡ç½®é‡è¯•è®¡æ•°
                await db_session.commit()
            
            # é‡è¯•å¾ªç¯
            retry_count = 0
            chapter_success = False
            chapter = None
            last_error = None
            
            while retry_count <= task.max_retries and not chapter_success:
                try:
                    # è·å–ç« èŠ‚ä¿¡æ¯
                    chapter_result = await db_session.execute(
                        select(Chapter).where(Chapter.id == chapter_id)
                    )
                    chapter = chapter_result.scalar_one_or_none()
                    
                    if not chapter:
                        raise Exception(f"ç« èŠ‚ {chapter_id} ä¸å­˜åœ¨")
                    
                    # æ›´æ–°å½“å‰ç« èŠ‚åºå·å’Œé‡è¯•æ¬¡æ•°
                    async with write_lock:
                        task.current_chapter_number = chapter.chapter_number
                        task.current_retry_count = retry_count
                        await db_session.commit()
                    
                    if retry_count > 0:
                        logger.info(f"ğŸ”„ [{idx}/{task.total_chapters}] é‡è¯•ç”Ÿæˆç« èŠ‚ (ç¬¬{retry_count}æ¬¡): ç¬¬{chapter.chapter_number}ç«  ã€Š{chapter.title}ã€‹")
                    else:
                        logger.info(f"ğŸ“ [{idx}/{task.total_chapters}] å¼€å§‹ç”Ÿæˆç« èŠ‚: ç¬¬{chapter.chapter_number}ç«  ã€Š{chapter.title}ã€‹")
                    
                    # æ£€æŸ¥å‰ç½®æ¡ä»¶ï¼ˆæ¯æ¬¡éƒ½æ£€æŸ¥ï¼Œç¡®ä¿é¡ºåºæ€§ï¼‰
                    can_generate, error_msg, _ = await check_prerequisites(db_session, chapter)
                    if not can_generate:
                        raise Exception(f"å‰ç½®æ¡ä»¶ä¸æ»¡è¶³: {error_msg}")
                    
                    # ç”Ÿæˆç« èŠ‚å†…å®¹ï¼ˆå¤ç”¨ç°æœ‰æµå¼ç”Ÿæˆé€»è¾‘çš„æ ¸å¿ƒéƒ¨åˆ†ï¼‰ï¼Œä¼ é€’modelå‚æ•°
                    await generate_single_chapter_for_batch(
                        db_session=db_session,
                        chapter=chapter,
                        user_id=user_id,
                        style_id=task.style_id,
                        target_word_count=task.target_word_count,
                        ai_service=ai_service,
                        write_lock=write_lock,
                        custom_model=custom_model
                    )
                    
                    logger.info(f"âœ… ç« èŠ‚ç”Ÿæˆå®Œæˆ: ç¬¬{chapter.chapter_number}ç« ")
                    
                    # å¦‚æœå¯ç”¨åŒæ­¥åˆ†æ
                    if task.enable_analysis:
                        logger.info(f"ğŸ” å¼€å§‹åŒæ­¥åˆ†æç« èŠ‚: ç¬¬{chapter.chapter_number}ç« ")
                        
                        async with write_lock:
                            analysis_task = AnalysisTask(
                                chapter_id=chapter_id,
                                user_id=user_id,
                                project_id=task.project_id,
                                status='pending',
                                progress=0
                            )
                            db_session.add(analysis_task)
                            await db_session.commit()
                            await db_session.refresh(analysis_task)
                        
                        # åŒæ­¥æ‰§è¡Œåˆ†æï¼ˆç­‰å¾…å®Œæˆï¼‰
                        await analyze_chapter_background(
                            chapter_id=chapter_id,
                            user_id=user_id,
                            project_id=task.project_id,
                            task_id=analysis_task.id,
                            ai_service=ai_service
                        )
                        
                        logger.info(f"âœ… ç« èŠ‚åˆ†æå®Œæˆ: ç¬¬{chapter.chapter_number}ç« ")
                    
                    # æ ‡è®°æˆåŠŸ
                    chapter_success = True
                    
                    # æ›´æ–°å®Œæˆæ•°
                    async with write_lock:
                        task.completed_chapters += 1
                        task.current_retry_count = 0  # é‡ç½®é‡è¯•è®¡æ•°
                        await db_session.commit()
                    
                    logger.info(f"âœ… è¿›åº¦: {task.completed_chapters}/{task.total_chapters}")
                    
                except Exception as e:
                    last_error = str(e)
                    logger.error(f"âŒ ç« èŠ‚ç”Ÿæˆå¤±è´¥: ç¬¬{chapter.chapter_number if chapter else '?'}ç« , é”™è¯¯: {last_error}")
                    
                    retry_count += 1
                    
                    # å¦‚æœè¿˜æœ‰é‡è¯•æœºä¼šï¼Œç­‰å¾…ä¸€å°æ®µæ—¶é—´åé‡è¯•
                    if retry_count <= task.max_retries:
                        wait_time = min(2 ** retry_count, 10)  # æŒ‡æ•°é€€é¿ï¼Œæœ€å¤šç­‰å¾…10ç§’
                        logger.info(f"â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                        await asyncio.sleep(wait_time)
                    else:
                        # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè®°å½•å¤±è´¥ä¿¡æ¯
                        logger.error(f"âŒ ç« èŠ‚ç”Ÿæˆå¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°({task.max_retries}): ç¬¬{chapter.chapter_number if chapter else '?'}ç« ")
                        
                        failed_info = {
                            'chapter_id': chapter_id,
                            'chapter_number': chapter.chapter_number if chapter else -1,
                            'title': chapter.title if chapter else 'æœªçŸ¥',
                            'error': last_error,
                            'retry_count': retry_count - 1
                        }
                        
                        async with write_lock:
                            if task.failed_chapters is None:
                                task.failed_chapters = []
                            task.failed_chapters.append(failed_info)
                            
                            # æ ‡è®°ä»»åŠ¡å¤±è´¥å¹¶ç»ˆæ­¢
                            task.status = 'failed'
                            task.error_message = f"ç¬¬{chapter.chapter_number}ç« ç”Ÿæˆå¤±è´¥(é‡è¯•{retry_count-1}æ¬¡): {last_error}"[:500]
                            task.completed_at = datetime.now()
                            task.current_retry_count = 0
                            await db_session.commit()
                        
                        logger.error(f"ğŸ›‘ æ‰¹é‡ç”Ÿæˆç»ˆæ­¢äºç¬¬{chapter.chapter_number}ç« ")
                        return
        
        # å…¨éƒ¨å®Œæˆ
        async with write_lock:
            task.status = 'completed'
            task.completed_at = datetime.now()
            task.current_chapter_id = None
            task.current_chapter_number = None
            await db_session.commit()
        
        logger.info(f"âœ… æ‰¹é‡ç”Ÿæˆä»»åŠ¡å…¨éƒ¨å®Œæˆ: {batch_id}, æˆåŠŸç”Ÿæˆ {task.completed_chapters} ç« ")
        
    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡ç”Ÿæˆä»»åŠ¡å¼‚å¸¸: {str(e)}", exc_info=True)
        if db_session and task:
            try:
                async with write_lock:
                    task.status = 'failed'
                    task.error_message = str(e)[:500]
                    task.completed_at = datetime.now()
                    await db_session.commit()
            except Exception as commit_error:
                logger.error(f"âŒ æ›´æ–°ä»»åŠ¡å¤±è´¥çŠ¶æ€å¤±è´¥: {str(commit_error)}")
    finally:
        if db_session:
            await db_session.close()


async def generate_single_chapter_for_batch(
    db_session: AsyncSession,
    chapter: Chapter,
    user_id: str,
    style_id: Optional[int],
    target_word_count: int,
    ai_service: AIService,
    write_lock: Lock,
    custom_model: Optional[str] = None
):
    """
    ä¸ºæ‰¹é‡ç”Ÿæˆæ‰§è¡Œå•ä¸ªç« èŠ‚çš„ç”Ÿæˆï¼ˆéæµå¼ï¼‰
    å¤ç”¨ç°æœ‰ç”Ÿæˆé€»è¾‘çš„æ ¸å¿ƒéƒ¨åˆ†
    """
    # è·å–é¡¹ç›®ä¿¡æ¯
    project_result = await db_session.execute(
        select(Project).where(Project.id == chapter.project_id)
    )
    project = project_result.scalar_one_or_none()
    if not project:
        raise Exception("é¡¹ç›®ä¸å­˜åœ¨")
    
    # è·å–é¡¹ç›®çš„å¤§çº²æ¨¡å¼
    outline_mode = project.outline_mode if project else 'one-to-many'
    logger.info(f"ğŸ“‹ æ‰¹é‡ç”Ÿæˆ - é¡¹ç›®å¤§çº²æ¨¡å¼: {outline_mode}")
    
    # è·å–å¯¹åº”çš„å¤§çº²
    outline_result = await db_session.execute(
        select(Outline)
        .where(Outline.project_id == chapter.project_id)
        .where(Outline.order_index == chapter.chapter_number)
    )
    outline = outline_result.scalar_one_or_none()
    
    # è·å–æ‰€æœ‰å¤§çº²ç”¨äºä¸Šä¸‹æ–‡
    all_outlines_result = await db_session.execute(
        select(Outline)
        .where(Outline.project_id == chapter.project_id)
        .order_by(Outline.order_index)
    )
    all_outlines = all_outlines_result.scalars().all()
    outlines_context = "\n".join([
        f"ç¬¬{o.order_index}ç«  {o.title}: {o.content[:100]}..."
        for o in all_outlines
    ])
    
    # è·å–è§’è‰²ä¿¡æ¯
    characters_result = await db_session.execute(
        select(Character).where(Character.project_id == chapter.project_id)
    )
    characters = characters_result.scalars().all()
    characters_info = "\n".join([
        f"- {c.name}({'ç»„ç»‡' if c.is_organization else 'è§’è‰²'}, {c.role_type}): {c.personality[:100] if c.personality else ''}"
        for c in characters
    ])
    
    # è·å–å†™ä½œé£æ ¼
    style_content = ""
    if style_id:
        style_result = await db_session.execute(
            select(WritingStyle).where(WritingStyle.id == style_id)
        )
        style = style_result.scalar_one_or_none()
        if style:
            if style.user_id is None or style.user_id == user_id:
                style_content = style.prompt_content or ""
    
    # æ„å»ºæ™ºèƒ½ä¸Šä¸‹æ–‡
    smart_context = await build_smart_chapter_context(
        db=db_session,
        project_id=project.id,
        current_chapter_number=chapter.chapter_number,
        user_id=user_id
    )
    
    # ç»„è£…ä¸Šä¸‹æ–‡
    previous_content = ""
    if smart_context['story_skeleton']:
        previous_content += smart_context['story_skeleton'] + "\n\n"
    if smart_context['relevant_history']:
        previous_content += smart_context['relevant_history'] + "\n\n"
    if smart_context['recent_summary']:
        previous_content += smart_context['recent_summary'] + "\n\n"
    if smart_context['recent_full']:
        previous_content += smart_context['recent_full']
    
    # æ„å»ºè®°å¿†å¢å¼ºä¸Šä¸‹æ–‡
    memory_context = await memory_service.build_context_for_generation(
        user_id=user_id,
        project_id=project.id,
        current_chapter=chapter.chapter_number,
        chapter_outline=outline.content if outline else chapter.summary or "",
        character_names=[c.name for c in characters] if characters else None
    )
    
    # ğŸ“‹ æ ¹æ®å¤§çº²æ¨¡å¼æ„å»ºå·®å¼‚åŒ–çš„ç« èŠ‚å¤§çº²ä¸Šä¸‹æ–‡
    chapter_outline_content = ""
    if outline_mode == 'one-to-one':
        # ä¸€å¯¹ä¸€æ¨¡å¼ï¼šä½¿ç”¨å¤§çº²çš„ content
        chapter_outline_content = outline.content if outline else chapter.summary or 'æš‚æ— å¤§çº²'
        logger.info(f"âœï¸ æ‰¹é‡ç”Ÿæˆ - ä¸€å¯¹ä¸€æ¨¡å¼ï¼šä½¿ç”¨å¤§çº²å†…å®¹")
    else:
        # ä¸€å¯¹å¤šæ¨¡å¼ï¼šä¼˜å…ˆä½¿ç”¨ expansion_plan çš„è¯¦ç»†è§„åˆ’
        if chapter.expansion_plan:
            try:
                plan = json.loads(chapter.expansion_plan)
                chapter_outline_content = f"""ã€æœ¬ç« è¯¦ç»†è§„åˆ’ã€‘
å‰§æƒ…æ‘˜è¦ï¼š{plan.get('plot_summary', 'æ— ')}

å…³é”®äº‹ä»¶ï¼š
{chr(10).join(f'- {event}' for event in plan.get('key_events', []))}

è§’è‰²ç„¦ç‚¹ï¼š{', '.join(plan.get('character_focus', []))}

æƒ…æ„ŸåŸºè°ƒï¼š{plan.get('emotional_tone', 'æœªè®¾å®š')}

å™äº‹ç›®æ ‡ï¼š{plan.get('narrative_goal', 'æœªè®¾å®š')}

å†²çªç±»å‹ï¼š{plan.get('conflict_type', 'æœªè®¾å®š')}"""
                
                # å¯é€‰ï¼šé™„åŠ ç« èŠ‚ summary
                if chapter.summary and chapter.summary.strip():
                    chapter_outline_content += f"\n\nã€ç« èŠ‚è¡¥å……è¯´æ˜ã€‘\n{chapter.summary}"
                
                # å¯é€‰ï¼šé™„åŠ å¤§çº²çš„èƒŒæ™¯ä¿¡æ¯
                if outline:
                    chapter_outline_content += f"\n\nã€å¤§çº²èŠ‚ç‚¹èƒŒæ™¯ã€‘\n{outline.content}"
                
                logger.info(f"âœï¸ æ‰¹é‡ç”Ÿæˆ - ä¸€å¯¹å¤šæ¨¡å¼ï¼šä½¿ç”¨expansion_planè¯¦ç»†è§„åˆ’")
            except json.JSONDecodeError as e:
                logger.warning(f"âš ï¸ expansion_planè§£æå¤±è´¥: {e}ï¼Œå›é€€åˆ°å¤§çº²å†…å®¹")
                chapter_outline_content = outline.content if outline else chapter.summary or 'æš‚æ— å¤§çº²'
        else:
            # æ²¡æœ‰expansion_planï¼Œä½¿ç”¨å¤§çº²å†…å®¹
            chapter_outline_content = outline.content if outline else chapter.summary or 'æš‚æ— å¤§çº²'
            logger.warning(f"âš ï¸ æ‰¹é‡ç”Ÿæˆ - ä¸€å¯¹å¤šæ¨¡å¼ä½†æ— expansion_planï¼Œä½¿ç”¨å¤§çº²å†…å®¹")
    
    # ç”Ÿæˆæç¤ºè¯ï¼ˆæ”¯æŒè‡ªå®šä¹‰ï¼‰
    if previous_content:
        # è·å–è‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿
        template = await PromptService.get_template("CHAPTER_GENERATION_WITH_CONTEXT", user_id, db_session)
        base_prompt = PromptService.format_prompt(
            template,
            title=project.title,
            theme=project.theme or '',
            genre=project.genre or '',
            narrative_perspective=project.narrative_perspective or 'ç¬¬ä¸‰äººç§°',
            time_period=project.world_time_period or 'æœªè®¾å®š',
            location=project.world_location or 'æœªè®¾å®š',
            atmosphere=project.world_atmosphere or 'æœªè®¾å®š',
            rules=project.world_rules or 'æœªè®¾å®š',
            characters_info=characters_info or 'æš‚æ— è§’è‰²ä¿¡æ¯',
            outlines_context=outlines_context,
            previous_content=previous_content,
            chapter_number=chapter.chapter_number,
            chapter_title=chapter.title,
            chapter_outline=chapter_outline_content,
            target_word_count=target_word_count,
            max_word_count=target_word_count + 1000,
            memory_context=memory_context.get('recent_context', '') + "\n" + memory_context.get('relevant_memories', '') + "\n" + memory_context.get('foreshadows', '') + "\n" + memory_context.get('character_states', '') + "\n" + memory_context.get('plot_points', '') if memory_context else "æš‚æ— ç›¸å…³è®°å¿†"
        )
        # åº”ç”¨å†™ä½œé£æ ¼
        if style_content:
            prompt = WritingStyleManager.apply_style_to_prompt(base_prompt, style_content)
        else:
            prompt = base_prompt
    else:
        # è·å–è‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿
        template = await PromptService.get_template("CHAPTER_GENERATION", user_id, db_session)
        base_prompt = PromptService.format_prompt(
            template,
            title=project.title,
            theme=project.theme or '',
            genre=project.genre or '',
            narrative_perspective=project.narrative_perspective or 'ç¬¬ä¸‰äººç§°',
            time_period=project.world_time_period or 'æœªè®¾å®š',
            location=project.world_location or 'æœªè®¾å®š',
            atmosphere=project.world_atmosphere or 'æœªè®¾å®š',
            rules=project.world_rules or 'æœªè®¾å®š',
            characters_info=characters_info or 'æš‚æ— è§’è‰²ä¿¡æ¯',
            outlines_context=outlines_context,
            chapter_number=chapter.chapter_number,
            chapter_title=chapter.title,
            chapter_outline=chapter_outline_content,
            target_word_count=target_word_count,
            max_word_count=target_word_count + 1000
        )
        # åº”ç”¨å†™ä½œé£æ ¼
        if style_content:
            prompt = WritingStyleManager.apply_style_to_prompt(base_prompt, style_content)
        else:
            prompt = base_prompt
    
    # éæµå¼ç”Ÿæˆå†…å®¹
    full_content = ""
    # å‡†å¤‡ç”Ÿæˆå‚æ•°
    generate_kwargs = {"prompt": prompt}
    # å¦‚æœä¼ å…¥äº†è‡ªå®šä¹‰æ¨¡å‹ï¼Œä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹
    if custom_model:
        generate_kwargs["model"] = custom_model
        logger.info(f"  æ‰¹é‡ç”Ÿæˆä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹: {custom_model}")
    
    async for chunk in ai_service.generate_text_stream(**generate_kwargs):
        full_content += chunk
    
    # æ›´æ–°ç« èŠ‚å†…å®¹åˆ°æ•°æ®åº“ï¼ˆä½¿ç”¨é”ä¿æŠ¤ï¼‰
    async with write_lock:
        old_word_count = chapter.word_count or 0
        chapter.content = full_content
        new_word_count = len(full_content)
        chapter.word_count = new_word_count
        chapter.status = "completed"
        
        # æ›´æ–°é¡¹ç›®å­—æ•°
        project.current_words = project.current_words - old_word_count + new_word_count
        
        # è®°å½•ç”Ÿæˆå†å²
        history = GenerationHistory(
            project_id=chapter.project_id,
            chapter_id=chapter.id,
            prompt=f"æ‰¹é‡ç”Ÿæˆ: ç¬¬{chapter.chapter_number}ç«  {chapter.title}",
            generated_content=full_content[:500] if len(full_content) > 500 else full_content,
            model="default"
        )
        db_session.add(history)
        
        await db_session.commit()
        await db_session.refresh(chapter)
    
    logger.info(f"âœ… å•ç« èŠ‚ç”Ÿæˆå®Œæˆ: ç¬¬{chapter.chapter_number}ç« ï¼Œå…± {new_word_count} å­—")




# ==================== ç« èŠ‚é‡æ–°ç”Ÿæˆç›¸å…³API ====================

@router.post("/{chapter_id}/regenerate-stream", summary="æµå¼é‡æ–°ç”Ÿæˆç« èŠ‚å†…å®¹")
async def regenerate_chapter_stream(
    chapter_id: str,
    request: Request,
    regenerate_request: ChapterRegenerateRequest,
    background_tasks: BackgroundTasks,
    db: AsyncSession = Depends(get_db),
    user_ai_service: AIService = Depends(get_user_ai_service)
):
    """
    æ ¹æ®åˆ†æå»ºè®®æˆ–è‡ªå®šä¹‰æŒ‡ä»¤é‡æ–°ç”Ÿæˆç« èŠ‚å†…å®¹ï¼ˆæµå¼è¿”å›ï¼‰
    
    å·¥ä½œæµç¨‹ï¼š
    1. éªŒè¯ç« èŠ‚å’Œåˆ†æç»“æœ
    2. åˆ›å»ºé‡æ–°ç”Ÿæˆä»»åŠ¡
    3. æ„å»ºä¿®æ”¹æŒ‡ä»¤
    4. æµå¼ç”Ÿæˆæ–°å†…å®¹
    5. ä¿å­˜ä¸ºç‰ˆæœ¬å†å²
    6. å¯é€‰è‡ªåŠ¨åº”ç”¨
    """
    user_id = getattr(request.state, 'user_id', None)
    if not user_id:
        raise HTTPException(status_code=401, detail="æœªç™»å½•")
    
    # éªŒè¯ç« èŠ‚å­˜åœ¨
    chapter_result = await db.execute(
        select(Chapter).where(Chapter.id == chapter_id)
    )
    chapter = chapter_result.scalar_one_or_none()
    
    if not chapter:
        raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
    
    if not chapter.content or chapter.content.strip() == "":
        raise HTTPException(status_code=400, detail="ç« èŠ‚å†…å®¹ä¸ºç©ºï¼Œæ— æ³•é‡æ–°ç”Ÿæˆ")
    
    # éªŒè¯ç”¨æˆ·æƒé™
    await verify_project_access(chapter.project_id, user_id, db)
    
    # è·å–åˆ†æç»“æœï¼ˆå¦‚æœä½¿ç”¨åˆ†æå»ºè®®ï¼‰
    analysis = None
    if regenerate_request.modification_source in ['analysis_suggestions', 'mixed']:
        analysis_result = await db.execute(
            select(PlotAnalysis)
            .where(PlotAnalysis.chapter_id == chapter_id)
            .order_by(PlotAnalysis.created_at.desc())
            .limit(1)
        )
        analysis = analysis_result.scalar_one_or_none()
        
        if not analysis:
            raise HTTPException(status_code=404, detail="è¯¥ç« èŠ‚æš‚æ— åˆ†æç»“æœ")
    
    # é¢„å…ˆè·å–é¡¹ç›®ä¸Šä¸‹æ–‡æ•°æ®å’Œå†™ä½œé£æ ¼
    async for temp_db in get_db(request):
        try:
            # è·å–é¡¹ç›®ä¿¡æ¯
            project_result = await temp_db.execute(
                select(Project).where(Project.id == chapter.project_id)
            )
            project = project_result.scalar_one_or_none()
            
            # è·å–è§’è‰²ä¿¡æ¯
            characters_result = await temp_db.execute(
                select(Character).where(Character.project_id == chapter.project_id)
            )
            characters = characters_result.scalars().all()
            
            # è·å–ç« èŠ‚å¤§çº²
            outline_result = await temp_db.execute(
                select(Outline)
                .where(Outline.project_id == chapter.project_id)
                .where(Outline.order_index == chapter.chapter_number)
            )
            outline = outline_result.scalar_one_or_none()
            
            # è·å–å†™ä½œé£æ ¼
            style_content = ""
            style_id = regenerate_request.style_id
            
            # å¦‚æœæ²¡æœ‰æŒ‡å®šé£æ ¼ï¼Œå°è¯•ä½¿ç”¨é¡¹ç›®çš„é»˜è®¤é£æ ¼
            if not style_id:
                from app.models.project_default_style import ProjectDefaultStyle
                default_style_result = await temp_db.execute(
                    select(ProjectDefaultStyle.style_id)
                    .where(ProjectDefaultStyle.project_id == chapter.project_id)
                )
                default_style_id = default_style_result.scalar_one_or_none()
                if default_style_id:
                    style_id = default_style_id
                    logger.info(f"ğŸ“ ä½¿ç”¨é¡¹ç›®é»˜è®¤å†™ä½œé£æ ¼: {style_id}")
            
            # è·å–é£æ ¼å†…å®¹
            if style_id:
                style_result = await temp_db.execute(
                    select(WritingStyle).where(WritingStyle.id == style_id)
                )
                style = style_result.scalar_one_or_none()
                if style:
                    # éªŒè¯é£æ ¼æ˜¯å¦å¯ç”¨ï¼šå…¨å±€é¢„è®¾é£æ ¼ï¼ˆuser_idä¸ºNULLï¼‰æˆ–è€…å½“å‰ç”¨æˆ·çš„è‡ªå®šä¹‰é£æ ¼
                    if style.user_id is None or style.user_id == user_id:
                        style_content = style.prompt_content or ""
                        style_type = "å…¨å±€é¢„è®¾" if style.user_id is None else "ç”¨æˆ·è‡ªå®šä¹‰"
                        logger.info(f"âœ… ä½¿ç”¨å†™ä½œé£æ ¼: {style.name} ({style_type})")
                    else:
                        logger.warning(f"âš ï¸ é£æ ¼ {style_id} ä¸å±äºå½“å‰é¡¹ç›®ï¼Œè·³è¿‡")
                else:
                    logger.warning(f"âš ï¸ æœªæ‰¾åˆ°é£æ ¼ {style_id}")
            else:
                logger.info("â„¹ï¸ æœªæŒ‡å®šå†™ä½œé£æ ¼ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯")
            
            # æ„å»ºé¡¹ç›®ä¸Šä¸‹æ–‡
            project_context = {
                'project_title': project.title if project else 'æœªçŸ¥',
                'genre': project.genre if project else 'æœªè®¾å®š',
                'theme': project.theme if project else 'æœªè®¾å®š',
                'narrative_perspective': project.narrative_perspective if project else 'ç¬¬ä¸‰äººç§°',
                'time_period': project.world_time_period if project else 'æœªè®¾å®š',
                'location': project.world_location if project else 'æœªè®¾å®š',
                'atmosphere': project.world_atmosphere if project else 'æœªè®¾å®š',
                'characters_info': "\n".join([
                    f"- {c.name}({'ç»„ç»‡' if c.is_organization else 'è§’è‰²'}, {c.role_type}): {c.personality[:100] if c.personality else ''}"
                    for c in characters
                ]) if characters else 'æš‚æ— è§’è‰²ä¿¡æ¯',
                'chapter_outline': outline.content if outline else chapter.summary or 'æš‚æ— å¤§çº²',
                'previous_context': ''  # å¯ä»¥åç»­æ‰©å±•æ·»åŠ å‰ç½®ç« èŠ‚ä¸Šä¸‹æ–‡
            }
        finally:
            await temp_db.close()
        break
    
    async def event_generator():
        """æµå¼ç”Ÿæˆäº‹ä»¶ç”Ÿæˆå™¨"""
        db_session = None
        db_committed = False
        
        try:
            # åˆ›å»ºç‹¬ç«‹æ•°æ®åº“ä¼šè¯
            async for db_session in get_db(request):
                # å‘é€å¼€å§‹äº‹ä»¶
                yield f"data: {json.dumps({'type': 'start', 'message': 'å¼€å§‹é‡æ–°ç”Ÿæˆç« èŠ‚...'}, ensure_ascii=False)}\n\n"
                
                # åˆ›å»ºé‡æ–°ç”Ÿæˆä»»åŠ¡
                regen_task = RegenerationTask(
                    chapter_id=chapter_id,
                    analysis_id=analysis.id if analysis else None,
                    user_id=user_id,
                    project_id=chapter.project_id,
                    modification_instructions="",  # ç¨åå¡«å……
                    original_suggestions=analysis.suggestions if analysis else None,
                    selected_suggestion_indices=regenerate_request.selected_suggestion_indices,
                    custom_instructions=regenerate_request.custom_instructions,
                    style_id=regenerate_request.style_id,
                    target_word_count=regenerate_request.target_word_count,
                    focus_areas=regenerate_request.focus_areas,
                    preserve_elements=regenerate_request.preserve_elements.model_dump() if regenerate_request.preserve_elements else None,
                    status='running',
                    original_content=chapter.content,
                    original_word_count=chapter.word_count or len(chapter.content),
                    version_note=regenerate_request.version_note,
                    started_at=datetime.now()
                )
                db_session.add(regen_task)
                await db_session.commit()
                await db_session.refresh(regen_task)
                
                task_id = regen_task.id
                logger.info(f"ğŸ“ åˆ›å»ºé‡æ–°ç”Ÿæˆä»»åŠ¡: {task_id}")
                
                yield f"data: {json.dumps({'type': 'task_created', 'task_id': task_id}, ensure_ascii=False)}\n\n"
                
                # åˆå§‹åŒ–é‡æ–°ç”Ÿæˆå™¨
                regenerator = ChapterRegenerator(user_ai_service)
                
                # æµå¼ç”Ÿæˆæ–°å†…å®¹
                full_content = ""
                async for event in regenerator.regenerate_with_feedback(
                    chapter=chapter,
                    analysis=analysis,
                    regenerate_request=regenerate_request,
                    project_context=project_context,
                    style_content=style_content,
                    user_id=user_id,
                    db=db_session
                ):
                    # å¤„ç†ä¸åŒç±»å‹çš„äº‹ä»¶
                    if event['type'] == 'chunk':
                        # å†…å®¹å—
                        chunk = event['content']
                        full_content += chunk
                        yield f"data: {json.dumps({'type': 'chunk', 'content': chunk}, ensure_ascii=False)}\n\n"
                    elif event['type'] == 'progress':
                        # è¿›åº¦æ›´æ–°
                        progress_data = {
                            'type': 'progress',
                            'progress': event.get('progress', 0),
                            'message': event.get('message', ''),
                            'word_count': event.get('word_count', 0)
                        }
                        yield f"data: {json.dumps(progress_data, ensure_ascii=False)}\n\n"
                    
                    await asyncio.sleep(0)
                
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                regen_task.status = 'completed'
                regen_task.regenerated_content = full_content
                regen_task.regenerated_word_count = len(full_content)
                regen_task.completed_at = datetime.now()
                
                # è®¡ç®—å·®å¼‚ç»Ÿè®¡
                diff_stats = regenerator.calculate_content_diff(chapter.content, full_content)
                
                await db_session.commit()
                db_committed = True
                
                # å…ˆå‘é€ç»“æœæ•°æ®
                result_data = {
                    'type': 'result',
                    'data': {
                        'task_id': task_id,
                        'word_count': len(full_content),
                        'version_number': regen_task.version_number,
                        'auto_applied': regenerate_request.auto_apply,
                        'diff_stats': diff_stats
                    }
                }
                yield f"data: {json.dumps(result_data, ensure_ascii=False)}\n\n"
                
                # å†å‘é€å®Œæˆäº‹ä»¶
                completion_data = {
                    'type': 'done',
                    'message': 'é‡æ–°ç”Ÿæˆå®Œæˆ'
                }
                yield f"data: {json.dumps(completion_data, ensure_ascii=False)}\n\n"
                
                logger.info(f"âœ… ç« èŠ‚é‡æ–°ç”Ÿæˆå®Œæˆ: {chapter_id}, ä»»åŠ¡: {task_id}")
                
                break
        
        except Exception as e:
            logger.error(f"âŒ é‡æ–°ç”Ÿæˆå¤±è´¥: {str(e)}", exc_info=True)
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
            if db_session and not db_committed:
                try:
                    task_result = await db_session.execute(
                        select(RegenerationTask).where(RegenerationTask.chapter_id == chapter_id)
                        .order_by(RegenerationTask.created_at.desc()).limit(1)
                    )
                    task = task_result.scalar_one_or_none()
                    if task:
                        task.status = 'failed'
                        task.error_message = str(e)[:500]
                        task.completed_at = datetime.now()
                        await db_session.commit()
                except Exception as update_error:
                    logger.error(f"æ›´æ–°ä»»åŠ¡å¤±è´¥çŠ¶æ€å¤±è´¥: {str(update_error)}")
            
            yield f"data: {json.dumps({'type': 'error', 'error': str(e)}, ensure_ascii=False)}\n\n"
        
        finally:
            if db_session:
                try:
                    if not db_committed and db_session.in_transaction():
                        await db_session.rollback()
                    await db_session.close()
                except Exception as close_error:
                    logger.error(f"å…³é—­æ•°æ®åº“ä¼šè¯å¤±è´¥: {str(close_error)}")
    
    return create_sse_response(event_generator())


@router.get("/{chapter_id}/regeneration/tasks", summary="è·å–ç« èŠ‚çš„é‡æ–°ç”Ÿæˆä»»åŠ¡åˆ—è¡¨")
async def get_regeneration_tasks(
    chapter_id: str,
    request: Request,
    limit: int = Query(10, ge=1, le=50),
    db: AsyncSession = Depends(get_db)
):
    """è·å–æŒ‡å®šç« èŠ‚çš„é‡æ–°ç”Ÿæˆä»»åŠ¡å†å²"""
    user_id = getattr(request.state, 'user_id', None)
    
    # éªŒè¯ç« èŠ‚å­˜åœ¨å’Œæƒé™
    chapter_result = await db.execute(
        select(Chapter).where(Chapter.id == chapter_id)
    )
    chapter = chapter_result.scalar_one_or_none()
    if not chapter:
        raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
    
    await verify_project_access(chapter.project_id, user_id, db)
    
    # è·å–ä»»åŠ¡åˆ—è¡¨
    result = await db.execute(
        select(RegenerationTask)
        .where(RegenerationTask.chapter_id == chapter_id)
        .order_by(RegenerationTask.created_at.desc())
        .limit(limit)
    )
    tasks = result.scalars().all()
    
    return {
        "chapter_id": chapter_id,
        "total": len(tasks),
        "tasks": [
            {
                "task_id": task.id,
                "status": task.status,
                "version_number": task.version_number,
                "version_note": task.version_note,
                "original_word_count": task.original_word_count,
                "regenerated_word_count": task.regenerated_word_count,
                "created_at": task.created_at.isoformat() if task.created_at else None,
                "completed_at": task.completed_at.isoformat() if task.completed_at else None
            }
            for task in tasks
        ]
    }


@router.put("/{chapter_id}/expansion-plan", response_model=dict, summary="æ›´æ–°ç« èŠ‚è§„åˆ’ä¿¡æ¯")
async def update_chapter_expansion_plan(
    chapter_id: str,
    expansion_plan: ExpansionPlanUpdate,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """
    æ›´æ–°ç« èŠ‚çš„å±•å¼€è§„åˆ’ä¿¡æ¯å’Œæƒ…èŠ‚æ¦‚è¦
    
    Args:
        chapter_id: ç« èŠ‚ID
        expansion_plan: è§„åˆ’ä¿¡æ¯æ›´æ–°æ•°æ®(åŒ…å«summaryå’Œexpansion_planå­—æ®µ)
    
    Returns:
        æ›´æ–°åçš„ç« èŠ‚è§„åˆ’ä¿¡æ¯
    """
    # è·å–ç« èŠ‚
    result = await db.execute(
        select(Chapter).where(Chapter.id == chapter_id)
    )
    chapter = result.scalar_one_or_none()
    
    if not chapter:
        raise HTTPException(status_code=404, detail="ç« èŠ‚ä¸å­˜åœ¨")
    
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    await verify_project_access(chapter.project_id, user_id, db)
    
    # å‡†å¤‡æ›´æ–°æ•°æ®(æ’é™¤Noneå€¼)
    plan_data = expansion_plan.model_dump(exclude_unset=True, exclude_none=True)
    
    # åˆ†ç¦»summaryå’Œexpansion_planæ•°æ®
    summary_value = plan_data.pop('summary', None)
    
    # æ›´æ–°summaryå­—æ®µ(å¦‚æœæä¾›)
    if summary_value is not None:
        chapter.summary = summary_value
        logger.info(f"æ›´æ–°ç« èŠ‚æ¦‚è¦: {chapter_id}")
    
    # æ›´æ–°expansion_planå­—æ®µ(å¦‚æœæœ‰å…¶ä»–å­—æ®µ)
    if plan_data:
        if chapter.expansion_plan:
            try:
                existing_plan = json.loads(chapter.expansion_plan)
                # åˆå¹¶æ›´æ–°
                existing_plan.update(plan_data)
                chapter.expansion_plan = json.dumps(existing_plan, ensure_ascii=False)
            except json.JSONDecodeError:
                logger.warning(f"ç« èŠ‚ {chapter_id} çš„expansion_planæ ¼å¼é”™è¯¯,å°†è¦†ç›–")
                chapter.expansion_plan = json.dumps(plan_data, ensure_ascii=False)
        else:
            chapter.expansion_plan = json.dumps(plan_data, ensure_ascii=False)
    
    await db.commit()
    await db.refresh(chapter)
    
    logger.info(f"ç« èŠ‚è§„åˆ’æ›´æ–°æˆåŠŸ: {chapter_id}")
    
    # è¿”å›æ›´æ–°åçš„è§„åˆ’æ•°æ®
    updated_plan = json.loads(chapter.expansion_plan) if chapter.expansion_plan else None
    
    return {
        "id": chapter.id,
        "summary": chapter.summary,
        "expansion_plan": updated_plan,
        "message": "è§„åˆ’ä¿¡æ¯æ›´æ–°æˆåŠŸ"
    }

