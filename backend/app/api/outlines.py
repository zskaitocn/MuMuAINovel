"""å¤§çº²ç®¡ç†API"""
from fastapi import APIRouter, Depends, HTTPException, Request
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func, delete
from typing import List, AsyncGenerator, Dict, Any
import json

from app.database import get_db
from app.models.outline import Outline
from app.models.project import Project
from app.models.chapter import Chapter
from app.models.character import Character
from app.models.generation_history import GenerationHistory
from app.schemas.outline import (
    OutlineCreate,
    OutlineUpdate,
    OutlineResponse,
    OutlineListResponse,
    OutlineGenerateRequest,
    OutlineExpansionRequest,
    OutlineExpansionResponse,
    BatchOutlineExpansionRequest,
    BatchOutlineExpansionResponse,
    CreateChaptersFromPlansRequest,
    CreateChaptersFromPlansResponse,
    CharacterPredictionRequest,
    PredictedCharacter,
    CharacterPredictionResponse
)
from app.services.ai_service import AIService
from app.services.prompt_service import prompt_service, PromptService
from app.services.memory_service import memory_service
from app.services.plot_expansion_service import PlotExpansionService
from app.logger import get_logger
from app.api.settings import get_user_ai_service
from app.utils.sse_response import SSEResponse, create_sse_response

router = APIRouter(prefix="/outlines", tags=["å¤§çº²ç®¡ç†"])
logger = get_logger(__name__)


async def verify_project_access(project_id: str, user_id: str, db: AsyncSession) -> Project:
    """
    éªŒè¯ç”¨æˆ·æ˜¯å¦æœ‰æƒè®¿é—®æŒ‡å®šé¡¹ç›®
    
    Args:
        project_id: é¡¹ç›®ID
        user_id: ç”¨æˆ·ID
        db: æ•°æ®åº“ä¼šè¯
        
    Returns:
        Project: é¡¹ç›®å¯¹è±¡
        
    Raises:
        HTTPException: 401 æœªç™»å½•ï¼Œ404 é¡¹ç›®ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®
    """
    if not user_id:
        raise HTTPException(status_code=401, detail="æœªç™»å½•")
    
    result = await db.execute(
        select(Project).where(
            Project.id == project_id,
            Project.user_id == user_id
        )
    )
    project = result.scalar_one_or_none()
    
    if not project:
        logger.warning(f"é¡¹ç›®è®¿é—®è¢«æ‹’ç»: project_id={project_id}, user_id={user_id}")
        raise HTTPException(status_code=404, detail="é¡¹ç›®ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®")
    
    return project


@router.post("", response_model=OutlineResponse, summary="åˆ›å»ºå¤§çº²")
async def create_outline(
    outline: OutlineCreate,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """åˆ›å»ºæ–°çš„ç« èŠ‚å¤§çº²ï¼ˆone-to-oneæ¨¡å¼ä¼šè‡ªåŠ¨åˆ›å»ºå¯¹åº”ç« èŠ‚ï¼‰"""
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    project = await verify_project_access(outline.project_id, user_id, db)
    
    # åˆ›å»ºå¤§çº²
    db_outline = Outline(**outline.model_dump())
    db.add(db_outline)
    await db.flush()  # ç¡®ä¿å¤§çº²æœ‰ID
    
    # å¦‚æœæ˜¯one-to-oneæ¨¡å¼ï¼Œè‡ªåŠ¨åˆ›å»ºå¯¹åº”çš„ç« èŠ‚
    if project.outline_mode == 'one-to-one':
        chapter = Chapter(
            project_id=outline.project_id,
            title=db_outline.title,
            summary=db_outline.content,
            chapter_number=db_outline.order_index,
            sub_index=1,
            outline_id=None,  # one-to-oneæ¨¡å¼ä¸å…³è”outline_id
            status='pending',
            content=""
        )
        db.add(chapter)
        logger.info(f"ä¸€å¯¹ä¸€æ¨¡å¼ï¼šä¸ºæ‰‹åŠ¨åˆ›å»ºçš„å¤§çº² {db_outline.title} (åºå·{db_outline.order_index}) è‡ªåŠ¨åˆ›å»ºäº†å¯¹åº”ç« èŠ‚")
    
    await db.commit()
    await db.refresh(db_outline)
    return db_outline


@router.get("", response_model=OutlineListResponse, summary="è·å–å¤§çº²åˆ—è¡¨")
async def get_outlines(
    project_id: str,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """è·å–æŒ‡å®šé¡¹ç›®çš„æ‰€æœ‰å¤§çº²"""
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    await verify_project_access(project_id, user_id, db)
    
    # è·å–æ€»æ•°
    count_result = await db.execute(
        select(func.count(Outline.id)).where(Outline.project_id == project_id)
    )
    total = count_result.scalar_one()
    
    # è·å–å¤§çº²åˆ—è¡¨
    result = await db.execute(
        select(Outline)
        .where(Outline.project_id == project_id)
        .order_by(Outline.order_index)
    )
    outlines = result.scalars().all()
    
    return OutlineListResponse(total=total, items=outlines)


@router.get("/project/{project_id}", response_model=OutlineListResponse, summary="è·å–é¡¹ç›®çš„æ‰€æœ‰å¤§çº²")
async def get_project_outlines(
    project_id: str,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """è·å–æŒ‡å®šé¡¹ç›®çš„æ‰€æœ‰å¤§çº²ï¼ˆè·¯å¾„å‚æ•°ç‰ˆæœ¬ï¼‰"""
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    await verify_project_access(project_id, user_id, db)
    
    # è·å–æ€»æ•°
    count_result = await db.execute(
        select(func.count(Outline.id)).where(Outline.project_id == project_id)
    )
    total = count_result.scalar_one()
    
    # è·å–å¤§çº²åˆ—è¡¨
    result = await db.execute(
        select(Outline)
        .where(Outline.project_id == project_id)
        .order_by(Outline.order_index)
    )
    outlines = result.scalars().all()
    
    return OutlineListResponse(total=total, items=outlines)


@router.get("/{outline_id}", response_model=OutlineResponse, summary="è·å–å¤§çº²è¯¦æƒ…")
async def get_outline(
    outline_id: str,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """æ ¹æ®IDè·å–å¤§çº²è¯¦æƒ…"""
    result = await db.execute(
        select(Outline).where(Outline.id == outline_id)
    )
    outline = result.scalar_one_or_none()
    
    if not outline:
        raise HTTPException(status_code=404, detail="å¤§çº²ä¸å­˜åœ¨")
    
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    await verify_project_access(outline.project_id, user_id, db)
    
    return outline


@router.put("/{outline_id}", response_model=OutlineResponse, summary="æ›´æ–°å¤§çº²")
async def update_outline(
    outline_id: str,
    outline_update: OutlineUpdate,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """æ›´æ–°å¤§çº²ä¿¡æ¯å¹¶åŒæ­¥æ›´æ–°structureå­—æ®µå’Œå…³è”ç« èŠ‚"""
    result = await db.execute(
        select(Outline).where(Outline.id == outline_id)
    )
    outline = result.scalar_one_or_none()
    
    if not outline:
        raise HTTPException(status_code=404, detail="å¤§çº²ä¸å­˜åœ¨")
    
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    project = await verify_project_access(outline.project_id, user_id, db)
    
    # æ›´æ–°å­—æ®µ
    update_data = outline_update.model_dump(exclude_unset=True)
    for field, value in update_data.items():
        setattr(outline, field, value)
    
    # å¦‚æœä¿®æ”¹äº†contentæˆ–titleï¼ŒåŒæ­¥æ›´æ–°structureå­—æ®µ
    if 'content' in update_data or 'title' in update_data:
        try:
            # å°è¯•è§£æç°æœ‰çš„structure
            if outline.structure:
                structure_data = json.loads(outline.structure)
            else:
                structure_data = {}
            
            # æ›´æ–°structureä¸­çš„å¯¹åº”å­—æ®µ
            if 'title' in update_data:
                structure_data['title'] = outline.title
            if 'content' in update_data:
                structure_data['summary'] = outline.content
                structure_data['content'] = outline.content
            
            # ä¿å­˜æ›´æ–°åçš„structure
            outline.structure = json.dumps(structure_data, ensure_ascii=False)
            logger.info(f"åŒæ­¥æ›´æ–°å¤§çº² {outline_id} çš„structureå­—æ®µ")
        except json.JSONDecodeError:
            logger.warning(f"å¤§çº² {outline_id} çš„structureå­—æ®µæ ¼å¼é”™è¯¯ï¼Œè·³è¿‡æ›´æ–°")
    
    # ğŸ”§ ä¼ ç»Ÿæ¨¡å¼ï¼ˆone-to-oneï¼‰ï¼šåŒæ­¥æ›´æ–°å…³è”ç« èŠ‚çš„æ ‡é¢˜
    if 'title' in update_data and project.outline_mode == 'one-to-one':
        try:
            # æŸ¥æ‰¾å¯¹åº”çš„ç« èŠ‚ï¼ˆé€šè¿‡chapter_numberåŒ¹é…order_indexï¼‰
            chapter_result = await db.execute(
                select(Chapter).where(
                    Chapter.project_id == outline.project_id,
                    Chapter.chapter_number == outline.order_index
                )
            )
            chapter = chapter_result.scalar_one_or_none()
            
            if chapter:
                # åŒæ­¥æ›´æ–°ç« èŠ‚æ ‡é¢˜
                chapter.title = outline.title
                logger.info(f"ä¸€å¯¹ä¸€æ¨¡å¼ï¼šåŒæ­¥æ›´æ–°ç« èŠ‚ {chapter.id} çš„æ ‡é¢˜ä¸º '{outline.title}'")
            else:
                logger.debug(f"ä¸€å¯¹ä¸€æ¨¡å¼ï¼šæœªæ‰¾åˆ°å¯¹åº”çš„ç« èŠ‚ï¼ˆchapter_number={outline.order_index}ï¼‰")
        except Exception as e:
            logger.error(f"åŒæ­¥æ›´æ–°ç« èŠ‚æ ‡é¢˜å¤±è´¥: {str(e)}")
            # ä¸é˜»æ–­å¤§çº²æ›´æ–°æµç¨‹ï¼Œä»…è®°å½•é”™è¯¯
    
    await db.commit()
    await db.refresh(outline)
    return outline


@router.delete("/{outline_id}", summary="åˆ é™¤å¤§çº²")
async def delete_outline(
    outline_id: str,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """åˆ é™¤å¤§çº²ï¼ŒåŒæ—¶åˆ é™¤è¯¥å¤§çº²å¯¹åº”çš„æ‰€æœ‰ç« èŠ‚"""
    result = await db.execute(
        select(Outline).where(Outline.id == outline_id)
    )
    outline = result.scalar_one_or_none()
    
    if not outline:
        raise HTTPException(status_code=404, detail="å¤§çº²ä¸å­˜åœ¨")
    
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    project = await verify_project_access(outline.project_id, user_id, db)
    
    project_id = outline.project_id
    deleted_order = outline.order_index
    
    # è·å–è¦åˆ é™¤çš„ç« èŠ‚å¹¶è®¡ç®—æ€»å­—æ•°
    deleted_word_count = 0
    if project.outline_mode == 'one-to-one':
        # one-to-oneæ¨¡å¼ï¼šé€šè¿‡chapter_numberè·å–å¯¹åº”ç« èŠ‚
        chapters_result = await db.execute(
            select(Chapter).where(
                Chapter.project_id == project_id,
                Chapter.chapter_number == outline.order_index
            )
        )
        chapters_to_delete = chapters_result.scalars().all()
        deleted_word_count = sum(ch.word_count or 0 for ch in chapters_to_delete)
        
        # åˆ é™¤ç« èŠ‚
        delete_result = await db.execute(
            delete(Chapter).where(
                Chapter.project_id == project_id,
                Chapter.chapter_number == outline.order_index
            )
        )
        deleted_chapters_count = delete_result.rowcount
        logger.info(f"ä¸€å¯¹ä¸€æ¨¡å¼ï¼šåˆ é™¤å¤§çº² {outline_id}ï¼ˆåºå·{outline.order_index}ï¼‰ï¼ŒåŒæ—¶åˆ é™¤äº†ç¬¬{outline.order_index}ç« ï¼ˆ{deleted_chapters_count}ä¸ªç« èŠ‚ï¼Œ{deleted_word_count}å­—ï¼‰")
    else:
        # one-to-manyæ¨¡å¼ï¼šé€šè¿‡outline_idè·å–å…³è”ç« èŠ‚
        chapters_result = await db.execute(
            select(Chapter).where(Chapter.outline_id == outline_id)
        )
        chapters_to_delete = chapters_result.scalars().all()
        deleted_word_count = sum(ch.word_count or 0 for ch in chapters_to_delete)
        
        # åˆ é™¤ç« èŠ‚
        delete_result = await db.execute(
            delete(Chapter).where(Chapter.outline_id == outline_id)
        )
        deleted_chapters_count = delete_result.rowcount
        logger.info(f"ä¸€å¯¹å¤šæ¨¡å¼ï¼šåˆ é™¤å¤§çº² {outline_id}ï¼ŒåŒæ—¶åˆ é™¤äº† {deleted_chapters_count} ä¸ªå…³è”ç« èŠ‚ï¼ˆ{deleted_word_count}å­—ï¼‰")
    
    # æ›´æ–°é¡¹ç›®å­—æ•°
    if deleted_word_count > 0:
        project.current_words = max(0, project.current_words - deleted_word_count)
        logger.info(f"æ›´æ–°é¡¹ç›®å­—æ•°ï¼šå‡å°‘ {deleted_word_count} å­—")
    
    # åˆ é™¤å¤§çº²
    await db.delete(outline)
    
    # é‡æ–°æ’åºåç»­çš„å¤§çº²ï¼ˆåºå·-1ï¼‰
    result = await db.execute(
        select(Outline).where(
            Outline.project_id == project_id,
            Outline.order_index > deleted_order
        )
    )
    subsequent_outlines = result.scalars().all()
    
    for o in subsequent_outlines:
        o.order_index -= 1
    
    # å¦‚æœæ˜¯one-to-oneæ¨¡å¼ï¼Œè¿˜éœ€è¦é‡æ–°æ’åºåç»­ç« èŠ‚çš„chapter_number
    if project.outline_mode == 'one-to-one':
        chapters_result = await db.execute(
            select(Chapter).where(
                Chapter.project_id == project_id,
                Chapter.chapter_number > deleted_order
            ).order_by(Chapter.chapter_number)
        )
        subsequent_chapters = chapters_result.scalars().all()
        
        for ch in subsequent_chapters:
            ch.chapter_number -= 1
        
        logger.info(f"ä¸€å¯¹ä¸€æ¨¡å¼ï¼šé‡æ–°æ’åºäº† {len(subsequent_chapters)} ä¸ªåç»­ç« èŠ‚")
    
    await db.commit()
    
    return {
        "message": "å¤§çº²åˆ é™¤æˆåŠŸ",
        "deleted_chapters": deleted_chapters_count
    }



@router.post("/predict-characters", summary="é¢„æµ‹ç»­å†™æ‰€éœ€è§’è‰²")
async def predict_characters(
    request_data: CharacterPredictionRequest,
    http_request: Request,
    db: AsyncSession = Depends(get_db),
    user_ai_service: AIService = Depends(get_user_ai_service)
):
    """
    é¢„æµ‹ç»­å†™å¤§çº²æ—¶å¯èƒ½éœ€è¦çš„æ–°è§’è‰²
    
    ç”¨äºè§’è‰²ç¡®è®¤æœºåˆ¶çš„ç¬¬ä¸€æ­¥ï¼šåœ¨ç”Ÿæˆå¤§çº²å‰é¢„æµ‹è§’è‰²éœ€æ±‚
    """
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(http_request.state, 'user_id', None)
    project = await verify_project_access(request_data.project_id, user_id, db)
    
    try:
        # è·å–ç°æœ‰å¤§çº²
        existing_result = await db.execute(
            select(Outline)
            .where(Outline.project_id == request_data.project_id)
            .order_by(Outline.order_index)
        )
        existing_outlines = existing_result.scalars().all()
        
        if not existing_outlines:
            return CharacterPredictionResponse(
                needs_new_characters=False,
                reason="é¡¹ç›®å°šæ— å¤§çº²ï¼Œæ— æ³•é¢„æµ‹è§’è‰²éœ€æ±‚",
                character_count=0,
                predicted_characters=[]
            )
        
        # è·å–ç°æœ‰è§’è‰²
        characters_result = await db.execute(
            select(Character).where(Character.project_id == request_data.project_id)
        )
        characters = characters_result.scalars().all()
        
        # æ„å»ºå·²æœ‰ç« èŠ‚æ¦‚è§ˆ
        all_chapters_brief = ""
        if len(existing_outlines) > 20:
            recent_20 = existing_outlines[-20:]
            all_chapters_brief = "\n".join([
                f"ç¬¬{o.order_index}ç« ã€Š{o.title}ã€‹"
                for o in recent_20
            ])
        else:
            all_chapters_brief = "\n".join([
                f"ç¬¬{o.order_index}ç« ã€Š{o.title}ã€‹"
                for o in existing_outlines
            ])
        
        # è°ƒç”¨è‡ªåŠ¨è§’è‰²æœåŠ¡è¿›è¡Œé¢„æµ‹
        from app.services.auto_character_service import get_auto_character_service
        
        auto_char_service = get_auto_character_service(user_ai_service)
        
        # ä½¿ç”¨é¢„æµ‹æ¨¡å¼ï¼ˆä¸åˆ›å»ºè§’è‰²ï¼Œä»…åˆ†æï¼‰
        last_chapter_number = existing_outlines[-1].order_index
        auto_result = await auto_char_service.analyze_and_create_characters(
            project_id=request_data.project_id,
            outline_content="",  # é¢„æµ‹æ¨¡å¼ä¸éœ€è¦å¤§çº²å†…å®¹
            existing_characters=list(characters),
            db=db,
            user_id=user_id,
            enable_mcp=request_data.enable_mcp,
            all_chapters_brief=all_chapters_brief,
            start_chapter=last_chapter_number + 1,
            chapter_count=request_data.chapter_count,
            plot_stage=request_data.plot_stage,
            story_direction=request_data.story_direction,
            preview_only=True  # æ–°å¢å‚æ•°ï¼šä»…é¢„æµ‹ä¸åˆ›å»º
        )
        
        # æ„å»ºé¢„æµ‹å“åº”
        predicted_characters = []
        for char_data in auto_result.get("predicted_characters", []):
            predicted_characters.append(PredictedCharacter(
                name=char_data.get("name"),
                role_description=char_data.get("role_description", ""),
                suggested_role_type=char_data.get("suggested_role_type", "supporting"),
                importance=char_data.get("importance", "medium"),
                appearance_chapter=char_data.get("appearance_chapter", last_chapter_number + 1),
                key_abilities=char_data.get("key_abilities", []),
                plot_function=char_data.get("plot_function", ""),
                relationship_suggestions=char_data.get("relationship_suggestions", [])
            ))
        
        return CharacterPredictionResponse(
            needs_new_characters=auto_result.get("needs_new_characters", False),
            reason=auto_result.get("reason", ""),
            character_count=len(predicted_characters),
            predicted_characters=predicted_characters
        )
        
    except Exception as e:
        logger.error(f"è§’è‰²é¢„æµ‹å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è§’è‰²é¢„æµ‹å¤±è´¥: {str(e)}")



async def _generate_new_outline(
    request: OutlineGenerateRequest,
    project: Project,
    db: AsyncSession,
    user_ai_service: AIService,
    user_id: str
) -> OutlineListResponse:
    """å…¨æ–°ç”Ÿæˆå¤§çº²ï¼ˆMCPå¢å¼ºç‰ˆï¼‰"""
    logger.info(f"å…¨æ–°ç”Ÿæˆå¤§çº² - é¡¹ç›®: {project.id}, enable_mcp: {request.enable_mcp}")
    
    # è·å–è§’è‰²ä¿¡æ¯
    characters_result = await db.execute(
        select(Character).where(Character.project_id == project.id)
    )
    characters = characters_result.scalars().all()
    characters_info = "\n".join([
        f"- {char.name} ({'ç»„ç»‡' if char.is_organization else 'è§’è‰²'}, {char.role_type}): "
        f"{char.personality[:100] if char.personality else 'æš‚æ— æè¿°'}"
        for char in characters
    ])
    
    # ğŸ” MCPå·¥å…·å¢å¼ºï¼šæ”¶é›†æƒ…èŠ‚è®¾è®¡å‚è€ƒèµ„æ–™ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
    mcp_reference_materials = ""
    if request.enable_mcp:
        try:
            # 1ï¸âƒ£ é™é»˜æ£€æŸ¥å·¥å…·å¯ç”¨æ€§ï¼ˆæ³¨æ„ï¼šæ–°å»ºå¤§çº²æ—¶user_idå¯èƒ½ä¸å¯ç”¨ï¼‰
            from app.services.mcp_tool_service import mcp_tool_service
            # ä½¿ç”¨ä¼ å…¥çš„user_idå‚æ•°
            
            if user_id:
                available_tools = await mcp_tool_service.get_user_enabled_tools(
                    user_id=user_id,
                    db_session=db
                )
                
                # 2ï¸âƒ£ åªåœ¨æœ‰å·¥å…·æ—¶æ‰è°ƒç”¨
                if available_tools:
                    logger.info(f"ğŸ” æ£€æµ‹åˆ°å¯ç”¨MCPå·¥å…·ï¼Œæ”¶é›†å¤§çº²è®¾è®¡å‚è€ƒèµ„æ–™...")
                    
                    # æ„å»ºèµ„æ–™æ”¶é›†æŸ¥è¯¢
                    planning_query = f"""ä½ æ­£åœ¨ä¸ºå°è¯´ã€Š{project.title}ã€‹è®¾è®¡å®Œæ•´å¤§çº²ã€‚
é¡¹ç›®ä¿¡æ¯ï¼š
- ä¸»é¢˜ï¼š{request.theme or project.theme}
- ç±»å‹ï¼š{request.genre or project.genre}
- ç« èŠ‚æ•°ï¼š{request.chapter_count}
- å™äº‹è§†è§’ï¼š{request.narrative_perspective}
- ç›®æ ‡å­—æ•°ï¼š{request.target_words}

ä¸–ç•Œè§‚è®¾å®šï¼š
- æ—¶é—´èƒŒæ™¯ï¼š{project.world_time_period or 'æœªè®¾å®š'}
- åœ°ç†ä½ç½®ï¼š{project.world_location or 'æœªè®¾å®š'}
- æ°›å›´åŸºè°ƒï¼š{project.world_atmosphere or 'æœªè®¾å®š'}

è§’è‰²ä¿¡æ¯ï¼š
{characters_info or 'æš‚æ— è§’è‰²'}

è¯·æœç´¢ï¼š
1. è¯¥ç±»å‹å°è¯´çš„ç»å…¸æƒ…èŠ‚ç»“æ„å’Œå¥—è·¯
2. é€‚åˆè¯¥ä¸»é¢˜çš„å†²çªè®¾è®¡æ€è·¯
3. ç¬¦åˆä¸–ç•Œè§‚çš„æƒ…èŠ‚å…ƒç´ å’Œåœºæ™¯è®¾è®¡çµæ„Ÿ

è¯·æœ‰é’ˆå¯¹æ€§åœ°æŸ¥è¯¢1-2ä¸ªæœ€å…³é”®çš„é—®é¢˜ã€‚"""
                    
                    # è°ƒç”¨MCPå¢å¼ºçš„AIï¼ˆéæµå¼ï¼Œé™åˆ¶1è½®é¿å…è¶…æ—¶ï¼‰
                    planning_result = await user_ai_service.generate_text_with_mcp(
                        prompt=planning_query,
                        user_id=user_id,
                        db_session=db,
                        enable_mcp=True,
                        max_tool_rounds=2,
                        tool_choice="auto",
                        provider=None,
                        model=None
                    )
                    
                    # æå–å‚è€ƒèµ„æ–™
                    if planning_result.get("tool_calls_made", 0) > 0:
                        mcp_reference_materials = planning_result.get("content", "")
                        logger.info(f"âœ… MCPå·¥å…·æ”¶é›†å‚è€ƒèµ„æ–™ï¼š{len(mcp_reference_materials)} å­—ç¬¦")
                    else:
                        logger.info(f"â„¹ï¸ MCPæœªä½¿ç”¨å·¥å…·ï¼Œç»§ç»­")
                else:
                    logger.debug(f"ç”¨æˆ· {user_id} æœªå¯ç”¨MCPå·¥å…·ï¼Œè·³è¿‡MCPå¢å¼º")
            else:
                logger.debug("æ— ç”¨æˆ·ä¸Šä¸‹æ–‡ï¼Œè·³è¿‡MCPå¢å¼º")
        except Exception as e:
            logger.warning(f"âš ï¸ MCPå·¥å…·è°ƒç”¨å¤±è´¥ï¼Œé™çº§ä¸ºåŸºç¡€æ¨¡å¼: {str(e)}")
            mcp_reference_materials = ""
    
    # ä½¿ç”¨å®Œæ•´æç¤ºè¯ï¼ˆæ’å…¥MCPå‚è€ƒèµ„æ–™ï¼Œæ”¯æŒè‡ªå®šä¹‰ï¼‰
    template = await PromptService.get_template("OUTLINE_CREATE", user_id, db)
    prompt = PromptService.format_prompt(
        template,
        title=project.title,
        theme=request.theme or project.theme or "æœªè®¾å®š",
        genre=request.genre or project.genre or "é€šç”¨",
        chapter_count=request.chapter_count,
        narrative_perspective=request.narrative_perspective,
        target_words=request.target_words,
        time_period=project.world_time_period or "æœªè®¾å®š",
        location=project.world_location or "æœªè®¾å®š",
        atmosphere=project.world_atmosphere or "æœªè®¾å®š",
        rules=project.world_rules or "æœªè®¾å®š",
        characters_info=characters_info or "æš‚æ— è§’è‰²ä¿¡æ¯",
        requirements=request.requirements or "",
        mcp_references=mcp_reference_materials
    )
    
    # è°ƒç”¨AIæµå¼ç”Ÿæˆå¤§çº²ï¼ˆå¸¦å­—æ•°ç»Ÿè®¡ï¼‰
    accumulated_text = ""
    chunk_count = 0
    
    async for chunk in user_ai_service.generate_text_stream(
        prompt=prompt,
        provider=request.provider,
        model=request.model
    ):
        chunk_count += 1
        accumulated_text += chunk
        
        # è¿™é‡Œæ˜¯éSSEæ¥å£ï¼Œä¸éœ€è¦å‘é€chunk
        # å¦‚æœæœªæ¥éœ€è¦è½¬SSEï¼Œå¯ä»¥åœ¨è¿™é‡Œyield
    
    ai_content = accumulated_text
    ai_response = {"content": ai_content}
    
    # è§£æå“åº”
    outline_data = _parse_ai_response(ai_content)
    
    # å…¨æ–°ç”Ÿæˆæ¨¡å¼ï¼šåˆ é™¤æ—§å¤§çº²å’Œå…³è”çš„æ‰€æœ‰ç« èŠ‚
    logger.info(f"å…¨æ–°ç”Ÿæˆï¼šåˆ é™¤é¡¹ç›® {project.id} çš„æ—§å¤§çº²å’Œç« èŠ‚ï¼ˆoutline_mode: {project.outline_mode}ï¼‰")
    
    from sqlalchemy import delete as sql_delete
    
    # å…ˆè·å–æ‰€æœ‰æ—§ç« èŠ‚å¹¶è®¡ç®—æ€»å­—æ•°
    old_chapters_result = await db.execute(
        select(Chapter).where(Chapter.project_id == project.id)
    )
    old_chapters = old_chapters_result.scalars().all()
    deleted_word_count = sum(ch.word_count or 0 for ch in old_chapters)
    
    # åˆ é™¤æ‰€æœ‰æ—§ç« èŠ‚ï¼ˆæ— è®ºæ˜¯ä¸€å¯¹ä¸€è¿˜æ˜¯ä¸€å¯¹å¤šæ¨¡å¼ï¼‰
    delete_result = await db.execute(
        sql_delete(Chapter).where(Chapter.project_id == project.id)
    )
    deleted_chapters_count = delete_result.rowcount
    logger.info(f"âœ… å…¨æ–°ç”Ÿæˆï¼šåˆ é™¤äº† {deleted_chapters_count} ä¸ªæ—§ç« èŠ‚ï¼ˆ{deleted_word_count}å­—ï¼‰")
    
    # æ›´æ–°é¡¹ç›®å­—æ•°
    if deleted_word_count > 0:
        project.current_words = max(0, project.current_words - deleted_word_count)
        logger.info(f"æ›´æ–°é¡¹ç›®å­—æ•°ï¼šå‡å°‘ {deleted_word_count} å­—")
    
    # å†åˆ é™¤æ‰€æœ‰æ—§å¤§çº²
    delete_outline_result = await db.execute(
        sql_delete(Outline).where(Outline.project_id == project.id)
    )
    deleted_outlines_count = delete_outline_result.rowcount
    logger.info(f"âœ… å…¨æ–°ç”Ÿæˆï¼šåˆ é™¤äº† {deleted_outlines_count} ä¸ªæ—§å¤§çº²")
    
    # ä¿å­˜æ–°å¤§çº²
    outlines = await _save_outlines(
        project.id, outline_data, db, start_index=1
    )
    
    # è®°å½•å†å²
    history = GenerationHistory(
        project_id=project.id,
        prompt=prompt,
        generated_content=json.dumps(ai_response, ensure_ascii=False) if isinstance(ai_response, dict) else ai_response,
        model=request.model or "default"
    )
    db.add(history)
    
    await db.commit()
    
    for outline in outlines:
        await db.refresh(outline)
    
    logger.info(f"å…¨æ–°ç”Ÿæˆå®Œæˆ - {len(outlines)} ç« ")
    return OutlineListResponse(total=len(outlines), items=outlines)


async def _build_smart_outline_context(
    latest_outlines: List[Outline],
    user_id: str,
    project_id: str
) -> dict:
    """
    æ™ºèƒ½æ„å»ºå¤§çº²ç»­å†™ä¸Šä¸‹æ–‡ï¼ˆæ”¯æŒæµ·é‡å¤§çº²åœºæ™¯ï¼‰
    
    ç­–ç•¥ï¼š
    1. æ•…äº‹éª¨æ¶ï¼šæ¯50ç« é‡‡æ ·1ç« ï¼ˆä»…æ ‡é¢˜ï¼‰
    2. è¿‘æœŸæ¦‚è¦ï¼šæœ€è¿‘20ç« ï¼ˆæ ‡é¢˜+ç®€è¦ï¼‰
    3. æœ€è¿‘è¯¦ç»†ï¼šæœ€è¿‘2ç« ï¼ˆå®Œæ•´å†…å®¹ï¼‰
    
    Args:
        latest_outlines: æ‰€æœ‰å·²æœ‰å¤§çº²åˆ—è¡¨
        user_id: ç”¨æˆ·ID
        project_id: é¡¹ç›®ID
        
    Returns:
        åŒ…å«å‹ç¼©åä¸Šä¸‹æ–‡çš„å­—å…¸
    """
    total_count = len(latest_outlines)
    
    context = {
        'story_skeleton': '',      # æ•…äº‹éª¨æ¶ï¼ˆæ ‡é¢˜åˆ—è¡¨ï¼‰
        'recent_summary': '',      # è¿‘æœŸæ¦‚è¦ï¼ˆæ ‡é¢˜+å†…å®¹å‰50å­—ï¼‰
        'recent_detail': '',       # æœ€è¿‘è¯¦ç»†ï¼ˆå®Œæ•´å†…å®¹ï¼‰
        'stats': {
            'total': total_count,
            'skeleton_samples': 0,
            'recent_summaries': 0,
            'recent_details': 0
        }
    }
    
    try:
        # 1. æ•…äº‹éª¨æ¶ï¼ˆæ¯50ç« é‡‡æ ·ï¼Œä»…æ ‡é¢˜ï¼‰
        if total_count > 50:
            sample_interval = 50
            skeleton_indices = list(range(0, total_count, sample_interval))
            skeleton_titles = [
                f"ç¬¬{latest_outlines[idx].order_index}ç« : {latest_outlines[idx].title}"
                for idx in skeleton_indices
            ]
            context['story_skeleton'] = "ã€æ•…äº‹éª¨æ¶ã€‘\n" + "\n".join(skeleton_titles)
            context['stats']['skeleton_samples'] = len(skeleton_titles)
            logger.info(f"  âœ… æ•…äº‹éª¨æ¶ï¼šé‡‡æ ·{len(skeleton_titles)}ç« æ ‡é¢˜")
        
        # 2. è¿‘æœŸæ¦‚è¦ï¼ˆæœ€è¿‘20ç« ï¼Œæ ‡é¢˜+å†…å®¹å‰50å­—ï¼‰
        recent_summary_count = min(20, total_count)
        if recent_summary_count > 2:  # æ’é™¤æœ€å2ç« ï¼ˆå®ƒä»¬ä¼šå®Œæ•´å±•ç¤ºï¼‰
            recent_for_summary = latest_outlines[-recent_summary_count:-2]
            recent_summaries = [
                f"ç¬¬{o.order_index}ç« ã€Š{o.title}ã€‹: {o.content[:50]}..."
                for o in recent_for_summary
            ]
            context['recent_summary'] = "ã€è¿‘æœŸå¤§çº²æ¦‚è¦ã€‘\n" + "\n".join(recent_summaries)
            context['stats']['recent_summaries'] = len(recent_summaries)
            logger.info(f"  âœ… è¿‘æœŸæ¦‚è¦ï¼š{len(recent_summaries)}ç« ")
        
        # 3. æœ€è¿‘è¯¦ç»†ï¼ˆæœ€è¿‘2ç« ï¼Œå®Œæ•´å†…å®¹ï¼‰
        recent_detail_count = min(2, total_count)
        recent_details = latest_outlines[-recent_detail_count:]
        detail_texts = [
            f"ç¬¬{o.order_index}ç« ã€Š{o.title}ã€‹: {o.content}"
            for o in recent_details
        ]
        context['recent_detail'] = "ã€æœ€è¿‘å¤§çº²è¯¦æƒ…ã€‘\n" + "\n".join(detail_texts)
        context['stats']['recent_details'] = len(detail_texts)
        logger.info(f"  âœ… æœ€è¿‘è¯¦ç»†ï¼š{len(detail_texts)}ç« ")
        
        # è®¡ç®—æ€»é•¿åº¦
        total_length = sum([
            len(context['story_skeleton']),
            len(context['recent_summary']),
            len(context['recent_detail'])
        ])
        context['stats']['total_length'] = total_length
        logger.info(f"ğŸ“Š å¤§çº²ä¸Šä¸‹æ–‡æ€»é•¿åº¦: {total_length} å­—ç¬¦")
        
    except Exception as e:
        logger.error(f"âŒ æ„å»ºæ™ºèƒ½å¤§çº²ä¸Šä¸‹æ–‡å¤±è´¥: {str(e)}", exc_info=True)
    
    return context


async def _continue_outline(
    request: OutlineGenerateRequest,
    project: Project,
    existing_outlines: List[Outline],
    db: AsyncSession,
    user_ai_service: AIService,
    user_id: str
) -> OutlineListResponse:
    """ç»­å†™å¤§çº² - åˆ†æ‰¹ç”Ÿæˆï¼Œæ¯æ‰¹5ç« ï¼ˆè®°å¿†+MCP+è‡ªåŠ¨è§’è‰²å¼•å…¥å¢å¼ºç‰ˆï¼‰"""
    logger.info(f"ç»­å†™å¤§çº² - é¡¹ç›®: {project.id}, å·²æœ‰: {len(existing_outlines)} ç« , enable_mcp: {request.enable_mcp}, enable_auto_characters: {request.enable_auto_characters}")
    
    # åˆ†æå·²æœ‰å¤§çº²
    current_chapter_count = len(existing_outlines)
    last_chapter_number = existing_outlines[-1].order_index
    
    # è®¡ç®—éœ€è¦ç”Ÿæˆçš„æ€»ç« æ•°å’Œæ‰¹æ¬¡
    total_chapters_to_generate = request.chapter_count
    batch_size = 5  # æ¯æ‰¹ç”Ÿæˆ5ç« 
    total_batches = (total_chapters_to_generate + batch_size - 1) // batch_size
    
    logger.info(f"åˆ†æ‰¹ç”Ÿæˆè®¡åˆ’: æ€»å…±{total_chapters_to_generate}ç« ï¼Œåˆ†{total_batches}æ‰¹ï¼Œæ¯æ‰¹{batch_size}ç« ")
    
    # è·å–è§’è‰²ä¿¡æ¯ï¼ˆæ‰€æœ‰æ‰¹æ¬¡å…±ç”¨ï¼‰
    characters_result = await db.execute(
        select(Character).where(Character.project_id == project.id)
    )
    characters = characters_result.scalars().all()
    characters_info = "\n".join([
        f"- {char.name} ({'ç»„ç»‡' if char.is_organization else 'è§’è‰²'}, {char.role_type}): "
        f"{char.personality[:100] if char.personality else 'æš‚æ— æè¿°'}"
        for char in characters
    ])
    
    # æƒ…èŠ‚é˜¶æ®µæŒ‡å¯¼
    stage_instructions = {
        "development": "ç»§ç»­å±•å¼€æƒ…èŠ‚ï¼Œæ·±åŒ–è§’è‰²å…³ç³»ï¼Œæ¨è¿›ä¸»çº¿å†²çª",
        "climax": "è¿›å…¥æ•…äº‹é«˜æ½®ï¼ŒçŸ›ç›¾æ¿€åŒ–ï¼Œå…³é”®å†²çªçˆ†å‘",
        "ending": "è§£å†³ä¸»è¦å†²çªï¼Œæ”¶æŸä¼ç¬”ï¼Œç»™å‡ºç»“å±€"
    }
    stage_instruction = stage_instructions.get(request.plot_stage, "")
    
    # ğŸ­ ã€æ–¹æ¡ˆAã€‘å…ˆè§’è‰²åå¤§çº²ï¼šåœ¨ç”Ÿæˆå¤§çº²å‰é¢„æµ‹å¹¶åˆ›å»ºè§’è‰²
    if request.enable_auto_characters:
        # æ£€æŸ¥æ˜¯å¦æœ‰ç”¨æˆ·ç¡®è®¤çš„è§’è‰²åˆ—è¡¨
        if request.confirmed_characters:
            # ç›´æ¥ä½¿ç”¨ç”¨æˆ·ç¡®è®¤çš„è§’è‰²åˆ—è¡¨åˆ›å»ºè§’è‰²
            try:
                from app.services.auto_character_service import get_auto_character_service
                
                logger.info(f"ğŸ­ ã€ç¡®è®¤æ¨¡å¼ã€‘ç”¨æˆ·æä¾›äº† {len(request.confirmed_characters)} ä¸ªç¡®è®¤çš„è§’è‰²ï¼Œç›´æ¥åˆ›å»º")
                
                auto_char_service = get_auto_character_service(user_ai_service)
                
                for char_data in request.confirmed_characters:
                    try:
                        # ç”Ÿæˆè§’è‰²è¯¦ç»†ä¿¡æ¯
                        character_data = await auto_char_service._generate_character_details(
                            spec=char_data,
                            project=project,
                            existing_characters=list(characters),
                            db=db,
                            user_id=user_id,
                            enable_mcp=request.enable_mcp
                        )
                        
                        # åˆ›å»ºè§’è‰²è®°å½•
                        character = await auto_char_service._create_character_record(
                            project_id=project.id,
                            character_data=character_data,
                            db=db
                        )
                        
                        # å»ºç«‹å…³ç³»
                        relationships_data = character_data.get("relationships") or character_data.get("relationships_array", [])
                        if relationships_data:
                            await auto_char_service._create_relationships(
                                new_character=character,
                                relationship_specs=relationships_data,
                                existing_characters=list(characters),
                                project_id=project.id,
                                db=db
                            )
                        
                        characters.append(character)
                        logger.info(f"âœ… åˆ›å»ºç¡®è®¤çš„è§’è‰²: {character.name}")
                        
                    except Exception as e:
                        logger.error(f"åˆ›å»ºç¡®è®¤çš„è§’è‰²å¤±è´¥: {e}", exc_info=True)
                        continue
                
                # æäº¤è§’è‰²åˆ°æ•°æ®åº“
                await db.commit()
                
                # æ›´æ–°è§’è‰²ä¿¡æ¯ï¼ˆä¾›åç»­å¤§çº²ç”Ÿæˆä½¿ç”¨ï¼‰
                characters_info = "\n".join([
                    f"- {char.name} ({'ç»„ç»‡' if char.is_organization else 'è§’è‰²'}, {char.role_type}): "
                    f"{char.personality[:100] if char.personality else 'æš‚æ— æè¿°'}"
                    for char in characters
                ])
                
                logger.info(f"âœ… ã€ç¡®è®¤æ¨¡å¼ã€‘æˆåŠŸåˆ›å»º {len(request.confirmed_characters)} ä¸ªç”¨æˆ·ç¡®è®¤çš„è§’è‰²")
                
            except Exception as e:
                logger.error(f"âš ï¸ ã€ç¡®è®¤æ¨¡å¼ã€‘åˆ›å»ºç¡®è®¤è§’è‰²å¤±è´¥: {e}", exc_info=True)
        else:
            # ğŸ”® é¢„æµ‹æ¨¡å¼ï¼šä»…é¢„æµ‹è§’è‰²ï¼Œä¸è‡ªåŠ¨åˆ›å»ºï¼Œéœ€è¦ç”¨æˆ·ç¡®è®¤
            # æŠ›å‡ºç‰¹æ®Šå¼‚å¸¸ï¼Œåœ¨éSSEæ¥å£ä¸­ä¼šè¢«æ•è·å¹¶è¿”å›449çŠ¶æ€ç 
            # åœ¨SSEæ¥å£ä¸­ä¼šè¢«ç‰¹æ®Šå¤„ç†
            try:
                from app.services.auto_character_service import get_auto_character_service
                
                logger.info(f"ğŸ”® ã€é¢„æµ‹æ¨¡å¼ã€‘åœ¨ç”Ÿæˆå¤§çº²å‰é¢„æµ‹æ˜¯å¦éœ€è¦æ–°è§’è‰²")
                
                # æ„å»ºå·²æœ‰ç« èŠ‚æ¦‚è§ˆ
                all_chapters_brief_for_analysis = ""
                if len(existing_outlines) > 20:
                    recent_20 = existing_outlines[-20:]
                    all_chapters_brief_for_analysis = "\n".join([
                        f"ç¬¬{o.order_index}ç« ã€Š{o.title}ã€‹"
                        for o in recent_20
                    ])
                else:
                    all_chapters_brief_for_analysis = "\n".join([
                        f"ç¬¬{o.order_index}ç« ã€Š{o.title}ã€‹"
                        for o in existing_outlines
                    ])
                
                # è°ƒç”¨è‡ªåŠ¨è§’è‰²æœåŠ¡ï¼ˆâœ… è®¾ç½® preview_only=Trueï¼Œä»…é¢„æµ‹ä¸åˆ›å»ºï¼‰
                auto_char_service = get_auto_character_service(user_ai_service)
                auto_result = await auto_char_service.analyze_and_create_characters(
                    project_id=project.id,
                    outline_content="",  # é¢„æµ‹æ¨¡å¼ä¸éœ€è¦å¤§çº²å†…å®¹
                    existing_characters=list(characters),
                    db=db,
                    user_id=user_id,
                    enable_mcp=request.enable_mcp,
                    all_chapters_brief=all_chapters_brief_for_analysis,
                    start_chapter=last_chapter_number + 1,
                    chapter_count=total_chapters_to_generate,
                    plot_stage=request.plot_stage,
                    story_direction=request.story_direction or "è‡ªç„¶å»¶ç»­",
                    preview_only=True  # âœ… å…³é”®ä¿®å¤ï¼šè®¾ç½®ä¸ºTrueï¼Œä»…é¢„æµ‹ä¸åˆ›å»º
                )
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ–°è§’è‰²
                if auto_result.get("needs_new_characters") and auto_result.get("predicted_characters"):
                    predicted_count = len(auto_result["predicted_characters"])
                    logger.warning(
                        f"âš ï¸ ã€é¢„æµ‹æ¨¡å¼ã€‘AIé¢„æµ‹éœ€è¦ {predicted_count} ä¸ªæ–°è§’è‰²ï¼Œéœ€è¦ç”¨æˆ·ç¡®è®¤ï¼"
                    )
                    
                    # ğŸš¨ æŠ›å‡ºç‰¹æ®Šå¼‚å¸¸ï¼ŒåŒ…å«é¢„æµ‹çš„è§’è‰²ä¿¡æ¯
                    raise HTTPException(
                        status_code=449,  # 449 Retry With
                        detail={
                            "code": "CHARACTER_CONFIRMATION_REQUIRED",
                            "message": "ç»­å†™éœ€è¦å¼•å…¥æ–°è§’è‰²ï¼Œè¯·å…ˆç¡®è®¤è§’è‰²ä¿¡æ¯",
                            "predicted_characters": auto_result["predicted_characters"],
                            "reason": auto_result.get("reason", "å‰§æƒ…å‘å±•éœ€è¦æ–°è§’è‰²"),
                            "chapter_range": f"ç¬¬{last_chapter_number + 1}-{last_chapter_number + total_chapters_to_generate}ç« "
                        }
                    )
                else:
                    logger.info(f"âœ… ã€é¢„æµ‹æ¨¡å¼ã€‘AIåˆ¤æ–­æ— éœ€å¼•å…¥æ–°è§’è‰²ï¼Œç»§ç»­ç”Ÿæˆå¤§çº²")
                    
            except HTTPException:
                raise
            except Exception as e:
                logger.error(f"âš ï¸ ã€æ–¹æ¡ˆAã€‘é¢„æµ‹æ€§è§’è‰²å¼•å…¥å¤±è´¥: {e}", exc_info=True)
                # ä¸é˜»æ–­å¤§çº²ç”Ÿæˆæµç¨‹
    
    # æ‰¹é‡ç”Ÿæˆ
    all_new_outlines = []
    current_start_chapter = last_chapter_number + 1
    
    for batch_num in range(total_batches):
        # è®¡ç®—å½“å‰æ‰¹æ¬¡çš„ç« èŠ‚æ•°
        remaining_chapters = total_chapters_to_generate - len(all_new_outlines)
        current_batch_size = min(batch_size, remaining_chapters)
        
        logger.info(f"å¼€å§‹ç”Ÿæˆç¬¬{batch_num + 1}/{total_batches}æ‰¹ï¼Œç« èŠ‚èŒƒå›´: {current_start_chapter}-{current_start_chapter + current_batch_size - 1}")
        
        # è·å–æœ€æ–°çš„å¤§çº²åˆ—è¡¨ï¼ˆåŒ…æ‹¬ä¹‹å‰æ‰¹æ¬¡ç”Ÿæˆçš„ï¼‰
        latest_result = await db.execute(
            select(Outline)
            .where(Outline.project_id == project.id)
            .order_by(Outline.order_index)
        )
        latest_outlines = latest_result.scalars().all()
        
        # ğŸš€ ä½¿ç”¨æ™ºèƒ½ä¸Šä¸‹æ–‡æ„å»ºï¼ˆæ”¯æŒæµ·é‡å¤§çº²ï¼‰
        smart_context = await _build_smart_outline_context(
            latest_outlines=latest_outlines,
            user_id=user_id,
            project_id=project.id
        )
        
        # ç»„è£…ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        all_chapters_brief = ""
        if smart_context['story_skeleton']:
            all_chapters_brief += smart_context['story_skeleton'] + "\n\n"
        if smart_context['recent_summary']:
            all_chapters_brief += smart_context['recent_summary'] + "\n\n"
        
        # æœ€è¿‘è¯¦ç»†å†…å®¹ä½œä¸º recent_plot
        recent_plot = smart_context['recent_detail']
        
        # æ—¥å¿—ç»Ÿè®¡
        stats = smart_context['stats']
        logger.info(f"ğŸ“Š å¤§çº²ä¸Šä¸‹æ–‡ç»Ÿè®¡: æ€»æ•°{stats['total']}, éª¨æ¶{stats['skeleton_samples']}, "
                   f"æ¦‚è¦{stats['recent_summaries']}, è¯¦ç»†{stats['recent_details']}, "
                   f"é•¿åº¦{stats['total_length']}å­—ç¬¦")
        
        # ğŸ§  æ„å»ºè®°å¿†å¢å¼ºä¸Šä¸‹æ–‡ï¼ˆä»…ç»­å†™æ¨¡å¼éœ€è¦ï¼‰
        memory_context = None
        try:
            logger.info(f"ğŸ§  ä¸ºç¬¬{batch_num + 1}æ‰¹æ„å»ºè®°å¿†ä¸Šä¸‹æ–‡...")
            # ä½¿ç”¨æœ€è¿‘ä¸€ç« çš„å¤§çº²ä½œä¸ºæŸ¥è¯¢
            query_outline = latest_outlines[-1].content if latest_outlines else ""
            memory_context = await memory_service.build_context_for_generation(
                user_id=user_id,
                project_id=project.id,
                current_chapter=current_start_chapter,
                chapter_outline=query_outline,
                character_names=[c.name for c in characters] if characters else None
            )
            logger.info(f"âœ… è®°å¿†ä¸Šä¸‹æ–‡æ„å»ºå®Œæˆ: {memory_context['stats']}")
        except Exception as e:
            logger.warning(f"âš ï¸ è®°å¿†ä¸Šä¸‹æ–‡æ„å»ºå¤±è´¥ï¼Œç»§ç»­ä¸ä½¿ç”¨è®°å¿†: {str(e)}")
            memory_context = None
        
        # ğŸ” MCPå·¥å…·å¢å¼ºï¼šæ”¶é›†ç»­å†™å‚è€ƒèµ„æ–™ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        mcp_reference_materials = ""
        if request.enable_mcp:
            try:
                # 1ï¸âƒ£ é™é»˜æ£€æŸ¥å·¥å…·å¯ç”¨æ€§
                from app.services.mcp_tool_service import mcp_tool_service
                available_tools = await mcp_tool_service.get_user_enabled_tools(
                    user_id=user_id,
                    db_session=db
                )
                
                # 2ï¸âƒ£ åªåœ¨æœ‰å·¥å…·æ—¶æ‰è°ƒç”¨
                if available_tools:
                    logger.info(f"ğŸ” ç¬¬{batch_num + 1}æ‰¹ï¼šæ£€æµ‹åˆ°å¯ç”¨MCPå·¥å…·ï¼Œæ”¶é›†ç»­å†™å‚è€ƒèµ„æ–™...")
                    
                    # æ„å»ºèµ„æ–™æ”¶é›†æŸ¥è¯¢
                    latest_summary = latest_outlines[-1].content if latest_outlines else ""
                    planning_query = f"""ä½ æ­£åœ¨ä¸ºå°è¯´ã€Š{project.title}ã€‹ç»­å†™å¤§çº²ã€‚
å½“å‰è¿›åº¦ï¼šå·²æœ‰{len(latest_outlines)}ç« ï¼Œå³å°†ç»­å†™ç¬¬{current_start_chapter}-{current_start_chapter + current_batch_size - 1}ç« 

é¡¹ç›®ä¿¡æ¯ï¼š
- ä¸»é¢˜ï¼š{request.theme or project.theme}
- ç±»å‹ï¼š{request.genre or project.genre}
- å™äº‹è§†è§’ï¼š{request.narrative_perspective}
- æƒ…èŠ‚é˜¶æ®µï¼š{request.plot_stage}
- æ•…äº‹å‘å±•æ–¹å‘ï¼š{request.story_direction or 'è‡ªç„¶å»¶ç»­'}

æœ€è¿‘ç« èŠ‚æ¦‚è¦ï¼š
{latest_summary[:200]}

è¯·æœç´¢ï¼š
1. è¯¥æƒ…èŠ‚é˜¶æ®µçš„ç»å…¸å¤„ç†æ‰‹æ³•å’ŒæŠ€å·§
2. é€‚åˆè¯¥å‘å±•æ–¹å‘çš„æƒ…èŠ‚è½¬æŠ˜å’Œå†²çªè®¾è®¡
3. ç¬¦åˆç±»å‹ç‰¹ç‚¹çš„åœºæ™¯è®¾è®¡å’Œå‰§æƒ…å…ƒç´ 

è¯·æœ‰é’ˆå¯¹æ€§åœ°æŸ¥è¯¢1-2ä¸ªæœ€å…³é”®çš„é—®é¢˜ã€‚"""
                    
                    # è°ƒç”¨MCPå¢å¼ºçš„AIï¼ˆéæµå¼ï¼Œé™åˆ¶1è½®é¿å…è¶…æ—¶ï¼‰
                    planning_result = await user_ai_service.generate_text_with_mcp(
                        prompt=planning_query,
                        user_id=user_id,
                        db_session=db,
                        enable_mcp=True,
                        max_tool_rounds=2,  # âœ… å‡å°‘ä¸º1è½®ï¼Œé¿å…è¶…æ—¶
                        tool_choice="auto",
                        provider=None,
                        model=None
                    )
                    
                    # æå–å‚è€ƒèµ„æ–™
                    if planning_result.get("tool_calls_made", 0) > 0:
                        mcp_reference_materials = planning_result.get("content", "")
                        logger.info(f"âœ… ç¬¬{batch_num + 1}æ‰¹MCPå·¥å…·æ”¶é›†å‚è€ƒèµ„æ–™ï¼š{len(mcp_reference_materials)} å­—ç¬¦")
                    else:
                        logger.info(f"â„¹ï¸ ç¬¬{batch_num + 1}æ‰¹MCPæœªä½¿ç”¨å·¥å…·ï¼Œç»§ç»­")
                else:
                    logger.debug(f"ç”¨æˆ· {user_id} æœªå¯ç”¨MCPå·¥å…·ï¼Œè·³è¿‡ç¬¬{batch_num + 1}æ‰¹MCPå¢å¼º")
            except Exception as e:
                logger.warning(f"âš ï¸ ç¬¬{batch_num + 1}æ‰¹MCPå·¥å…·è°ƒç”¨å¤±è´¥ï¼Œé™çº§ä¸ºåŸºç¡€æ¨¡å¼: {str(e)}")
                mcp_reference_materials = ""
        
        # ä½¿ç”¨æ ‡å‡†ç»­å†™æç¤ºè¯æ¨¡æ¿ï¼ˆæ”¯æŒè®°å¿†+MCPå¢å¼º+è‡ªå®šä¹‰ï¼‰
        template = await PromptService.get_template("OUTLINE_CONTINUE", user_id, db)
        prompt = PromptService.format_prompt(
            template,
            title=project.title,
            theme=request.theme or project.theme or "æœªè®¾å®š",
            genre=request.genre or project.genre or "é€šç”¨",
            narrative_perspective=request.narrative_perspective,
            chapter_count=current_batch_size,  # å½“å‰æ‰¹æ¬¡çš„ç« èŠ‚æ•°
            time_period=project.world_time_period or "æœªè®¾å®š",
            location=project.world_location or "æœªè®¾å®š",
            atmosphere=project.world_atmosphere or "æœªè®¾å®š",
            rules=project.world_rules or "æœªè®¾å®š",
            characters_info=characters_info or "æš‚æ— è§’è‰²ä¿¡æ¯",
            current_chapter_count=len(latest_outlines),
            all_chapters_brief=all_chapters_brief,
            recent_plot=recent_plot,
            plot_stage_instruction=stage_instruction,
            start_chapter=current_start_chapter,
            end_chapter=current_start_chapter + current_batch_size - 1,
            story_direction=request.story_direction or "è‡ªç„¶å»¶ç»­",
            requirements=request.requirements or "",
            memory_context=memory_context,
            mcp_references=mcp_reference_materials
        )
        
        # è°ƒç”¨AIç”Ÿæˆå½“å‰æ‰¹æ¬¡ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        logger.info(f"æ­£åœ¨è°ƒç”¨AIæµå¼ç”Ÿæˆç¬¬{batch_num + 1}æ‰¹...")
        
        max_retries = 2
        retry_count = 0
        outline_data = None
        
        while retry_count <= max_retries:
            accumulated_text = ""
            chunk_count = 0
            
            # ç¬¬ä¸€æ¬¡ä½¿ç”¨åŸå§‹promptï¼Œé‡è¯•æ—¶æ·»åŠ æ ¼å¼å¼ºè°ƒ
            current_prompt = prompt if retry_count == 0 else (
                prompt + "\n\nã€é‡è¦æé†’ã€‘è¯·ç¡®ä¿è¿”å›å®Œæ•´çš„JSONæ•°ç»„ï¼Œä¸è¦æˆªæ–­ã€‚æ¯ä¸ªç« èŠ‚å¯¹è±¡å¿…é¡»åŒ…å«å®Œæ•´çš„titleã€summaryç­‰å­—æ®µã€‚"
            )
            
            async for chunk in user_ai_service.generate_text_stream(
                prompt=current_prompt,
                provider=request.provider,
                model=request.model
            ):
                chunk_count += 1
                accumulated_text += chunk
                
                # è¿™é‡Œæ˜¯éSSEæ¥å£ï¼Œä¸éœ€è¦å‘é€chunk
            
            ai_content = accumulated_text
            ai_response = {"content": ai_content}
            
            # è§£æå“åº”
            try:
                outline_data = _parse_ai_response(ai_content, raise_on_error=True)
                break  # è§£ææˆåŠŸï¼Œè·³å‡ºå¾ªç¯
                
            except JSONParseError as e:
                retry_count += 1
                if retry_count > max_retries:
                    # è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä½¿ç”¨fallbackæ•°æ®
                    logger.error(f"âŒ ç¬¬{batch_num + 1}æ‰¹è§£æå¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°({max_retries})ï¼Œä½¿ç”¨fallbackæ•°æ®")
                    outline_data = _parse_ai_response(ai_content, raise_on_error=False)
                    break
                
                logger.warning(f"âš ï¸ ç¬¬{batch_num + 1}æ‰¹JSONè§£æå¤±è´¥ï¼ˆç¬¬{retry_count}æ¬¡ï¼‰ï¼Œæ­£åœ¨é‡è¯•...")
        
        # ä¿å­˜å½“å‰æ‰¹æ¬¡çš„å¤§çº²
        batch_outlines = await _save_outlines(
            project.id, outline_data, db, start_index=current_start_chapter
        )
        
        # è®°å½•å†å²
        history = GenerationHistory(
            project_id=project.id,
            prompt=f"[æ‰¹æ¬¡{batch_num + 1}/{total_batches}] {str(prompt)[:500]}",
            generated_content=json.dumps(ai_response, ensure_ascii=False) if isinstance(ai_response, dict) else ai_response,
            model=request.model or "default"
        )
        db.add(history)
        
        # æäº¤å½“å‰æ‰¹æ¬¡
        await db.commit()
        
        for outline in batch_outlines:
            await db.refresh(outline)
        
        all_new_outlines.extend(batch_outlines)
        current_start_chapter += current_batch_size
        
        logger.info(f"ç¬¬{batch_num + 1}æ‰¹ç”Ÿæˆå®Œæˆï¼Œæœ¬æ‰¹ç”Ÿæˆ{len(batch_outlines)}ç« ")
                
    
    # è¿”å›æ‰€æœ‰å¤§çº²ï¼ˆåŒ…æ‹¬æ—§çš„å’Œæ–°çš„ï¼‰
    final_result = await db.execute(
        select(Outline)
        .where(Outline.project_id == project.id)
        .order_by(Outline.order_index)
    )
    all_outlines = final_result.scalars().all()
    
    logger.info(f"ç»­å†™å®Œæˆ - å…±{total_batches}æ‰¹ï¼Œæ–°å¢ {len(all_new_outlines)} ç« ï¼Œæ€»è®¡ {len(all_outlines)} ç« ")
    return OutlineListResponse(total=len(all_outlines), items=all_outlines)


class JSONParseError(Exception):
    """JSONè§£æå¤±è´¥å¼‚å¸¸ï¼Œç”¨äºè§¦å‘é‡è¯•"""
    def __init__(self, message: str, original_content: str = ""):
        super().__init__(message)
        self.original_content = original_content


def _parse_ai_response(ai_response: str, raise_on_error: bool = False) -> list:
    """
    è§£æAIå“åº”ä¸ºç« èŠ‚æ•°æ®åˆ—è¡¨ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„JSONæ¸…æ´—æ–¹æ³•ï¼‰
    
    Args:
        ai_response: AIè¿”å›çš„åŸå§‹æ–‡æœ¬
        raise_on_error: å¦‚æœä¸ºTrueï¼Œè§£æå¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸è€Œä¸æ˜¯è¿”å›fallbackæ•°æ®
        
    Returns:
        è§£æåçš„ç« èŠ‚æ•°æ®åˆ—è¡¨
        
    Raises:
        JSONParseError: å½“raise_on_error=Trueä¸”è§£æå¤±è´¥æ—¶æŠ›å‡º
    """
    try:
        # ä½¿ç”¨ç»Ÿä¸€çš„JSONæ¸…æ´—æ–¹æ³•ï¼ˆä»AIServiceå¯¼å…¥ï¼‰
        from app.services.ai_service import AIService
        ai_service_temp = AIService()
        cleaned_text = ai_service_temp._clean_json_response(ai_response)
        
        outline_data = json.loads(cleaned_text)
        
        # ç¡®ä¿æ˜¯åˆ—è¡¨æ ¼å¼
        if not isinstance(outline_data, list):
            # å¦‚æœæ˜¯å¯¹è±¡ï¼Œå°è¯•æå–chapterså­—æ®µ
            if isinstance(outline_data, dict):
                outline_data = outline_data.get("chapters", [outline_data])
            else:
                outline_data = [outline_data]
        
        # éªŒè¯è§£æç»“æœæ˜¯å¦æœ‰æ•ˆï¼ˆè‡³å°‘æœ‰ä¸€ä¸ªæœ‰æ•ˆç« èŠ‚ï¼‰
        valid_chapters = [
            ch for ch in outline_data
            if isinstance(ch, dict) and (ch.get("title") or ch.get("summary") or ch.get("content"))
        ]
        
        if not valid_chapters:
            error_msg = "è§£æç»“æœæ— æ•ˆï¼šæœªæ‰¾åˆ°æœ‰æ•ˆçš„ç« èŠ‚æ•°æ®"
            logger.error(f"âŒ {error_msg}")
            if raise_on_error:
                raise JSONParseError(error_msg, ai_response)
            return [{
                "title": "AIç”Ÿæˆçš„å¤§çº²",
                "content": ai_response[:1000],
                "summary": ai_response[:1000]
            }]
        
        logger.info(f"âœ… æˆåŠŸè§£æ {len(valid_chapters)} ä¸ªç« èŠ‚æ•°æ®")
        return valid_chapters
        
    except json.JSONDecodeError as e:
        error_msg = f"JSONè§£æå¤±è´¥: {e}"
        logger.error(f"âŒ AIå“åº”è§£æå¤±è´¥: {e}")
        
        if raise_on_error:
            raise JSONParseError(error_msg, ai_response)
        
        # è¿”å›ä¸€ä¸ªåŒ…å«åŸå§‹å†…å®¹çš„ç« èŠ‚
        return [{
            "title": "AIç”Ÿæˆçš„å¤§çº²",
            "content": ai_response[:1000],
            "summary": ai_response[:1000]
        }]
    except JSONParseError:
        # é‡æ–°æŠ›å‡ºJSONParseError
        raise
    except Exception as e:
        error_msg = f"è§£æå¼‚å¸¸: {str(e)}"
        logger.error(f"âŒ {error_msg}")
        
        if raise_on_error:
            raise JSONParseError(error_msg, ai_response)
        
        return [{
            "title": "è§£æå¼‚å¸¸çš„å¤§çº²",
            "content": "ç³»ç»Ÿé”™è¯¯",
            "summary": "ç³»ç»Ÿé”™è¯¯"
        }]


async def _save_outlines(
    project_id: str,
    outline_data: list,
    db: AsyncSession,
    start_index: int = 1
) -> List[Outline]:
    """
    ä¿å­˜å¤§çº²åˆ°æ•°æ®åº“
    
    å¦‚æœé¡¹ç›®ä¸ºone-to-oneæ¨¡å¼ï¼ŒåŒæ—¶è‡ªåŠ¨åˆ›å»ºå¯¹åº”çš„ç« èŠ‚
    """
    # è·å–é¡¹ç›®ä¿¡æ¯ä»¥ç¡®å®šoutline_mode
    project_result = await db.execute(
        select(Project).where(Project.id == project_id)
    )
    project = project_result.scalar_one_or_none()
    
    outlines = []
    
    for idx, chapter_data in enumerate(outline_data):
        order_idx = chapter_data.get("chapter_number", start_index + idx)
        title = chapter_data.get("title", f"ç¬¬{order_idx}ç« ")
        
        # ä¼˜å…ˆä½¿ç”¨summaryï¼Œå…¶æ¬¡content
        content = chapter_data.get("summary") or chapter_data.get("content", "")
        
        # å¦‚æœæœ‰é¢å¤–ä¿¡æ¯ï¼Œæ·»åŠ åˆ°å†…å®¹ä¸­
        if "key_events" in chapter_data:
            content += f"\n\nå…³é”®äº‹ä»¶ï¼š" + "ã€".join(chapter_data["key_events"])
        if "characters_involved" in chapter_data:
            content += f"\næ¶‰åŠè§’è‰²ï¼š" + "ã€".join(chapter_data["characters_involved"])
        
        # åˆ›å»ºå¤§çº²
        outline = Outline(
            project_id=project_id,
            title=title,
            content=content,
            structure=json.dumps(chapter_data, ensure_ascii=False),
            order_index=order_idx
        )
        db.add(outline)
        outlines.append(outline)
    
    # å¦‚æœæ˜¯one-to-oneæ¨¡å¼ï¼Œè‡ªåŠ¨åˆ›å»ºç« èŠ‚
    if project and project.outline_mode == 'one-to-one':
        await db.flush()  # ç¡®ä¿å¤§çº²æœ‰ID
        
        for outline in outlines:
            await db.refresh(outline)
            
            # ä¸ºæ¯ä¸ªå¤§çº²åˆ›å»ºå¯¹åº”çš„ç« èŠ‚
            chapter = Chapter(
                project_id=project_id,
                title=outline.title,
                summary=outline.content,
                chapter_number=outline.order_index,
                sub_index=1,
                outline_id=None,  # one-to-oneæ¨¡å¼ä¸å…³è”outline_id
                status='pending',
                content=""
            )
            db.add(chapter)
        
        logger.info(f"ä¸€å¯¹ä¸€æ¨¡å¼ï¼šä¸º{len(outlines)}ä¸ªå¤§çº²è‡ªåŠ¨åˆ›å»ºäº†å¯¹åº”çš„ç« èŠ‚")
    
    return outlines


async def new_outline_generator(
    data: Dict[str, Any],
    db: AsyncSession,
    user_ai_service: AIService
) -> AsyncGenerator[str, None]:
    """å…¨æ–°ç”Ÿæˆå¤§çº²SSEç”Ÿæˆå™¨ï¼ˆMCPå¢å¼ºç‰ˆï¼‰"""
    db_committed = False
    try:
        yield await SSEResponse.send_progress("å¼€å§‹ç”Ÿæˆå¤§çº²...", 5)
        
        project_id = data.get("project_id")
        # ç¡®ä¿chapter_countæ˜¯æ•´æ•°ï¼ˆå‰ç«¯å¯èƒ½ä¼ å­—ç¬¦ä¸²ï¼‰
        chapter_count = int(data.get("chapter_count", 10))
        enable_mcp = data.get("enable_mcp", True)
        
        # éªŒè¯é¡¹ç›®
        yield await SSEResponse.send_progress("åŠ è½½é¡¹ç›®ä¿¡æ¯...", 10)
        result = await db.execute(
            select(Project).where(Project.id == project_id)
        )
        project = result.scalar_one_or_none()
        if not project:
            yield await SSEResponse.send_error("é¡¹ç›®ä¸å­˜åœ¨", 404)
            return
        
        yield await SSEResponse.send_progress(f"å‡†å¤‡ç”Ÿæˆ{chapter_count}ç« å¤§çº²...", 15)
        
        # è·å–è§’è‰²ä¿¡æ¯
        characters_result = await db.execute(
            select(Character).where(Character.project_id == project_id)
        )
        characters = characters_result.scalars().all()
        characters_info = "\n".join([
            f"- {char.name} ({'ç»„ç»‡' if char.is_organization else 'è§’è‰²'}, {char.role_type}): "
            f"{char.personality[:100] if char.personality else 'æš‚æ— æè¿°'}"
            for char in characters
        ])
        
        # ğŸ” MCPå·¥å…·å¢å¼ºï¼šæ”¶é›†æƒ…èŠ‚è®¾è®¡å‚è€ƒèµ„æ–™ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        mcp_reference_materials = ""
        if enable_mcp:
            try:
                # 1ï¸âƒ£ é™é»˜æ£€æŸ¥å·¥å…·å¯ç”¨æ€§
                from app.services.mcp_tool_service import mcp_tool_service
                # å°è¯•ä»ç¯å¢ƒè·å–user_idï¼ˆSSEæµå¼åœºæ™¯ä¸‹å¯èƒ½æ²¡æœ‰ï¼‰
                # è¿™é‡Œå¯ä»¥è€ƒè™‘è®©å‰ç«¯ä¼ é€’user_id
                user_id_for_mcp = data.get("user_id")  # éœ€è¦å‰ç«¯ä¼ é€’
                
                if user_id_for_mcp:
                    available_tools = await mcp_tool_service.get_user_enabled_tools(
                        user_id=user_id_for_mcp,
                        db_session=db
                    )
                    
                    # 2ï¸âƒ£ åªåœ¨æœ‰å·¥å…·æ—¶æ‰æ˜¾ç¤ºæ¶ˆæ¯å’Œè°ƒç”¨
                    if available_tools:
                        yield await SSEResponse.send_progress("ğŸ” ä½¿ç”¨MCPå·¥å…·æ”¶é›†å‚è€ƒèµ„æ–™...", 18)
                        logger.info(f"ğŸ” æ£€æµ‹åˆ°å¯ç”¨MCPå·¥å…·ï¼Œæ”¶é›†å¤§çº²è®¾è®¡å‚è€ƒèµ„æ–™...")
                        
                        # æ„å»ºèµ„æ–™æ”¶é›†æŸ¥è¯¢
                        planning_query = f"""ä½ æ­£åœ¨ä¸ºå°è¯´ã€Š{project.title}ã€‹è®¾è®¡å®Œæ•´å¤§çº²ã€‚
é¡¹ç›®ä¿¡æ¯ï¼š
- ä¸»é¢˜ï¼š{data.get('theme') or project.theme}
- ç±»å‹ï¼š{data.get('genre') or project.genre}
- ç« èŠ‚æ•°ï¼š{chapter_count}
- å™äº‹è§†è§’ï¼š{data.get('narrative_perspective') or 'ç¬¬ä¸‰äººç§°'}
- ç›®æ ‡å­—æ•°ï¼š{data.get('target_words') or project.target_words or 100000}

ä¸–ç•Œè§‚è®¾å®šï¼š
- æ—¶é—´èƒŒæ™¯ï¼š{project.world_time_period or 'æœªè®¾å®š'}
- åœ°ç†ä½ç½®ï¼š{project.world_location or 'æœªè®¾å®š'}
- æ°›å›´åŸºè°ƒï¼š{project.world_atmosphere or 'æœªè®¾å®š'}

è§’è‰²ä¿¡æ¯ï¼š
{characters_info or 'æš‚æ— è§’è‰²'}

è¯·æœç´¢ï¼š
1. è¯¥ç±»å‹å°è¯´çš„ç»å…¸æƒ…èŠ‚ç»“æ„å’Œå¥—è·¯
2. é€‚åˆè¯¥ä¸»é¢˜çš„å†²çªè®¾è®¡æ€è·¯
3. ç¬¦åˆä¸–ç•Œè§‚çš„æƒ…èŠ‚å…ƒç´ å’Œåœºæ™¯è®¾è®¡çµæ„Ÿ

è¯·æœ‰é’ˆå¯¹æ€§åœ°æŸ¥è¯¢1-2ä¸ªæœ€å…³é”®çš„é—®é¢˜ã€‚"""
                        
                        # è°ƒç”¨MCPå¢å¼ºçš„AIï¼ˆéæµå¼ï¼Œé™åˆ¶1è½®é¿å…è¶…æ—¶ï¼‰
                        planning_result = await user_ai_service.generate_text_with_mcp(
                            prompt=planning_query,
                            user_id=user_id_for_mcp,
                            db_session=db,
                            enable_mcp=True,
                            max_tool_rounds=2,  # âœ… å‡å°‘ä¸º1è½®ï¼Œé¿å…è¶…æ—¶
                            tool_choice="auto",
                            provider=None,
                            model=None
                        )
                        
                        # æå–å‚è€ƒèµ„æ–™
                        if planning_result.get("tool_calls_made", 0) > 0:
                            mcp_reference_materials = planning_result.get("content", "")
                            logger.info(f"âœ… MCPå·¥å…·æ”¶é›†å‚è€ƒèµ„æ–™ï¼š{len(mcp_reference_materials)} å­—ç¬¦")
                            yield await SSEResponse.send_progress(f"âœ… MCPæ”¶é›†åˆ°å‚è€ƒèµ„æ–™ ({len(mcp_reference_materials)}å­—ç¬¦)", 19)
                        else:
                            logger.info(f"â„¹ï¸ MCPæœªä½¿ç”¨å·¥å…·ï¼Œç»§ç»­")
                    else:
                        logger.debug(f"ç”¨æˆ· {user_id_for_mcp} æœªå¯ç”¨MCPå·¥å…·ï¼Œè·³è¿‡MCPå¢å¼º")
                else:
                    logger.debug("æ— ç”¨æˆ·ä¸Šä¸‹æ–‡ï¼Œè·³è¿‡MCPå¢å¼º")
            except Exception as e:
                logger.warning(f"âš ï¸ MCPå·¥å…·è°ƒç”¨å¤±è´¥ï¼Œé™çº§ä¸ºåŸºç¡€æ¨¡å¼: {str(e)}")
                mcp_reference_materials = ""
        
        # ä½¿ç”¨å®Œæ•´æç¤ºè¯ï¼ˆæ’å…¥MCPå‚è€ƒèµ„æ–™ï¼Œæ”¯æŒè‡ªå®šä¹‰ï¼‰
        yield await SSEResponse.send_progress("å‡†å¤‡AIæç¤ºè¯...", 20)
        template = await PromptService.get_template("OUTLINE_CREATE", user_id_for_mcp, db)
        prompt = PromptService.format_prompt(
            template,
            title=project.title,
            theme=data.get("theme") or project.theme or "æœªè®¾å®š",
            genre=data.get("genre") or project.genre or "é€šç”¨",
            chapter_count=chapter_count,
            narrative_perspective=data.get("narrative_perspective") or "ç¬¬ä¸‰äººç§°",
            target_words=data.get("target_words") or project.target_words or 100000,
            time_period=project.world_time_period or "æœªè®¾å®š",
            location=project.world_location or "æœªè®¾å®š",
            atmosphere=project.world_atmosphere or "æœªè®¾å®š",
            rules=project.world_rules or "æœªè®¾å®š",
            characters_info=characters_info or "æš‚æ— è§’è‰²ä¿¡æ¯",
            requirements=data.get("requirements") or "",
            mcp_references=mcp_reference_materials
        )
        
        # è°ƒç”¨AIæµå¼ç”Ÿæˆ
        yield await SSEResponse.send_progress("ğŸ¤– æ­£åœ¨è°ƒç”¨AIç”Ÿæˆ...", 30)
        
        # æ·»åŠ è°ƒè¯•æ—¥å¿—
        model_param = data.get("model")
        provider_param = data.get("provider")
        logger.info(f"=== å¤§çº²ç”ŸæˆAIè°ƒç”¨å‚æ•° ===")
        logger.info(f"  providerå‚æ•°: {provider_param}")
        logger.info(f"  modelå‚æ•°: {model_param}")
        
        # âœ… æµå¼ç”Ÿæˆï¼ˆå¸¦å­—æ•°ç»Ÿè®¡å’Œè¿›åº¦ï¼‰
        accumulated_text = ""
        chunk_count = 0
        
        async for chunk in user_ai_service.generate_text_stream(
            prompt=prompt,
            provider=provider_param,
            model=model_param
        ):
            chunk_count += 1
            accumulated_text += chunk
            
            # å‘é€å†…å®¹å—
            yield await SSEResponse.send_chunk(chunk)
            
            # å®šæœŸæ›´æ–°è¿›åº¦å’Œå­—æ•°ï¼ˆ30-95%ï¼ŒAIç”Ÿæˆå 65%ï¼‰
            if chunk_count % 5 == 0:
                progress = min(30 + (chunk_count // 2), 95)
                yield await SSEResponse.send_progress(
                    f"AIç”Ÿæˆå¤§çº²ä¸­... ({len(accumulated_text)}å­—ç¬¦)",
                    progress
                )
            
            # æ¯20ä¸ªå—å‘é€å¿ƒè·³
            if chunk_count % 20 == 0:
                yield await SSEResponse.send_heartbeat()
        
        yield await SSEResponse.send_progress("âœ… AIç”Ÿæˆå®Œæˆï¼Œæ­£åœ¨è§£æ...", 96)
        
        ai_content = accumulated_text
        ai_response = {"content": ai_content}
        
        # è§£æå“åº”ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        max_retries = 2
        retry_count = 0
        outline_data = None
        
        while retry_count <= max_retries:
            try:
                # ä½¿ç”¨ raise_on_error=Trueï¼Œè§£æå¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
                outline_data = _parse_ai_response(ai_content, raise_on_error=True)
                break  # è§£ææˆåŠŸï¼Œè·³å‡ºå¾ªç¯
                
            except JSONParseError as e:
                retry_count += 1
                if retry_count > max_retries:
                    # è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä½¿ç”¨fallbackæ•°æ®
                    logger.error(f"âŒ å¤§çº²è§£æå¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°({max_retries})ï¼Œä½¿ç”¨fallbackæ•°æ®")
                    yield await SSEResponse.send_progress(
                        f"âš ï¸ è§£æå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®",
                        96.5
                    )
                    outline_data = _parse_ai_response(ai_content, raise_on_error=False)
                    break
                
                logger.warning(f"âš ï¸ JSONè§£æå¤±è´¥ï¼ˆç¬¬{retry_count}æ¬¡ï¼‰ï¼Œæ­£åœ¨é‡è¯•...")
                yield await SSEResponse.send_progress(
                    f"âš ï¸ è§£æå¤±è´¥ï¼Œæ­£åœ¨é‡è¯•({retry_count}/{max_retries})...",
                    96
                )
                
                # é‡æ–°è°ƒç”¨AIç”Ÿæˆ
                accumulated_text = ""
                chunk_count = 0
                
                # åœ¨promptä¸­æ·»åŠ æ ¼å¼å¼ºè°ƒ
                retry_prompt = prompt + "\n\nã€é‡è¦æé†’ã€‘è¯·ç¡®ä¿è¿”å›å®Œæ•´çš„JSONæ•°ç»„ï¼Œä¸è¦æˆªæ–­ã€‚æ¯ä¸ªç« èŠ‚å¯¹è±¡å¿…é¡»åŒ…å«å®Œæ•´çš„titleã€summaryç­‰å­—æ®µã€‚"
                
                async for chunk in user_ai_service.generate_text_stream(
                    prompt=retry_prompt,
                    provider=provider_param,
                    model=model_param
                ):
                    chunk_count += 1
                    accumulated_text += chunk
                    
                    # å‘é€å†…å®¹å—
                    yield await SSEResponse.send_chunk(chunk)
                    
                    # æ¯20ä¸ªå—å‘é€å¿ƒè·³
                    if chunk_count % 20 == 0:
                        yield await SSEResponse.send_heartbeat()
                
                ai_content = accumulated_text
                ai_response = {"content": ai_content}
                logger.info(f"ğŸ”„ é‡è¯•ç”Ÿæˆå®Œæˆï¼Œç´¯è®¡{len(ai_content)}å­—ç¬¦")
        
        # å…¨æ–°ç”Ÿæˆæ¨¡å¼ï¼šåˆ é™¤æ—§å¤§çº²å’Œå…³è”çš„æ‰€æœ‰ç« èŠ‚
        yield await SSEResponse.send_progress("æ¸…ç†æ—§å¤§çº²å’Œç« èŠ‚...", 97)
        logger.info(f"å…¨æ–°ç”Ÿæˆï¼šåˆ é™¤é¡¹ç›® {project_id} çš„æ—§å¤§çº²å’Œç« èŠ‚ï¼ˆoutline_mode: {project.outline_mode}ï¼‰")
        
        from sqlalchemy import delete as sql_delete
        
        # å…ˆè·å–æ‰€æœ‰æ—§ç« èŠ‚å¹¶è®¡ç®—æ€»å­—æ•°
        old_chapters_result = await db.execute(
            select(Chapter).where(Chapter.project_id == project_id)
        )
        old_chapters = old_chapters_result.scalars().all()
        deleted_word_count = sum(ch.word_count or 0 for ch in old_chapters)
        
        # åˆ é™¤æ‰€æœ‰æ—§ç« èŠ‚
        delete_chapters_result = await db.execute(
            sql_delete(Chapter).where(Chapter.project_id == project_id)
        )
        deleted_chapters_count = delete_chapters_result.rowcount
        logger.info(f"âœ… å…¨æ–°ç”Ÿæˆï¼šåˆ é™¤äº† {deleted_chapters_count} ä¸ªæ—§ç« èŠ‚ï¼ˆ{deleted_word_count}å­—ï¼‰")
        
        # æ›´æ–°é¡¹ç›®å­—æ•°
        if deleted_word_count > 0:
            project.current_words = max(0, project.current_words - deleted_word_count)
            logger.info(f"æ›´æ–°é¡¹ç›®å­—æ•°ï¼šå‡å°‘ {deleted_word_count} å­—")
        
        # å†åˆ é™¤æ‰€æœ‰æ—§å¤§çº²
        delete_outlines_result = await db.execute(
            sql_delete(Outline).where(Outline.project_id == project_id)
        )
        deleted_outlines_count = delete_outlines_result.rowcount
        logger.info(f"âœ… å…¨æ–°ç”Ÿæˆï¼šåˆ é™¤äº† {deleted_outlines_count} ä¸ªæ—§å¤§çº²")
        
        # ä¿å­˜æ–°å¤§çº²
        yield await SSEResponse.send_progress("ğŸ’¾ ä¿å­˜å¤§çº²åˆ°æ•°æ®åº“...", 98)
        outlines = await _save_outlines(
            project_id, outline_data, db, start_index=1
        )
        
        # è®°å½•å†å²
        history = GenerationHistory(
            project_id=project_id,
            prompt=prompt,
            generated_content=json.dumps(ai_response, ensure_ascii=False) if isinstance(ai_response, dict) else ai_response,
            model=data.get("model") or "default"
        )
        db.add(history)
        
        await db.commit()
        db_committed = True
        
        for outline in outlines:
            await db.refresh(outline)
        
        yield await SSEResponse.send_progress("æ•´ç†ç»“æœæ•°æ®...", 99)
        
        logger.info(f"å…¨æ–°ç”Ÿæˆå®Œæˆ - {len(outlines)} ç« ")
        
        # å‘é€æœ€ç»ˆç»“æœ
        yield await SSEResponse.send_result({
            "message": f"æˆåŠŸç”Ÿæˆ{len(outlines)}ç« å¤§çº²",
            "total_chapters": len(outlines),
            "outlines": [
                {
                    "id": outline.id,
                    "project_id": outline.project_id,
                    "title": outline.title,
                    "content": outline.content,
                    "order_index": outline.order_index,
                    "structure": outline.structure,
                    "created_at": outline.created_at.isoformat() if outline.created_at else None,
                    "updated_at": outline.updated_at.isoformat() if outline.updated_at else None
                } for outline in outlines
            ]
        })
        
        yield await SSEResponse.send_progress("ğŸ‰ ç”Ÿæˆå®Œæˆ!", 100, "success")
        yield await SSEResponse.send_done()
        
    except GeneratorExit:
        logger.warning("å¤§çº²ç”Ÿæˆå™¨è¢«æå‰å…³é—­")
        if not db_committed and db.in_transaction():
            await db.rollback()
            logger.info("å¤§çº²ç”Ÿæˆäº‹åŠ¡å·²å›æ»šï¼ˆGeneratorExitï¼‰")
    except Exception as e:
        logger.error(f"å¤§çº²ç”Ÿæˆå¤±è´¥: {str(e)}")
        if not db_committed and db.in_transaction():
            await db.rollback()
            logger.info("å¤§çº²ç”Ÿæˆäº‹åŠ¡å·²å›æ»šï¼ˆå¼‚å¸¸ï¼‰")
        yield await SSEResponse.send_error(f"ç”Ÿæˆå¤±è´¥: {str(e)}")


async def continue_outline_generator(
    data: Dict[str, Any],
    db: AsyncSession,
    user_ai_service: AIService,
    user_id: str = "system"
) -> AsyncGenerator[str, None]:
    """å¤§çº²ç»­å†™SSEç”Ÿæˆå™¨ - åˆ†æ‰¹ç”Ÿæˆï¼Œæ¨é€è¿›åº¦ï¼ˆè®°å¿†+MCPå¢å¼ºç‰ˆï¼‰"""
    db_committed = False
    try:
        yield await SSEResponse.send_progress("å¼€å§‹ç»­å†™å¤§çº²...", 5)
        
        project_id = data.get("project_id")
        # ç¡®ä¿chapter_countæ˜¯æ•´æ•°ï¼ˆå‰ç«¯å¯èƒ½ä¼ å­—ç¬¦ä¸²ï¼‰
        total_chapters_to_generate = int(data.get("chapter_count", 5))
        
        # éªŒè¯é¡¹ç›®
        yield await SSEResponse.send_progress("åŠ è½½é¡¹ç›®ä¿¡æ¯...", 10)
        result = await db.execute(
            select(Project).where(Project.id == project_id)
        )
        project = result.scalar_one_or_none()
        if not project:
            yield await SSEResponse.send_error("é¡¹ç›®ä¸å­˜åœ¨", 404)
            return
        
        # è·å–ç°æœ‰å¤§çº²
        yield await SSEResponse.send_progress("åˆ†æå·²æœ‰å¤§çº²...", 15)
        existing_result = await db.execute(
            select(Outline)
            .where(Outline.project_id == project_id)
            .order_by(Outline.order_index)
        )
        existing_outlines = existing_result.scalars().all()
        
        if not existing_outlines:
            yield await SSEResponse.send_error("ç»­å†™æ¨¡å¼éœ€è¦å·²æœ‰å¤§çº²ï¼Œå½“å‰é¡¹ç›®æ²¡æœ‰å¤§çº²", 400)
            return
        
        current_chapter_count = len(existing_outlines)
        last_chapter_number = existing_outlines[-1].order_index
        
        yield await SSEResponse.send_progress(
            f"å½“å‰å·²æœ‰{str(current_chapter_count)}ç« ï¼Œå°†ç»­å†™{str(total_chapters_to_generate)}ç« ",
            20
        )
        
        # è·å–è§’è‰²ä¿¡æ¯
        characters_result = await db.execute(
            select(Character).where(Character.project_id == project_id)
        )
        characters = characters_result.scalars().all()
        characters_info = "\n".join([
            f"- {char.name} ({'ç»„ç»‡' if char.is_organization else 'è§’è‰²'}, {char.role_type}): "
            f"{char.personality[:100] if char.personality else 'æš‚æ— æè¿°'}"
            for char in characters
        ])

        # åˆ†æ‰¹é…ç½®
        batch_size = 5
        total_batches = (total_chapters_to_generate + batch_size - 1) // batch_size
        yield await SSEResponse.send_progress(
            f"åˆ†æ‰¹ç”Ÿæˆè®¡åˆ’: æ€»å…±{str(total_chapters_to_generate)}ç« ï¼Œåˆ†{str(total_batches)}æ‰¹ï¼Œæ¯æ‰¹{str(batch_size)}ç« ",
            25
        )
        
        # æƒ…èŠ‚é˜¶æ®µæŒ‡å¯¼
        stage_instructions = {
            "development": "ç»§ç»­å±•å¼€æƒ…èŠ‚ï¼Œæ·±åŒ–è§’è‰²å…³ç³»ï¼Œæ¨è¿›ä¸»çº¿å†²çª",
            "climax": "è¿›å…¥æ•…äº‹é«˜æ½®ï¼ŒçŸ›ç›¾æ¿€åŒ–ï¼Œå…³é”®å†²çªçˆ†å‘",
            "ending": "è§£å†³ä¸»è¦å†²çªï¼Œæ”¶æŸä¼ç¬”ï¼Œç»™å‡ºç»“å±€"
        }
        stage_instruction = stage_instructions.get(data.get("plot_stage", "development"), "")
        
        # ğŸ­ ã€æ–¹æ¡ˆAã€‘å…ˆè§’è‰²åå¤§çº²ï¼šåœ¨ç”Ÿæˆå¤§çº²å‰é¢„æµ‹å¹¶åˆ›å»ºè§’è‰²
        enable_auto_characters = data.get("enable_auto_characters", True)
        confirmed_characters = data.get("confirmed_characters")
        
        if enable_auto_characters:
            # æ£€æŸ¥æ˜¯å¦æœ‰ç”¨æˆ·ç¡®è®¤çš„è§’è‰²åˆ—è¡¨
            if confirmed_characters:
                # ç›´æ¥ä½¿ç”¨ç”¨æˆ·ç¡®è®¤çš„è§’è‰²åˆ—è¡¨åˆ›å»ºè§’è‰²
                try:
                    yield await SSEResponse.send_progress(
                        f"ğŸ­ ã€ç¡®è®¤æ¨¡å¼ã€‘åˆ›å»º {len(confirmed_characters)} ä¸ªç”¨æˆ·ç¡®è®¤çš„è§’è‰²...",
                        27
                    )
                    
                    from app.services.auto_character_service import get_auto_character_service
                    
                    logger.info(f"ğŸ­ ã€ç¡®è®¤æ¨¡å¼ã€‘ç”¨æˆ·æä¾›äº† {len(confirmed_characters)} ä¸ªç¡®è®¤çš„è§’è‰²ï¼Œç›´æ¥åˆ›å»º")
                    
                    auto_char_service = get_auto_character_service(user_ai_service)
                    
                    created_count = 0
                    for char_data in confirmed_characters:
                        try:
                            # ç”Ÿæˆè§’è‰²è¯¦ç»†ä¿¡æ¯
                            character_data = await auto_char_service._generate_character_details(
                                spec=char_data,
                                project=project,
                                existing_characters=list(characters),
                                db=db,
                                user_id=user_id,
                                enable_mcp=data.get("enable_mcp", True)
                            )
                            
                            # åˆ›å»ºè§’è‰²è®°å½•
                            character = await auto_char_service._create_character_record(
                                project_id=project_id,
                                character_data=character_data,
                                db=db
                            )
                            
                            # å»ºç«‹å…³ç³»
                            relationships_data = character_data.get("relationships") or character_data.get("relationships_array", [])
                            if relationships_data:
                                await auto_char_service._create_relationships(
                                    new_character=character,
                                    relationship_specs=relationships_data,
                                    existing_characters=list(characters),
                                    project_id=project_id,
                                    db=db
                                )
                            
                            characters.append(character)
                            created_count += 1
                            logger.info(f"âœ… åˆ›å»ºç¡®è®¤çš„è§’è‰²: {character.name}")
                            
                        except Exception as e:
                            logger.error(f"åˆ›å»ºç¡®è®¤çš„è§’è‰²å¤±è´¥: {e}", exc_info=True)
                            continue
                    
                    # æäº¤è§’è‰²åˆ°æ•°æ®åº“
                    await db.commit()
                    
                    yield await SSEResponse.send_progress(
                        f"âœ… ã€ç¡®è®¤æ¨¡å¼ã€‘æˆåŠŸåˆ›å»º {created_count} ä¸ªè§’è‰²",
                        28
                    )
                    logger.info(f"âœ… ã€ç¡®è®¤æ¨¡å¼ã€‘æˆåŠŸåˆ›å»º {created_count} ä¸ªç”¨æˆ·ç¡®è®¤çš„è§’è‰²")
                    
                except Exception as e:
                    logger.error(f"âš ï¸ ã€ç¡®è®¤æ¨¡å¼ã€‘åˆ›å»ºç¡®è®¤è§’è‰²å¤±è´¥: {e}", exc_info=True)
                    yield await SSEResponse.send_progress(
                        f"âš ï¸ è§’è‰²åˆ›å»ºå¤±è´¥ï¼Œç»§ç»­ç”Ÿæˆå¤§çº²",
                        28
                    )
            else:
                # ğŸ”® é¢„æµ‹æ¨¡å¼ï¼šä»…é¢„æµ‹è§’è‰²ï¼Œä¸è‡ªåŠ¨åˆ›å»ºï¼Œéœ€è¦ç”¨æˆ·ç¡®è®¤
                try:
                    yield await SSEResponse.send_progress(
                        "ğŸ”® ã€é¢„æµ‹æ¨¡å¼ã€‘æ£€æµ‹æ˜¯å¦éœ€è¦æ–°è§’è‰²ï¼ˆéœ€ç”¨æˆ·ç¡®è®¤ï¼‰...",
                        27
                    )
                    
                    from app.services.auto_character_service import get_auto_character_service
                    
                    logger.info(f"ğŸ”® ã€é¢„æµ‹æ¨¡å¼ã€‘åœ¨ç”Ÿæˆå¤§çº²å‰é¢„æµ‹æ˜¯å¦éœ€è¦æ–°è§’è‰²")
                    
                    # æ„å»ºå·²æœ‰ç« èŠ‚æ¦‚è§ˆ
                    all_chapters_brief_for_analysis = ""
                    if len(existing_outlines) > 20:
                        recent_20 = existing_outlines[-20:]
                        all_chapters_brief_for_analysis = "\n".join([
                            f"ç¬¬{o.order_index}ç« ã€Š{o.title}ã€‹"
                            for o in recent_20
                        ])
                    else:
                        all_chapters_brief_for_analysis = "\n".join([
                            f"ç¬¬{o.order_index}ç« ã€Š{o.title}ã€‹"
                            for o in existing_outlines
                        ])
                    
                    # è°ƒç”¨è‡ªåŠ¨è§’è‰²æœåŠ¡ï¼ˆâœ… è®¾ç½® preview_only=Trueï¼‰
                    auto_char_service = get_auto_character_service(user_ai_service)
                    auto_result = await auto_char_service.analyze_and_create_characters(
                        project_id=project_id,
                        outline_content="",  # é¢„æµ‹æ¨¡å¼ä¸éœ€è¦å¤§çº²å†…å®¹
                        existing_characters=list(characters),
                        db=db,
                        user_id=user_id,
                        enable_mcp=data.get("enable_mcp", True),
                        all_chapters_brief=all_chapters_brief_for_analysis,
                        start_chapter=last_chapter_number + 1,
                        chapter_count=total_chapters_to_generate,
                        plot_stage=data.get("plot_stage", "development"),
                        story_direction=data.get("story_direction", "è‡ªç„¶å»¶ç»­"),
                        preview_only=True  # âœ… å…³é”®ä¿®å¤ï¼šä»…é¢„æµ‹ä¸åˆ›å»º
                    )
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ–°è§’è‰²
                    if auto_result.get("needs_new_characters") and auto_result.get("predicted_characters"):
                        predicted_count = len(auto_result["predicted_characters"])
                        logger.warning(
                            f"âš ï¸ ã€é¢„æµ‹æ¨¡å¼ã€‘AIé¢„æµ‹éœ€è¦ {predicted_count} ä¸ªæ–°è§’è‰²ï¼Œéœ€è¦ç”¨æˆ·ç¡®è®¤ï¼"
                        )
                        
                        # ğŸš¨ ä½¿ç”¨ä¸“ç”¨äº‹ä»¶ç±»å‹é€šçŸ¥å‰ç«¯éœ€è¦è§’è‰²ç¡®è®¤
                        yield await SSEResponse.send_event(
                            event="character_confirmation_required",
                            data={
                                "message": "ç»­å†™éœ€è¦å¼•å…¥æ–°è§’è‰²ï¼Œè¯·å…ˆç¡®è®¤è§’è‰²ä¿¡æ¯",
                                "predicted_characters": auto_result["predicted_characters"],
                                "reason": auto_result.get("reason", "å‰§æƒ…å‘å±•éœ€è¦æ–°è§’è‰²"),
                                "chapter_range": f"ç¬¬{last_chapter_number + 1}-{last_chapter_number + total_chapters_to_generate}ç« "
                            }
                        )
                        return
                    else:
                        yield await SSEResponse.send_progress(
                            "âœ… ã€é¢„æµ‹æ¨¡å¼ã€‘æ— éœ€å¼•å…¥æ–°è§’è‰²ï¼Œç»§ç»­ç”Ÿæˆå¤§çº²",
                            28
                        )
                        logger.info(f"âœ… ã€é¢„æµ‹æ¨¡å¼ã€‘AIåˆ¤æ–­æ— éœ€å¼•å…¥æ–°è§’è‰²")
                        
                except Exception as e:
                    logger.error(f"âš ï¸ ã€æ–¹æ¡ˆAã€‘é¢„æµ‹æ€§è§’è‰²å¼•å…¥å¤±è´¥: {e}", exc_info=True)
                    yield await SSEResponse.send_progress(
                        f"âš ï¸ è§’è‰²é¢„æµ‹å¤±è´¥ï¼Œç»§ç»­ç”Ÿæˆå¤§çº²",
                        28
                    )
                    # ä¸é˜»æ–­å¤§çº²ç”Ÿæˆæµç¨‹
        
        # æ‰¹é‡ç”Ÿæˆ
        all_new_outlines = []
        current_start_chapter = last_chapter_number + 1

        for batch_num in range(total_batches):
            # è®¡ç®—å½“å‰æ‰¹æ¬¡çš„ç« èŠ‚æ•°
            remaining_chapters = int(total_chapters_to_generate) - len(all_new_outlines)
            current_batch_size = min(batch_size, remaining_chapters)
            
            batch_progress = 25 + (batch_num * 60 // total_batches)
            
            yield await SSEResponse.send_progress(
                f"ğŸ“ ç¬¬{str(batch_num + 1)}/{str(total_batches)}æ‰¹: ç”Ÿæˆç¬¬{str(current_start_chapter)}-{str(current_start_chapter + current_batch_size - 1)}ç« ",
                batch_progress
            )
            
            # è·å–æœ€æ–°çš„å¤§çº²åˆ—è¡¨ï¼ˆåŒ…æ‹¬ä¹‹å‰æ‰¹æ¬¡ç”Ÿæˆçš„ï¼‰
            latest_result = await db.execute(
                select(Outline)
                .where(Outline.project_id == project_id)
                .order_by(Outline.order_index)
            )
            latest_outlines = latest_result.scalars().all()
            
            # ğŸš€ ä½¿ç”¨æ™ºèƒ½ä¸Šä¸‹æ–‡æ„å»ºï¼ˆæ”¯æŒæµ·é‡å¤§çº²ï¼‰
            smart_context = await _build_smart_outline_context(
                latest_outlines=latest_outlines,
                user_id=user_id,
                project_id=project_id
            )
            
            # ç»„è£…ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
            all_chapters_brief = ""
            if smart_context['story_skeleton']:
                all_chapters_brief += smart_context['story_skeleton'] + "\n\n"
            if smart_context['recent_summary']:
                all_chapters_brief += smart_context['recent_summary'] + "\n\n"
            
            # æœ€è¿‘è¯¦ç»†å†…å®¹ä½œä¸º recent_plot
            recent_plot = smart_context['recent_detail']
            
            # æ—¥å¿—ç»Ÿè®¡
            stats = smart_context['stats']
            logger.info(f"ğŸ“Š æ‰¹æ¬¡{batch_num + 1}å¤§çº²ä¸Šä¸‹æ–‡: æ€»æ•°{stats['total']}, "
                       f"éª¨æ¶{stats['skeleton_samples']}, æ¦‚è¦{stats['recent_summaries']}, "
                       f"è¯¦ç»†{stats['recent_details']}, é•¿åº¦{stats['total_length']}å­—ç¬¦")
            
            # ğŸ§  æ„å»ºè®°å¿†å¢å¼ºä¸Šä¸‹æ–‡
            memory_context = None
            try:
                yield await SSEResponse.send_progress(
                    f"ğŸ§  æ„å»ºè®°å¿†ä¸Šä¸‹æ–‡...",
                    batch_progress + 3
                )
                query_outline = latest_outlines[-1].content if latest_outlines else ""
                memory_context = await memory_service.build_context_for_generation(
                    user_id=user_id,
                    project_id=project_id,
                    current_chapter=current_start_chapter,
                    chapter_outline=query_outline,
                    character_names=[c.name for c in characters] if characters else None
                )
                logger.info(f"âœ… è®°å¿†ä¸Šä¸‹æ–‡: {memory_context['stats']}")
            except Exception as e:
                logger.warning(f"âš ï¸ è®°å¿†ä¸Šä¸‹æ–‡æ„å»ºå¤±è´¥: {str(e)}")
                memory_context = None
            # ğŸ” MCPå·¥å…·å¢å¼ºï¼šæ”¶é›†ç»­å†™å‚è€ƒèµ„æ–™ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
            mcp_reference_materials = ""
            enable_mcp = data.get("enable_mcp", True)
            if enable_mcp:
                try:
                    # 1ï¸âƒ£ é™é»˜æ£€æŸ¥å·¥å…·å¯ç”¨æ€§
                    from app.services.mcp_tool_service import mcp_tool_service
                    available_tools = await mcp_tool_service.get_user_enabled_tools(
                        user_id=user_id,
                        db_session=db
                    )
                    
                    # 2ï¸âƒ£ åªåœ¨æœ‰å·¥å…·æ—¶æ‰æ˜¾ç¤ºæ¶ˆæ¯å’Œè°ƒç”¨
                    if available_tools:
                        yield await SSEResponse.send_progress(
                            f"ğŸ” ç¬¬{str(batch_num + 1)}æ‰¹ï¼šä½¿ç”¨MCPå·¥å…·æ”¶é›†å‚è€ƒèµ„æ–™...",
                            batch_progress + 4
                        )
                        logger.info(f"ğŸ” ç¬¬{batch_num + 1}æ‰¹ï¼šæ£€æµ‹åˆ°å¯ç”¨MCPå·¥å…·ï¼Œæ”¶é›†ç»­å†™å‚è€ƒèµ„æ–™...")
                        
                        # æ„å»ºèµ„æ–™æ”¶é›†æŸ¥è¯¢
                        latest_summary = latest_outlines[-1].content if latest_outlines else ""
                        planning_query = f"""ä½ æ­£åœ¨ä¸ºå°è¯´ã€Š{project.title}ã€‹ç»­å†™å¤§çº²ã€‚
å½“å‰è¿›åº¦ï¼šå·²æœ‰{len(latest_outlines)}ç« ï¼Œå³å°†ç»­å†™ç¬¬{current_start_chapter}-{current_start_chapter + current_batch_size - 1}ç« 

é¡¹ç›®ä¿¡æ¯ï¼š
- ä¸»é¢˜ï¼š{data.get('theme') or project.theme}
- ç±»å‹ï¼š{data.get('genre') or project.genre}
- å™äº‹è§†è§’ï¼š{data.get('narrative_perspective') or project.narrative_perspective or 'ç¬¬ä¸‰äººç§°'}
- æƒ…èŠ‚é˜¶æ®µï¼š{data.get('plot_stage', 'development')}
- æ•…äº‹å‘å±•æ–¹å‘ï¼š{data.get('story_direction', 'è‡ªç„¶å»¶ç»­')}

æœ€è¿‘ç« èŠ‚æ¦‚è¦ï¼š
{latest_summary[:200]}

è¯·æœç´¢ï¼š
1. è¯¥æƒ…èŠ‚é˜¶æ®µçš„ç»å…¸å¤„ç†æ‰‹æ³•å’ŒæŠ€å·§
2. é€‚åˆè¯¥å‘å±•æ–¹å‘çš„æƒ…èŠ‚è½¬æŠ˜å’Œå†²çªè®¾è®¡
3. ç¬¦åˆç±»å‹ç‰¹ç‚¹çš„åœºæ™¯è®¾è®¡å’Œå‰§æƒ…å…ƒç´ 

è¯·æœ‰é’ˆå¯¹æ€§åœ°æŸ¥è¯¢1-2ä¸ªæœ€å…³é”®çš„é—®é¢˜ã€‚"""
                        
                        # è°ƒç”¨MCPå¢å¼ºçš„AIï¼ˆéæµå¼ï¼Œé™åˆ¶1è½®é¿å…è¶…æ—¶ï¼‰
                        planning_result = await user_ai_service.generate_text_with_mcp(
                            prompt=planning_query,
                            user_id=user_id,
                            db_session=db,
                            enable_mcp=True,
                            max_tool_rounds=2,  # âœ… å‡å°‘ä¸º1è½®ï¼Œé¿å…è¶…æ—¶
                            tool_choice="auto",
                            provider=None,
                            model=None
                        )
                        
                        # æå–å‚è€ƒèµ„æ–™
                        if planning_result.get("tool_calls_made", 0) > 0:
                            mcp_reference_materials = planning_result.get("content", "")
                            logger.info(f"âœ… ç¬¬{batch_num + 1}æ‰¹MCPå·¥å…·æ”¶é›†å‚è€ƒèµ„æ–™ï¼š{len(mcp_reference_materials)} å­—ç¬¦")
                            yield await SSEResponse.send_progress(
                                f"âœ… ç¬¬{str(batch_num + 1)}æ‰¹æ”¶é›†åˆ°å‚è€ƒèµ„æ–™ ({len(mcp_reference_materials)}å­—ç¬¦)",
                                batch_progress + 4.5
                            )
                        else:
                            logger.info(f"â„¹ï¸ ç¬¬{batch_num + 1}æ‰¹MCPæœªä½¿ç”¨å·¥å…·ï¼Œç»§ç»­")
                    else:
                        logger.debug(f"ç”¨æˆ· {user_id} æœªå¯ç”¨MCPå·¥å…·ï¼Œè·³è¿‡ç¬¬{batch_num + 1}æ‰¹MCPå¢å¼º")
                except Exception as e:
                    logger.warning(f"âš ï¸ ç¬¬{batch_num + 1}æ‰¹MCPå·¥å…·è°ƒç”¨å¤±è´¥ï¼Œé™çº§ä¸ºåŸºç¡€æ¨¡å¼: {str(e)}")
                    mcp_reference_materials = ""
            
            
            yield await SSEResponse.send_progress(
                f" è°ƒç”¨AIç”Ÿæˆç¬¬{str(batch_num + 1)}æ‰¹...",
                batch_progress + 5
            )
            
            # ä½¿ç”¨æ ‡å‡†ç»­å†™æç¤ºè¯æ¨¡æ¿ï¼ˆæ”¯æŒè®°å¿†+MCPå¢å¼º+è‡ªå®šä¹‰ï¼‰
            template = await PromptService.get_template("OUTLINE_CONTINUE", user_id, db)
            prompt = PromptService.format_prompt(
                template,
                title=project.title,
                theme=data.get("theme") or project.theme or "æœªè®¾å®š",
                genre=data.get("genre") or project.genre or "é€šç”¨",
                narrative_perspective=data.get("narrative_perspective") or project.narrative_perspective or "ç¬¬ä¸‰äººç§°",
                chapter_count=current_batch_size,
                time_period=project.world_time_period or "æœªè®¾å®š",
                location=project.world_location or "æœªè®¾å®š",
                atmosphere=project.world_atmosphere or "æœªè®¾å®š",
                rules=project.world_rules or "æœªè®¾å®š",
                characters_info=characters_info or "æš‚æ— è§’è‰²ä¿¡æ¯",
                current_chapter_count=len(latest_outlines),
                all_chapters_brief=all_chapters_brief,
                recent_plot=recent_plot,
                plot_stage_instruction=stage_instruction,
                start_chapter=current_start_chapter,
                end_chapter=current_start_chapter + current_batch_size - 1,
                story_direction=data.get("story_direction", "è‡ªç„¶å»¶ç»­"),
                requirements=data.get("requirements", ""),
                memory_context=memory_context,
                mcp_references=mcp_reference_materials
            )
            
            # è°ƒç”¨AIç”Ÿæˆå½“å‰æ‰¹æ¬¡
            model_param = data.get("model")
            provider_param = data.get("provider")
            logger.info(f"=== ç»­å†™æ‰¹æ¬¡{batch_num + 1} AIè°ƒç”¨å‚æ•° ===")
            logger.info(f"  providerå‚æ•°: {provider_param}")
            logger.info(f"  modelå‚æ•°: {model_param}")
            
            # æµå¼ç”Ÿæˆå¹¶ç´¯ç§¯æ–‡æœ¬
            accumulated_text = ""
            chunk_count = 0
            
            async for chunk in user_ai_service.generate_text_stream(
                prompt=prompt,
                provider=provider_param,
                model=model_param
            ):
                chunk_count += 1
                accumulated_text += chunk
                
                # å‘é€å†…å®¹å—
                yield await SSEResponse.send_chunk(chunk)
                
                # å®šæœŸæ›´æ–°è¿›åº¦ï¼ˆæ¯æ‰¹å ç”¨çº¦50%çš„è¿›åº¦ç©ºé—´ï¼‰
                if chunk_count % 5 == 0:
                    # åœ¨æ‰¹æ¬¡èŒƒå›´å†…å¹³æ»‘é€’å¢ï¼ˆä»10åˆ°85ï¼Œæ€»å…±75%ï¼‰
                    batch_range = 60 // total_batches  # æ€»è¿›åº¦60%åˆ†é…ç»™æ‰€æœ‰æ‰¹æ¬¡
                    progress_in_batch = batch_progress + 5 + min((chunk_count // 2), batch_range - 5)
                    yield await SSEResponse.send_progress(
                        f"ğŸ“ ç¬¬{str(batch_num + 1)}/{str(total_batches)}æ‰¹ç”Ÿæˆä¸­... ({len(accumulated_text)}å­—ç¬¦)",
                        progress_in_batch
                    )
                
                # æ¯20ä¸ªå—å‘é€å¿ƒè·³
                if chunk_count % 20 == 0:
                    yield await SSEResponse.send_heartbeat()
            
            yield await SSEResponse.send_progress(
                f"âœ… ç¬¬{str(batch_num + 1)}æ‰¹AIç”Ÿæˆå®Œæˆï¼Œæ­£åœ¨è§£æ...",
                batch_progress + 10
            )
            
            # æå–å†…å®¹
            ai_content = accumulated_text
            ai_response = {"content": ai_content}
            
            # è§£æå“åº”ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
            max_retries = 2
            retry_count = 0
            outline_data = None
            
            while retry_count <= max_retries:
                try:
                    # ä½¿ç”¨ raise_on_error=Trueï¼Œè§£æå¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸
                    outline_data = _parse_ai_response(ai_content, raise_on_error=True)
                    break  # è§£ææˆåŠŸï¼Œè·³å‡ºå¾ªç¯
                    
                except JSONParseError as e:
                    retry_count += 1
                    if retry_count > max_retries:
                        # è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä½¿ç”¨fallbackæ•°æ®
                        logger.error(f"âŒ ç¬¬{batch_num + 1}æ‰¹è§£æå¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°({max_retries})ï¼Œä½¿ç”¨fallbackæ•°æ®")
                        yield await SSEResponse.send_progress(
                            f"âš ï¸ ç¬¬{str(batch_num + 1)}æ‰¹è§£æå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®",
                            batch_progress + 11
                        )
                        outline_data = _parse_ai_response(ai_content, raise_on_error=False)
                        break
                    
                    logger.warning(f"âš ï¸ ç¬¬{batch_num + 1}æ‰¹JSONè§£æå¤±è´¥ï¼ˆç¬¬{retry_count}æ¬¡ï¼‰ï¼Œæ­£åœ¨é‡è¯•...")
                    yield await SSEResponse.send_progress(
                        f"âš ï¸ ç¬¬{str(batch_num + 1)}æ‰¹è§£æå¤±è´¥ï¼Œæ­£åœ¨é‡è¯•({retry_count}/{max_retries})...",
                        batch_progress + 10.5
                    )
                    
                    # é‡æ–°è°ƒç”¨AIç”Ÿæˆ
                    accumulated_text = ""
                    chunk_count = 0
                    
                    # åœ¨promptä¸­æ·»åŠ æ ¼å¼å¼ºè°ƒ
                    retry_prompt = prompt + "\n\nã€é‡è¦æé†’ã€‘è¯·ç¡®ä¿è¿”å›å®Œæ•´çš„JSONæ•°ç»„ï¼Œä¸è¦æˆªæ–­ã€‚æ¯ä¸ªç« èŠ‚å¯¹è±¡å¿…é¡»åŒ…å«å®Œæ•´çš„titleã€summaryç­‰å­—æ®µã€‚"
                    
                    async for chunk in user_ai_service.generate_text_stream(
                        prompt=retry_prompt,
                        provider=provider_param,
                        model=model_param
                    ):
                        chunk_count += 1
                        accumulated_text += chunk
                        
                        # å‘é€å†…å®¹å—
                        yield await SSEResponse.send_chunk(chunk)
                        
                        # æ¯20ä¸ªå—å‘é€å¿ƒè·³
                        if chunk_count % 20 == 0:
                            yield await SSEResponse.send_heartbeat()
                    
                    ai_content = accumulated_text
                    ai_response = {"content": ai_content}
                    logger.info(f"ğŸ”„ ç¬¬{batch_num + 1}æ‰¹é‡è¯•ç”Ÿæˆå®Œæˆï¼Œç´¯è®¡{len(ai_content)}å­—ç¬¦")
            
            # ä¿å­˜å½“å‰æ‰¹æ¬¡çš„å¤§çº²
            batch_outlines = await _save_outlines(
                project_id, outline_data, db, start_index=current_start_chapter
            )
            
            # è®°å½•å†å²
            history = GenerationHistory(
                project_id=project_id,
                prompt=f"[ç»­å†™æ‰¹æ¬¡{batch_num + 1}/{total_batches}] {str(prompt)[:500]}",
                generated_content=json.dumps(ai_response, ensure_ascii=False) if isinstance(ai_response, dict) else ai_response,
                model=data.get("model") or "default"
            )
            db.add(history)
            
            # æäº¤å½“å‰æ‰¹æ¬¡
            await db.commit()
            
            for outline in batch_outlines:
                await db.refresh(outline)
            
            all_new_outlines.extend(batch_outlines)
            current_start_chapter += current_batch_size
            
            yield await SSEResponse.send_progress(
                f"ğŸ’¾ ç¬¬{str(batch_num + 1)}æ‰¹ä¿å­˜æˆåŠŸï¼æœ¬æ‰¹ç”Ÿæˆ{str(len(batch_outlines))}ç« ï¼Œç´¯è®¡æ–°å¢{str(len(all_new_outlines))}ç« ",
                batch_progress + 15
            )
            
            logger.info(f"ç¬¬{str(batch_num + 1)}æ‰¹ç”Ÿæˆå®Œæˆï¼Œæœ¬æ‰¹ç”Ÿæˆ{str(len(batch_outlines))}ç« ")
        
        db_committed = True
        
        # è¿”å›æ‰€æœ‰å¤§çº²ï¼ˆåŒ…æ‹¬æ—§çš„å’Œæ–°çš„ï¼‰
        final_result = await db.execute(
            select(Outline)
            .where(Outline.project_id == project_id)
            .order_by(Outline.order_index)
        )
        all_outlines = final_result.scalars().all()
        
        yield await SSEResponse.send_progress("æ•´ç†ç»“æœæ•°æ®...", 95)
        
        # å‘é€æœ€ç»ˆç»“æœ
        yield await SSEResponse.send_result({
            "message": f"ç»­å†™å®Œæˆï¼å…±{str(total_batches)}æ‰¹ï¼Œæ–°å¢{str(len(all_new_outlines))}ç« ï¼Œæ€»è®¡{str(len(all_outlines))}ç« ",
            "total_batches": total_batches,
            "new_chapters": len(all_new_outlines),
            "total_chapters": len(all_outlines),
            "outlines": [
                {
                    "id": outline.id,
                    "project_id": outline.project_id,
                    "title": outline.title,
                    "content": outline.content,
                    "order_index": outline.order_index,
                    "structure": outline.structure,
                    "created_at": outline.created_at.isoformat() if outline.created_at else None,
                    "updated_at": outline.updated_at.isoformat() if outline.updated_at else None
                } for outline in all_outlines
            ]
        })
        
        yield await SSEResponse.send_progress("ğŸ‰ ç»­å†™å®Œæˆ!", 100, "success")
        yield await SSEResponse.send_done()
        
    except GeneratorExit:
        logger.warning("å¤§çº²ç»­å†™ç”Ÿæˆå™¨è¢«æå‰å…³é—­")
        if not db_committed and db.in_transaction():
            await db.rollback()
            logger.info("å¤§çº²ç»­å†™äº‹åŠ¡å·²å›æ»šï¼ˆGeneratorExitï¼‰")
    except Exception as e:
        logger.error(f"å¤§çº²ç»­å†™å¤±è´¥: {str(e)}")
        if not db_committed and db.in_transaction():
            await db.rollback()
            logger.info("å¤§çº²ç»­å†™äº‹åŠ¡å·²å›æ»šï¼ˆå¼‚å¸¸ï¼‰")
        yield await SSEResponse.send_error(f"ç»­å†™å¤±è´¥: {str(e)}")


@router.post("/generate-stream", summary="AIç”Ÿæˆ/ç»­å†™å¤§çº²(SSEæµå¼)")
async def generate_outline_stream(
    data: Dict[str, Any],
    request: Request,
    db: AsyncSession = Depends(get_db),
    user_ai_service: AIService = Depends(get_user_ai_service)
):
    """
    ä½¿ç”¨SSEæµå¼ç”Ÿæˆæˆ–ç»­å†™å°è¯´å¤§çº²ï¼Œå®æ—¶æ¨é€æ‰¹æ¬¡è¿›åº¦
    
    æ”¯æŒæ¨¡å¼ï¼š
    - auto: è‡ªåŠ¨åˆ¤æ–­ï¼ˆæ— å¤§çº²â†’æ–°å»ºï¼Œæœ‰å¤§çº²â†’ç»­å†™ï¼‰
    - new: å…¨æ–°ç”Ÿæˆ
    - continue: ç»­å†™æ¨¡å¼
    
    è¯·æ±‚ä½“ç¤ºä¾‹ï¼š
    {
        "project_id": "é¡¹ç›®ID",
        "chapter_count": 5,  // ç« èŠ‚æ•°
        "mode": "auto",  // auto/new/continue
        "theme": "æ•…äº‹ä¸»é¢˜",  // newæ¨¡å¼å¿…éœ€
        "story_direction": "æ•…äº‹å‘å±•æ–¹å‘",  // continueæ¨¡å¼å¯é€‰
        "plot_stage": "development",  // continueæ¨¡å¼ï¼šdevelopment/climax/ending
        "narrative_perspective": "ç¬¬ä¸‰äººç§°",
        "requirements": "å…¶ä»–è¦æ±‚",
        "provider": "openai",  // å¯é€‰
        "model": "gpt-4"  // å¯é€‰
    }
    """
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    project = await verify_project_access(data.get("project_id"), user_id, db)
    
    # åˆ¤æ–­æ¨¡å¼
    mode = data.get("mode", "auto")
    
    # è·å–ç°æœ‰å¤§çº²
    existing_result = await db.execute(
        select(Outline)
        .where(Outline.project_id == data.get("project_id"))
        .order_by(Outline.order_index)
    )
    existing_outlines = existing_result.scalars().all()
    
    # è‡ªåŠ¨åˆ¤æ–­æ¨¡å¼
    if mode == "auto":
        mode = "continue" if existing_outlines else "new"
        logger.info(f"è‡ªåŠ¨åˆ¤æ–­æ¨¡å¼ï¼š{'ç»­å†™' if existing_outlines else 'æ–°å»º'}")
    
    # è·å–ç”¨æˆ·ID
    user_id = getattr(request.state, "user_id", "system")
    
    # æ ¹æ®æ¨¡å¼é€‰æ‹©ç”Ÿæˆå™¨
    if mode == "new":
        return create_sse_response(new_outline_generator(data, db, user_ai_service))
    elif mode == "continue":
        if not existing_outlines:
            raise HTTPException(
                status_code=400,
                detail="ç»­å†™æ¨¡å¼éœ€è¦å·²æœ‰å¤§çº²ï¼Œå½“å‰é¡¹ç›®æ²¡æœ‰å¤§çº²"
            )
        return create_sse_response(continue_outline_generator(data, db, user_ai_service, user_id))
    else:
        raise HTTPException(
            status_code=400,
            detail=f"ä¸æ”¯æŒçš„æ¨¡å¼: {mode}"
        )


async def expand_outline_generator(
    outline_id: str,
    data: Dict[str, Any],
    db: AsyncSession,
    user_ai_service: AIService
) -> AsyncGenerator[str, None]:
    """å•ä¸ªå¤§çº²å±•å¼€SSEç”Ÿæˆå™¨ - å®æ—¶æ¨é€è¿›åº¦ï¼ˆæ”¯æŒåˆ†æ‰¹ç”Ÿæˆï¼‰"""
    db_committed = False
    try:
        yield await SSEResponse.send_progress("å¼€å§‹å±•å¼€å¤§çº²...", 5)
        
        target_chapter_count = int(data.get("target_chapter_count", 3))
        expansion_strategy = data.get("expansion_strategy", "balanced")
        enable_scene_analysis = data.get("enable_scene_analysis", True)
        auto_create_chapters = data.get("auto_create_chapters", False)
        batch_size = int(data.get("batch_size", 5))  # æ”¯æŒè‡ªå®šä¹‰æ‰¹æ¬¡å¤§å°
        
        # è·å–å¤§çº²
        yield await SSEResponse.send_progress("åŠ è½½å¤§çº²ä¿¡æ¯...", 10)
        result = await db.execute(
            select(Outline).where(Outline.id == outline_id)
        )
        outline = result.scalar_one_or_none()
        
        if not outline:
            yield await SSEResponse.send_error("å¤§çº²ä¸å­˜åœ¨", 404)
            return
        
        # è·å–é¡¹ç›®ä¿¡æ¯
        yield await SSEResponse.send_progress("åŠ è½½é¡¹ç›®ä¿¡æ¯...", 15)
        project_result = await db.execute(
            select(Project).where(Project.id == outline.project_id)
        )
        project = project_result.scalar_one_or_none()
        if not project:
            yield await SSEResponse.send_error("é¡¹ç›®ä¸å­˜åœ¨", 404)
            return
        
        yield await SSEResponse.send_progress(
            f"å‡†å¤‡å±•å¼€ã€Š{outline.title}ã€‹ä¸º {target_chapter_count} ç« ...",
            20
        )
        
        # åˆ›å»ºå±•å¼€æœåŠ¡å®ä¾‹
        expansion_service = PlotExpansionService(user_ai_service)
        
        # å®šä¹‰è¿›åº¦å›è°ƒå‡½æ•°
        async def progress_callback(batch_num: int, total_batches: int, start_idx: int, batch_size: int):
            progress = 30 + int((batch_num - 1) / total_batches * 40)
            yield await SSEResponse.send_progress(
                f"ğŸ“ ç”Ÿæˆç¬¬{batch_num}/{total_batches}æ‰¹ï¼ˆç¬¬{start_idx}-{start_idx + batch_size - 1}èŠ‚ï¼‰...",
                progress
            )
        
        # åˆ†æå¤§çº²å¹¶ç”Ÿæˆç« èŠ‚è§„åˆ’ï¼ˆæ”¯æŒåˆ†æ‰¹ï¼‰
        if target_chapter_count > batch_size:
            yield await SSEResponse.send_progress(
                f"ğŸ¤– AIåˆ†æ‰¹ç”Ÿæˆç« èŠ‚è§„åˆ’ï¼ˆæ¯æ‰¹{batch_size}ç« ï¼‰...",
                30
            )
        else:
            yield await SSEResponse.send_progress("ğŸ¤– AIåˆ†æå¤§çº²ï¼Œç”Ÿæˆç« èŠ‚è§„åˆ’...", 30)
        
        chapter_plans = await expansion_service.analyze_outline_for_chapters(
            outline=outline,
            project=project,
            db=db,
            target_chapter_count=target_chapter_count,
            expansion_strategy=expansion_strategy,
            enable_scene_analysis=enable_scene_analysis,
            provider=data.get("provider"),
            model=data.get("model"),
            batch_size=batch_size,
            progress_callback=None  # SSEä¸­æš‚ä¸æ”¯æŒåµŒå¥—å›è°ƒ
        )
        
        if not chapter_plans:
            yield await SSEResponse.send_error("AIåˆ†æå¤±è´¥ï¼Œæœªèƒ½ç”Ÿæˆç« èŠ‚è§„åˆ’", 500)
            return
        
        yield await SSEResponse.send_progress(
            f"âœ… è§„åˆ’ç”Ÿæˆå®Œæˆï¼å…± {len(chapter_plans)} ä¸ªç« èŠ‚",
            70
        )
        
        # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦åˆ›å»ºç« èŠ‚è®°å½•
        created_chapters = None
        if auto_create_chapters:
            yield await SSEResponse.send_progress("ğŸ’¾ åˆ›å»ºç« èŠ‚è®°å½•...", 80)
            
            created_chapters = await expansion_service.create_chapters_from_plans(
                outline_id=outline_id,
                chapter_plans=chapter_plans,
                project_id=outline.project_id,
                db=db,
                start_chapter_number=None  # è‡ªåŠ¨è®¡ç®—ç« èŠ‚åºå·
            )
            
            await db.commit()
            db_committed = True
            
            # åˆ·æ–°ç« èŠ‚æ•°æ®
            for chapter in created_chapters:
                await db.refresh(chapter)
            
            yield await SSEResponse.send_progress(
                f"âœ… æˆåŠŸåˆ›å»º {len(created_chapters)} ä¸ªç« èŠ‚è®°å½•",
                90
            )
        
        yield await SSEResponse.send_progress("æ•´ç†ç»“æœæ•°æ®...", 95)
        
        # æ„å»ºå“åº”æ•°æ®
        result_data = {
            "outline_id": outline_id,
            "outline_title": outline.title,
            "target_chapter_count": target_chapter_count,
            "actual_chapter_count": len(chapter_plans),
            "expansion_strategy": expansion_strategy,
            "chapter_plans": chapter_plans,
            "created_chapters": [
                {
                    "id": ch.id,
                    "chapter_number": ch.chapter_number,
                    "title": ch.title,
                    "summary": ch.summary,
                    "outline_id": ch.outline_id,
                    "sub_index": ch.sub_index,
                    "status": ch.status
                }
                for ch in created_chapters
            ] if created_chapters else None
        }
        
        yield await SSEResponse.send_result(result_data)
        yield await SSEResponse.send_progress("ğŸ‰ å±•å¼€å®Œæˆ!", 100, "success")
        yield await SSEResponse.send_done()
        
    except GeneratorExit:
        logger.warning("å¤§çº²å±•å¼€ç”Ÿæˆå™¨è¢«æå‰å…³é—­")
        if not db_committed and db.in_transaction():
            await db.rollback()
            logger.info("å¤§çº²å±•å¼€äº‹åŠ¡å·²å›æ»šï¼ˆGeneratorExitï¼‰")
    except Exception as e:
        logger.error(f"å¤§çº²å±•å¼€å¤±è´¥: {str(e)}")
        if not db_committed and db.in_transaction():
            await db.rollback()
            logger.info("å¤§çº²å±•å¼€äº‹åŠ¡å·²å›æ»šï¼ˆå¼‚å¸¸ï¼‰")
        yield await SSEResponse.send_error(f"å±•å¼€å¤±è´¥: {str(e)}")


@router.post("/{outline_id}/create-single-chapter", summary="ä¸€å¯¹ä¸€åˆ›å»ºç« èŠ‚(ä¼ ç»Ÿæ¨¡å¼)")
async def create_single_chapter_from_outline(
    outline_id: str,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """
    ä¼ ç»Ÿæ¨¡å¼ï¼šä¸€ä¸ªå¤§çº²å¯¹åº”åˆ›å»ºä¸€ä¸ªç« èŠ‚
    
    é€‚ç”¨åœºæ™¯ï¼š
    - é¡¹ç›®çš„outline_modeä¸º'one-to-one'
    - ç›´æ¥å°†å¤§çº²å†…å®¹ä½œä¸ºç« èŠ‚æ‘˜è¦
    - ä¸è°ƒç”¨AIï¼Œä¸å±•å¼€
    
    æµç¨‹ï¼š
    1. éªŒè¯é¡¹ç›®æ¨¡å¼ä¸ºone-to-one
    2. æ£€æŸ¥è¯¥å¤§çº²æ˜¯å¦å·²åˆ›å»ºç« èŠ‚
    3. åˆ›å»ºç« èŠ‚è®°å½•ï¼ˆoutline_id=NULLï¼Œchapter_number=outline.order_indexï¼‰
    
    è¿”å›ï¼šåˆ›å»ºçš„ç« èŠ‚ä¿¡æ¯
    """
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    
    # è·å–å¤§çº²
    result = await db.execute(
        select(Outline).where(Outline.id == outline_id)
    )
    outline = result.scalar_one_or_none()
    
    if not outline:
        raise HTTPException(status_code=404, detail="å¤§çº²ä¸å­˜åœ¨")
    
    # éªŒè¯é¡¹ç›®æƒé™å¹¶è·å–é¡¹ç›®ä¿¡æ¯
    project = await verify_project_access(outline.project_id, user_id, db)
    
    # éªŒè¯é¡¹ç›®æ¨¡å¼
    if project.outline_mode != 'one-to-one':
        raise HTTPException(
            status_code=400,
            detail=f"å½“å‰é¡¹ç›®ä¸º{project.outline_mode}æ¨¡å¼ï¼Œä¸æ”¯æŒä¸€å¯¹ä¸€åˆ›å»ºã€‚è¯·ä½¿ç”¨å±•å¼€åŠŸèƒ½ã€‚"
        )
    
    # æ£€æŸ¥è¯¥å¤§çº²å¯¹åº”çš„ç« èŠ‚æ˜¯å¦å·²å­˜åœ¨
    existing_chapter_result = await db.execute(
        select(Chapter).where(
            Chapter.project_id == outline.project_id,
            Chapter.chapter_number == outline.order_index,
            Chapter.sub_index == 1
        )
    )
    existing_chapter = existing_chapter_result.scalar_one_or_none()
    
    if existing_chapter:
        raise HTTPException(
            status_code=400,
            detail=f"ç¬¬{outline.order_index}ç« å·²å­˜åœ¨ï¼Œä¸èƒ½é‡å¤åˆ›å»º"
        )
    
    try:
        # åˆ›å»ºç« èŠ‚ï¼ˆoutline_id=NULLè¡¨ç¤ºä¸€å¯¹ä¸€æ¨¡å¼ï¼‰
        new_chapter = Chapter(
            project_id=outline.project_id,
            title=outline.title,
            summary=outline.content,  # ä½¿ç”¨å¤§çº²å†…å®¹ä½œä¸ºæ‘˜è¦
            chapter_number=outline.order_index,
            sub_index=1,  # ä¸€å¯¹ä¸€æ¨¡å¼å›ºå®šä¸º1
            outline_id=None,  # ä¼ ç»Ÿæ¨¡å¼ä¸å…³è”outline_id
            status='pending'
        )
        
        db.add(new_chapter)
        await db.commit()
        await db.refresh(new_chapter)
        
        logger.info(f"ä¸€å¯¹ä¸€æ¨¡å¼ï¼šä¸ºå¤§çº² {outline.title} åˆ›å»ºç« èŠ‚ {new_chapter.chapter_number}")
        
        return {
            "message": "ç« èŠ‚åˆ›å»ºæˆåŠŸ",
            "chapter": {
                "id": new_chapter.id,
                "project_id": new_chapter.project_id,
                "title": new_chapter.title,
                "summary": new_chapter.summary,
                "chapter_number": new_chapter.chapter_number,
                "sub_index": new_chapter.sub_index,
                "outline_id": new_chapter.outline_id,
                "status": new_chapter.status,
                "created_at": new_chapter.created_at.isoformat() if new_chapter.created_at else None
            }
        }
        
    except Exception as e:
        logger.error(f"ä¸€å¯¹ä¸€åˆ›å»ºç« èŠ‚å¤±è´¥: {str(e)}", exc_info=True)
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºç« èŠ‚å¤±è´¥: {str(e)}")


@router.post("/{outline_id}/expand-stream", summary="å±•å¼€å•ä¸ªå¤§çº²ä¸ºå¤šç« (SSEæµå¼)")
async def expand_outline_to_chapters_stream(
    outline_id: str,
    data: Dict[str, Any],
    request: Request,
    db: AsyncSession = Depends(get_db),
    user_ai_service: AIService = Depends(get_user_ai_service)
):
    """
    ä½¿ç”¨SSEæµå¼å±•å¼€å•ä¸ªå¤§çº²ï¼Œå®æ—¶æ¨é€è¿›åº¦
    
    è¯·æ±‚ä½“ç¤ºä¾‹ï¼š
    {
        "target_chapter_count": 3,  // ç›®æ ‡ç« èŠ‚æ•°
        "expansion_strategy": "balanced",  // balanced/climax/detail
        "auto_create_chapters": false,  // æ˜¯å¦è‡ªåŠ¨åˆ›å»ºç« èŠ‚
        "enable_scene_analysis": true,  // æ˜¯å¦å¯ç”¨åœºæ™¯åˆ†æ
        "provider": "openai",  // å¯é€‰
        "model": "gpt-4"  // å¯é€‰
    }
    
    è¿›åº¦é˜¶æ®µï¼š
    - 5% - å¼€å§‹å±•å¼€
    - 10% - åŠ è½½å¤§çº²ä¿¡æ¯
    - 15% - åŠ è½½é¡¹ç›®ä¿¡æ¯
    - 20% - å‡†å¤‡å±•å¼€å‚æ•°
    - 30% - AIåˆ†æå¤§çº²ï¼ˆè€—æ—¶ï¼‰
    - 70% - è§„åˆ’ç”Ÿæˆå®Œæˆ
    - 80% - åˆ›å»ºç« èŠ‚è®°å½•ï¼ˆå¦‚æœauto_create_chapters=Trueï¼‰
    - 90% - åˆ›å»ºå®Œæˆ
    - 95% - æ•´ç†ç»“æœæ•°æ®
    - 100% - å…¨éƒ¨å®Œæˆ
    """
    # è·å–å¤§çº²å¹¶éªŒè¯æƒé™
    result = await db.execute(
        select(Outline).where(Outline.id == outline_id)
    )
    outline = result.scalar_one_or_none()
    
    if not outline:
        raise HTTPException(status_code=404, detail="å¤§çº²ä¸å­˜åœ¨")
    
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    await verify_project_access(outline.project_id, user_id, db)
    
    return create_sse_response(expand_outline_generator(outline_id, data, db, user_ai_service))


@router.get("/{outline_id}/chapters", summary="è·å–å¤§çº²å…³è”çš„ç« èŠ‚")
async def get_outline_chapters(
    outline_id: str,
    request: Request,
    db: AsyncSession = Depends(get_db)
):
    """
    è·å–æŒ‡å®šå¤§çº²å·²å±•å¼€çš„ç« èŠ‚åˆ—è¡¨
    
    ç”¨äºæ£€æŸ¥å¤§çº²æ˜¯å¦å·²ç»å±•å¼€è¿‡,å¦‚æœæœ‰åˆ™è¿”å›ç« èŠ‚ä¿¡æ¯
    """
    # è·å–å¤§çº²
    result = await db.execute(
        select(Outline).where(Outline.id == outline_id)
    )
    outline = result.scalar_one_or_none()
    
    if not outline:
        raise HTTPException(status_code=404, detail="å¤§çº²ä¸å­˜åœ¨")
    
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    await verify_project_access(outline.project_id, user_id, db)
    
    # æŸ¥è¯¢è¯¥å¤§çº²å…³è”çš„ç« èŠ‚
    chapters_result = await db.execute(
        select(Chapter)
        .where(Chapter.outline_id == outline_id)
        .order_by(Chapter.sub_index)
    )
    chapters = chapters_result.scalars().all()
    
    # å¦‚æœæœ‰ç« èŠ‚,è§£æå±•å¼€è§„åˆ’
    expansion_plans = []
    if chapters:
        for chapter in chapters:
            plan_data = None
            if chapter.expansion_plan:
                try:
                    plan_data = json.loads(chapter.expansion_plan)
                except json.JSONDecodeError:
                    logger.warning(f"ç« èŠ‚ {chapter.id} çš„expansion_planè§£æå¤±è´¥")
                    plan_data = None
            
            expansion_plans.append({
                "sub_index": chapter.sub_index,
                "title": chapter.title,
                "plot_summary": chapter.summary or "",
                "key_events": plan_data.get("key_events", []) if plan_data else [],
                "character_focus": plan_data.get("character_focus", []) if plan_data else [],
                "emotional_tone": plan_data.get("emotional_tone", "") if plan_data else "",
                "narrative_goal": plan_data.get("narrative_goal", "") if plan_data else "",
                "conflict_type": plan_data.get("conflict_type", "") if plan_data else "",
                "estimated_words": plan_data.get("estimated_words", 0) if plan_data else 0,
                "scenes": plan_data.get("scenes") if plan_data else None
            })
    
    return {
        "has_chapters": len(chapters) > 0,
        "outline_id": outline_id,
        "outline_title": outline.title,
        "chapter_count": len(chapters),
        "chapters": [
            {
                "id": ch.id,
                "chapter_number": ch.chapter_number,
                "title": ch.title,
                "summary": ch.summary,
                "sub_index": ch.sub_index,
                "status": ch.status,
                "word_count": ch.word_count
            }
            for ch in chapters
        ],
        "expansion_plans": expansion_plans if expansion_plans else None
    }


async def batch_expand_outlines_generator(
    data: Dict[str, Any],
    db: AsyncSession,
    user_ai_service: AIService
) -> AsyncGenerator[str, None]:
    """æ‰¹é‡å±•å¼€å¤§çº²SSEç”Ÿæˆå™¨ - å®æ—¶æ¨é€è¿›åº¦"""
    db_committed = False
    try:
        yield await SSEResponse.send_progress("å¼€å§‹æ‰¹é‡å±•å¼€å¤§çº²...", 5)
        
        project_id = data.get("project_id")
        chapters_per_outline = int(data.get("chapters_per_outline", 3))
        expansion_strategy = data.get("expansion_strategy", "balanced")
        auto_create_chapters = data.get("auto_create_chapters", False)
        outline_ids = data.get("outline_ids")
        
        # è·å–é¡¹ç›®ä¿¡æ¯
        yield await SSEResponse.send_progress("åŠ è½½é¡¹ç›®ä¿¡æ¯...", 10)
        project_result = await db.execute(
            select(Project).where(Project.id == project_id)
        )
        project = project_result.scalar_one_or_none()
        if not project:
            yield await SSEResponse.send_error("é¡¹ç›®ä¸å­˜åœ¨", 404)
            return
        
        # è·å–è¦å±•å¼€çš„å¤§çº²åˆ—è¡¨
        yield await SSEResponse.send_progress("è·å–å¤§çº²åˆ—è¡¨...", 15)
        if outline_ids:
            outlines_result = await db.execute(
                select(Outline)
                .where(
                    Outline.project_id == project_id,
                    Outline.id.in_(outline_ids)
                )
                .order_by(Outline.order_index)
            )
        else:
            outlines_result = await db.execute(
                select(Outline)
                .where(Outline.project_id == project_id)
                .order_by(Outline.order_index)
            )
        
        outlines = outlines_result.scalars().all()
        
        if not outlines:
            yield await SSEResponse.send_error("æ²¡æœ‰æ‰¾åˆ°è¦å±•å¼€çš„å¤§çº²", 404)
            return
        
        total_outlines = len(outlines)
        yield await SSEResponse.send_progress(
            f"å…±æ‰¾åˆ° {total_outlines} ä¸ªå¤§çº²ï¼Œå¼€å§‹æ‰¹é‡å±•å¼€...",
            20
        )
        
        # åˆ›å»ºå±•å¼€æœåŠ¡å®ä¾‹
        expansion_service = PlotExpansionService(user_ai_service)
        
        expansion_results = []
        total_chapters_created = 0
        skipped_outlines = []
        
        for idx, outline in enumerate(outlines):
            try:
                # è®¡ç®—å½“å‰è¿›åº¦ (20% - 90%)
                progress = 20 + int((idx / total_outlines) * 70)
                
                yield await SSEResponse.send_progress(
                    f"ğŸ“ å¤„ç†ç¬¬ {idx + 1}/{total_outlines} ä¸ªå¤§çº²: {outline.title}",
                    progress
                )
                
                # æ£€æŸ¥å¤§çº²æ˜¯å¦å·²ç»å±•å¼€è¿‡
                existing_chapters_result = await db.execute(
                    select(Chapter)
                    .where(Chapter.outline_id == outline.id)
                    .limit(1)
                )
                existing_chapter = existing_chapters_result.scalar_one_or_none()
                
                if existing_chapter:
                    logger.info(f"å¤§çº² {outline.title} (ID: {outline.id}) å·²ç»å±•å¼€è¿‡ï¼Œè·³è¿‡")
                    skipped_outlines.append({
                        "outline_id": outline.id,
                        "outline_title": outline.title,
                        "reason": "å·²å±•å¼€"
                    })
                    yield await SSEResponse.send_progress(
                        f"â­ï¸ {outline.title} å·²å±•å¼€è¿‡ï¼Œè·³è¿‡",
                        progress + 1
                    )
                    continue
                
                # åˆ†æå¤§çº²ç”Ÿæˆç« èŠ‚è§„åˆ’
                yield await SSEResponse.send_progress(
                    f"ğŸ¤– AIåˆ†æå¤§çº²: {outline.title}",
                    progress + 2
                )
                
                chapter_plans = await expansion_service.analyze_outline_for_chapters(
                    outline=outline,
                    project=project,
                    db=db,
                    target_chapter_count=chapters_per_outline,
                    expansion_strategy=expansion_strategy,
                    enable_scene_analysis=data.get("enable_scene_analysis", True),
                    provider=data.get("provider"),
                    model=data.get("model")
                )
                
                yield await SSEResponse.send_progress(
                    f"âœ… {outline.title} è§„åˆ’ç”Ÿæˆå®Œæˆ ({len(chapter_plans)} ç« )",
                    progress + 3
                )
                
                created_chapters = None
                if auto_create_chapters:
                    # åˆ›å»ºç« èŠ‚è®°å½•
                    chapters = await expansion_service.create_chapters_from_plans(
                        outline_id=outline.id,
                        chapter_plans=chapter_plans,
                        project_id=outline.project_id,
                        db=db,
                        start_chapter_number=None  # è‡ªåŠ¨è®¡ç®—ç« èŠ‚åºå·
                    )
                    created_chapters = [
                        {
                            "id": ch.id,
                            "chapter_number": ch.chapter_number,
                            "title": ch.title,
                            "summary": ch.summary,
                            "outline_id": ch.outline_id,
                            "sub_index": ch.sub_index,
                            "status": ch.status
                        }
                        for ch in chapters
                    ]
                    total_chapters_created += len(chapters)
                    
                    yield await SSEResponse.send_progress(
                        f"ğŸ’¾ {outline.title} ç« èŠ‚åˆ›å»ºå®Œæˆ ({len(chapters)} ç« )",
                        progress + 4
                    )
                
                expansion_results.append({
                    "outline_id": outline.id,
                    "outline_title": outline.title,
                    "target_chapter_count": chapters_per_outline,
                    "actual_chapter_count": len(chapter_plans),
                    "expansion_strategy": expansion_strategy,
                    "chapter_plans": chapter_plans,
                    "created_chapters": created_chapters
                })
                
                logger.info(f"å¤§çº² {outline.title} å±•å¼€å®Œæˆï¼Œç”Ÿæˆ {len(chapter_plans)} ä¸ªç« èŠ‚è§„åˆ’")
                
            except Exception as e:
                logger.error(f"å±•å¼€å¤§çº² {outline.id} å¤±è´¥: {str(e)}", exc_info=True)
                yield await SSEResponse.send_progress(
                    f"âŒ {outline.title} å±•å¼€å¤±è´¥: {str(e)}",
                    progress
                )
                expansion_results.append({
                    "outline_id": outline.id,
                    "outline_title": outline.title,
                    "target_chapter_count": chapters_per_outline,
                    "actual_chapter_count": 0,
                    "expansion_strategy": expansion_strategy,
                    "chapter_plans": [],
                    "created_chapters": None,
                    "error": str(e)
                })
        
        yield await SSEResponse.send_progress("æ•´ç†ç»“æœæ•°æ®...", 95)
        
        db_committed = True
        
        logger.info(f"æ‰¹é‡å±•å¼€å®Œæˆ: {len(expansion_results)} ä¸ªå¤§çº²ï¼Œè·³è¿‡ {len(skipped_outlines)} ä¸ªï¼Œå…±ç”Ÿæˆ {total_chapters_created} ä¸ªç« èŠ‚")
        
        # å‘é€æœ€ç»ˆç»“æœ
        result_data = {
            "project_id": project_id,
            "total_outlines_expanded": len(expansion_results),
            "total_chapters_created": total_chapters_created,
            "skipped_count": len(skipped_outlines),
            "skipped_outlines": skipped_outlines,
            "expansion_results": [
                {
                    "outline_id": result["outline_id"],
                    "outline_title": result["outline_title"],
                    "target_chapter_count": result["target_chapter_count"],
                    "actual_chapter_count": result["actual_chapter_count"],
                    "expansion_strategy": result["expansion_strategy"],
                    "chapter_plans": result["chapter_plans"],
                    "created_chapters": result.get("created_chapters")
                }
                for result in expansion_results
            ]
        }
        
        yield await SSEResponse.send_result(result_data)
        yield await SSEResponse.send_progress("ğŸ‰ æ‰¹é‡å±•å¼€å®Œæˆ!", 100, "success")
        yield await SSEResponse.send_done()
        
    except GeneratorExit:
        logger.warning("æ‰¹é‡å±•å¼€ç”Ÿæˆå™¨è¢«æå‰å…³é—­")
        if not db_committed and db.in_transaction():
            await db.rollback()
            logger.info("æ‰¹é‡å±•å¼€äº‹åŠ¡å·²å›æ»šï¼ˆGeneratorExitï¼‰")
    except Exception as e:
        logger.error(f"æ‰¹é‡å±•å¼€å¤±è´¥: {str(e)}")
        if not db_committed and db.in_transaction():
            await db.rollback()
            logger.info("æ‰¹é‡å±•å¼€äº‹åŠ¡å·²å›æ»šï¼ˆå¼‚å¸¸ï¼‰")
        yield await SSEResponse.send_error(f"æ‰¹é‡å±•å¼€å¤±è´¥: {str(e)}")


@router.post("/batch-expand-stream", summary="æ‰¹é‡å±•å¼€å¤§çº²ä¸ºå¤šç« (SSEæµå¼)")
async def batch_expand_outlines_stream(
    data: Dict[str, Any],
    request: Request,
    db: AsyncSession = Depends(get_db),
    user_ai_service: AIService = Depends(get_user_ai_service)
):
    """
    ä½¿ç”¨SSEæµå¼æ‰¹é‡å±•å¼€å¤§çº²ï¼Œå®æ—¶æ¨é€æ¯ä¸ªå¤§çº²çš„å¤„ç†è¿›åº¦
    
    è¯·æ±‚ä½“ç¤ºä¾‹ï¼š
    {
        "project_id": "é¡¹ç›®ID",
        "outline_ids": ["å¤§çº²ID1", "å¤§çº²ID2"],  // å¯é€‰ï¼Œä¸ä¼ åˆ™å±•å¼€æ‰€æœ‰å¤§çº²
        "chapters_per_outline": 3,  // æ¯ä¸ªå¤§çº²å±•å¼€å‡ ç« 
        "expansion_strategy": "balanced",  // balanced/climax/detail
        "auto_create_chapters": false,  // æ˜¯å¦è‡ªåŠ¨åˆ›å»ºç« èŠ‚
        "enable_scene_analysis": true,  // æ˜¯å¦å¯ç”¨åœºæ™¯åˆ†æ
        "provider": "openai",  // å¯é€‰
        "model": "gpt-4"  // å¯é€‰
    }
    """
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    await verify_project_access(data.get("project_id"), user_id, db)
    
    return create_sse_response(batch_expand_outlines_generator(data, db, user_ai_service))


@router.post("/{outline_id}/create-chapters-from-plans", response_model=CreateChaptersFromPlansResponse, summary="æ ¹æ®å·²æœ‰è§„åˆ’åˆ›å»ºç« èŠ‚")
async def create_chapters_from_existing_plans(
    outline_id: str,
    plans_request: CreateChaptersFromPlansRequest,
    request: Request,
    db: AsyncSession = Depends(get_db),
    user_ai_service: AIService = Depends(get_user_ai_service)
):
    """
    æ ¹æ®å‰ç«¯ç¼“å­˜çš„ç« èŠ‚è§„åˆ’ç›´æ¥åˆ›å»ºç« èŠ‚è®°å½•ï¼Œé¿å…é‡å¤è°ƒç”¨AI
    
    ä½¿ç”¨åœºæ™¯ï¼š
    1. ç”¨æˆ·ç¬¬ä¸€æ¬¡è°ƒç”¨ /outlines/{outline_id}/expand?auto_create_chapters=false è·å–è§„åˆ’é¢„è§ˆ
    2. å‰ç«¯å±•ç¤ºè§„åˆ’ç»™ç”¨æˆ·ç¡®è®¤
    3. ç”¨æˆ·ç¡®è®¤åï¼Œå‰ç«¯è°ƒç”¨æ­¤æ¥å£ï¼Œä¼ é€’ç¼“å­˜çš„è§„åˆ’æ•°æ®ï¼Œç›´æ¥åˆ›å»ºç« èŠ‚
    
    ä¼˜åŠ¿ï¼š
    - é¿å…é‡å¤çš„AIè°ƒç”¨ï¼ŒèŠ‚çœTokenå’Œæ—¶é—´
    - ç¡®ä¿ç”¨æˆ·çœ‹åˆ°çš„é¢„è§ˆå’Œå®é™…åˆ›å»ºçš„ç« èŠ‚å®Œå…¨ä¸€è‡´
    - æå‡ç”¨æˆ·ä½“éªŒ
    
    å‚æ•°ï¼š
    - outline_id: è¦å±•å¼€çš„å¤§çº²ID
    - plans_request: åŒ…å«ä¹‹å‰AIç”Ÿæˆçš„ç« èŠ‚è§„åˆ’åˆ—è¡¨
    
    è¿”å›ï¼š
    - åˆ›å»ºçš„ç« èŠ‚åˆ—è¡¨å’Œç»Ÿè®¡ä¿¡æ¯
    """
    # éªŒè¯ç”¨æˆ·æƒé™
    user_id = getattr(request.state, 'user_id', None)
    
    # è·å–å¤§çº²
    result = await db.execute(
        select(Outline).where(Outline.id == outline_id)
    )
    outline = result.scalar_one_or_none()
    
    if not outline:
        raise HTTPException(status_code=404, detail="å¤§çº²ä¸å­˜åœ¨")
    
    # éªŒè¯é¡¹ç›®æƒé™
    await verify_project_access(outline.project_id, user_id, db)
    
    try:
        # éªŒè¯è§„åˆ’æ•°æ®
        if not plans_request.chapter_plans:
            raise HTTPException(status_code=400, detail="ç« èŠ‚è§„åˆ’åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
        
        logger.info(f"æ ¹æ®å·²æœ‰è§„åˆ’ä¸ºå¤§çº² {outline_id} åˆ›å»º {len(plans_request.chapter_plans)} ä¸ªç« èŠ‚")
        
        # åˆ›å»ºå±•å¼€æœåŠ¡å®ä¾‹
        expansion_service = PlotExpansionService(user_ai_service)
        
        # å°†Pydanticæ¨¡å‹è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        chapter_plans_dict = [plan.model_dump() for plan in plans_request.chapter_plans]
        
        # ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„è§„åˆ’åˆ›å»ºç« èŠ‚è®°å½•ï¼ˆä¸è°ƒç”¨AIï¼‰
        created_chapters = await expansion_service.create_chapters_from_plans(
            outline_id=outline_id,
            chapter_plans=chapter_plans_dict,
            project_id=outline.project_id,
            db=db,
            start_chapter_number=None  # è‡ªåŠ¨è®¡ç®—ç« èŠ‚åºå·
        )
        
        await db.commit()
        
        # åˆ·æ–°ç« èŠ‚æ•°æ®
        for chapter in created_chapters:
            await db.refresh(chapter)
        
        logger.info(f"æˆåŠŸæ ¹æ®å·²æœ‰è§„åˆ’åˆ›å»º {len(created_chapters)} ä¸ªç« èŠ‚è®°å½•")
        
        # æ„å»ºå“åº”
        return CreateChaptersFromPlansResponse(
            outline_id=outline_id,
            outline_title=outline.title,
            chapters_created=len(created_chapters),
            created_chapters=[
                {
                    "id": ch.id,
                    "chapter_number": ch.chapter_number,
                    "title": ch.title,
                    "summary": ch.summary,
                    "outline_id": ch.outline_id,
                    "sub_index": ch.sub_index,
                    "status": ch.status
                }
                for ch in created_chapters
            ]
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ ¹æ®å·²æœ‰è§„åˆ’åˆ›å»ºç« èŠ‚å¤±è´¥: {str(e)}", exc_info=True)
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºç« èŠ‚å¤±è´¥: {str(e)}")